{
    "https://api.github.com/repos/Sygil-Dev/sygil-webui": {
        "forks": 882,
        "watchers": 7888,
        "stars": 7888,
        "languages": {
            "Python": 2640668,
            "JavaScript": 80330,
            "Vue": 51703,
            "Jupyter Notebook": 28608,
            "Shell": 27350,
            "CSS": 25133,
            "Batchfile": 14937,
            "HTML": 3948,
            "TypeScript": 1959,
            "Dockerfile": 941
        },
        "commits": [
            "2024-08-14T15:03:33Z",
            "2024-08-14T15:01:55Z",
            "2024-08-13T08:37:45Z",
            "2024-05-20T12:31:05Z",
            "2024-05-14T22:25:08Z",
            "2023-11-26T05:34:39Z",
            "2023-11-26T05:33:55Z",
            "2023-11-26T05:32:56Z",
            "2023-11-26T05:32:45Z",
            "2023-11-26T05:32:17Z",
            "2023-11-26T05:31:49Z",
            "2023-11-26T03:00:32Z",
            "2023-09-12T21:13:00Z",
            "2023-09-12T21:10:25Z",
            "2023-09-12T15:29:03Z",
            "2023-09-12T15:27:35Z",
            "2023-09-02T00:39:10Z",
            "2023-09-02T00:35:49Z",
            "2023-09-02T00:32:16Z",
            "2023-09-02T00:28:49Z",
            "2023-08-06T11:22:33Z",
            "2023-08-06T11:18:28Z",
            "2023-08-06T11:13:25Z",
            "2023-08-06T11:10:06Z",
            "2023-08-03T16:01:50Z",
            "2023-08-03T16:01:14Z",
            "2023-08-03T16:01:02Z",
            "2023-08-03T16:00:03Z",
            "2023-08-03T15:58:31Z",
            "2023-07-27T00:11:57Z"
        ],
        "creation_date": "2022-08-24T10:43:48Z",
        "contributors": 30,
        "topics": [],
        "subscribers": 77,
        "readme": "# <center>Web-based UI for Stable Diffusion</center>\r\n\r\n## Created by [Sygil.Dev](https://github.com/sygil-dev)\r\n\r\n## Join us at Sygil.Dev's Discord Server [![Generic badge](https://flat.badgen.net/discord/members/ttM8Tm6wge?icon=discord)](https://discord.gg/ttM8Tm6wge)\r\n\r\n## Installation instructions for:\r\n\r\n- **[Windows](https://sygil-dev.github.io/sygil-webui/docs/Installation/windows-installation)**\r\n- **[Linux](https://sygil-dev.github.io/sygil-webui/docs/Installation/linux-installation)**\r\n\r\n### Want to ask a question or request a feature?\r\n\r\nCome to our [Discord Server](https://discord.gg/gyXNe4NySY) or use [Discussions](https://github.com/sygil-dev/sygil-webui/discussions).\r\n\r\n## Documentation\r\n\r\n[Documentation is located here](https://sygil-dev.github.io/sygil-webui/)\r\n\r\n## Want to contribute?\r\n\r\nCheck the [Contribution Guide](CONTRIBUTING.md)\r\n\r\n[Sygil-Dev](https://github.com/Sygil-Dev) main devs:\r\n\r\n* ![ZeroCool940711's avatar](https://avatars.githubusercontent.com/u/5977640?s=40&v=4)[ZeroCool940711](https://github.com/ZeroCool940711)\r\n* ![Kasiya13's avatar](https://avatars.githubusercontent.com/u/26075839?s=40&v=4)[Kasiya13](https://github.com/Kasiya13)\r\n\r\n### Project Features:\r\n\r\n* Built-in image enhancers and upscalers, including GFPGAN and realESRGAN\r\n\r\n* Generator Preview: See your image as its being made\r\n\r\n* Run additional upscaling models on CPU to save VRAM\r\n\r\n* Textual inversion: [Reaserch Paper](https://textual-inversion.github.io/)\r\n\r\n* K-Diffusion Samplers: A great collection of samplers to use, including:\r\n\r\n  - `k_euler`\r\n  - `k_lms`\r\n  - `k_euler_a`\r\n  - `k_dpm_2`\r\n  - `k_dpm_2_a`\r\n  - `k_heun`\r\n  - `PLMS`\r\n  - `DDIM`\r\n\r\n* Loopback: Automatically feed the last generated sample back into img2img\r\n\r\n* Prompt Weighting & Negative Prompts: Gain more control over your creations\r\n\r\n* Selectable GPU usage from Settings tab\r\n\r\n* Word Seeds: Use words instead of seed numbers\r\n\r\n* Automated Launcher: Activate conda and run Stable Diffusion with a single command\r\n\r\n* Lighter on VRAM: 512x512 Text2Image & Image2Image tested working on 4GB (with *optimized* mode enabled in Settings)\r\n\r\n* Prompt validation: If your prompt is too long, you will get a warning in the text output field\r\n\r\n* Sequential seeds for batches: If you use a seed of 1000 to generate two batches of two images each, four generated images will have seeds: `1000, 1001, 1002, 1003`.\r\n\r\n* Prompt matrix: Separate multiple prompts using the `|` character, and the system will produce an image for every combination of them.\r\n\r\n* [Gradio] Advanced img2img editor with Mask and crop capabilities\r\n\r\n* [Gradio] Mask painting \ud83d\udd8c\ufe0f: Powerful tool for re-generating only specific parts of an image you want to change (currently Gradio only)\r\n\r\n# SD WebUI\r\n\r\nAn easy way to work with Stable Diffusion right from your browser.\r\n\r\n## Streamlit\r\n\r\n![](images/streamlit/streamlit-t2i.png)\r\n\r\n**Features:**\r\n\r\n- Clean UI with an easy to use design, with support for widescreen displays\r\n- *Dynamic live preview* of your generations\r\n- Easily customizable defaults, right from the WebUI's Settings tab\r\n- An integrated gallery to show the generations for a prompt\r\n- *Optimized VRAM* usage for bigger generations or usage on lower end GPUs\r\n- *Text to Video:* Generate video clips from text prompts right from the WebUI (WIP)\r\n- Image to Text: Use [CLIP Interrogator](https://github.com/pharmapsychotic/clip-interrogator) to interrogate an image and get a prompt that you can use to generate a similar image using Stable Diffusion.\r\n- *Concepts Library:* Run custom embeddings others have made via textual inversion.\r\n- Textual Inversion training: Train your own embeddings on any photo you want and use it on your prompt.\r\n- **Currently in development: [Stable Horde](https://stablehorde.net/) integration; ImgLab, batch inputs, & mask editor from Gradio\r\n\r\n**Prompt Weights & Negative Prompts:**\r\n\r\nTo give a token (tag recognized by the AI) a specific or increased weight (emphasis), add `:0.##` to the prompt, where `0.##` is a decimal that will specify the weight of all tokens before the colon.\r\nEx: `cat:0.30, dog:0.70` or `guy riding a bicycle :0.7, incoming car :0.30`\r\n\r\nNegative prompts can be added by using  `###` , after which any tokens will be seen as negative.\r\nEx: `cat playing with string ### yarn` will negate `yarn` from the generated image.\r\n\r\nNegatives are a very powerful tool to get rid of contextually similar or related topics, but **be careful when adding them since the AI might see connections you can't**, and end up outputting gibberish\r\n\r\n**Tip:* Try using the same seed with different prompt configurations or weight values see how the AI understands them, it can lead to prompts that are more well-tuned and less prone to error.\r\n\r\nPlease see the [Streamlit Documentation](docs/4.streamlit-interface.md) to learn more.\r\n\r\n## Gradio [Legacy]\r\n\r\n![](images/gradio/gradio-t2i.png)\r\n\r\n**Features:**\r\n\r\n- Older UI that is functional and feature complete.\r\n- Has access to all upscaling models, including LSDR.\r\n- Dynamic prompt entry automatically changes your generation settings based on `--params` in a prompt.\r\n- Includes quick and easy ways to send generations to Image2Image or the Image Lab for upscaling.\r\n\r\n**Note: the Gradio interface is no longer being actively developed by Sygil.Dev and is only receiving bug fixes.**\r\n\r\nPlease see the [Gradio Documentation](https://sygil-dev.github.io/sygil-webui/docs/Gradio/gradio-interface/) to learn more.\r\n\r\n## Image Upscalers\r\n\r\n---\r\n\r\n### GFPGAN\r\n\r\n![](images/GFPGAN.png)\r\n\r\nLets you improve faces in pictures using the GFPGAN model. There is a checkbox in every tab to use GFPGAN at 100%, and also a separate tab that just allows you to use GFPGAN on any picture, with a slider that controls how strong the effect is.\r\n\r\nIf you want to use GFPGAN to improve generated faces, you need to install it separately.\r\nDownload [GFPGANv1.4.pth](https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth) and put it\r\ninto the `/sygil-webui/models/gfpgan` directory.\r\n\r\n### RealESRGAN\r\n\r\n![](images/RealESRGAN.png)\r\n\r\nLets you double the resolution of generated images. There is a checkbox in every tab to use RealESRGAN, and you can choose between the regular upscaler and the anime version.\r\nThere is also a separate tab for using RealESRGAN on any picture.\r\n\r\nDownload [RealESRGAN_x4plus.pth](https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth) and [RealESRGAN_x4plus_anime_6B.pth](https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth).\r\nPut them into the `sygil-webui/models/realesrgan` directory.\r\n\r\n### LSDR\r\n\r\nDownload **LDSR** [project.yaml](https://heibox.uni-heidelberg.de/f/31a76b13ea27482981b4/?dl=1) and [model last.cpkt](https://heibox.uni-heidelberg.de/f/578df07c8fc04ffbadf3/?dl=1). Rename `last.ckpt` to `model.ckpt` and place both under `sygil-webui/models/ldsr/`\r\n\r\n### GoBig, and GoLatent *(Currently on the Gradio version Only)*\r\n\r\nMore powerful upscalers that uses a separate Latent Diffusion model to more cleanly upscale images.\r\n\r\nPlease see the [Post-Processing Documentation](https://sygil-dev.github.io/sygil-webui/docs/post-processing) to learn more.\r\n\r\n-----\r\n\r\n### *Original Information From The Stable Diffusion Repo:*\r\n\r\n# Stable Diffusion\r\n\r\n*Stable Diffusion was made possible thanks to a collaboration with [Stability AI](https://stability.ai/) and [Runway](https://runwayml.com/) and builds upon our previous work:*\r\n\r\n[**High-Resolution Image Synthesis with Latent Diffusion Models**](https://ommer-lab.com/research/latent-diffusion-models/)\r\n[Robin Rombach](https://github.com/rromb)\\*,\r\n[Andreas Blattmann](https://github.com/ablattmann)\\*,\r\n[Dominik Lorenz](https://github.com/qp-qp)\\,\r\n[Patrick Esser](https://github.com/pesser),\r\n[Bj\u00f6rn Ommer](https://hci.iwr.uni-heidelberg.de/Staff/bommer)\r\n\r\n**CVPR '22 Oral**\r\n\r\nwhich is available on [GitHub](https://github.com/CompVis/latent-diffusion). PDF at [arXiv](https://arxiv.org/abs/2112.10752). Please also visit our [Project page](https://ommer-lab.com/research/latent-diffusion-models/).\r\n\r\n[Stable Diffusion](#stable-diffusion-v1) is a latent text-to-image diffusion\r\nmodel.\r\nThanks to a generous compute donation from [Stability AI](https://stability.ai/) and support from [LAION](https://laion.ai/), we were able to train a Latent Diffusion Model on 512x512 images from a subset of the [LAION-5B](https://laion.ai/blog/laion-5b/) database.\r\nSimilar to Google's [Imagen](https://arxiv.org/abs/2205.11487),\r\nthis model uses a frozen CLIP ViT-L/14 text encoder to condition the model on text prompts.\r\nWith its 860M UNet and 123M text encoder, the model is relatively lightweight and runs on a GPU with at least 10GB VRAM.\r\nSee [this section](#stable-diffusion-v1) below and the [model card](https://huggingface.co/CompVis/stable-diffusion).\r\n\r\n## Stable Diffusion v1\r\n\r\nStable Diffusion v1 refers to a specific configuration of the model\r\narchitecture that uses a downsampling-factor 8 autoencoder with an 860M UNet\r\nand CLIP ViT-L/14 text encoder for the diffusion model. The model was pretrained on 256x256 images and\r\nthen finetuned on 512x512 images.\r\n\r\n*Note: Stable Diffusion v1 is a general text-to-image diffusion model and therefore mirrors biases and (mis-)conceptions that are present\r\nin its training data.\r\nDetails on the training procedure and data, as well as the intended use of the model can be found in the corresponding [model card](https://huggingface.co/CompVis/stable-diffusion).\r\n\r\n## Comments\r\n\r\n- Our code base for the diffusion models builds heavily on [OpenAI's ADM codebase](https://github.com/openai/guided-diffusion)\r\n  and [https://github.com/lucidrains/denoising-diffusion-pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch).\r\n  Thanks for open-sourcing!\r\n\r\n- The implementation of the transformer encoder is from [x-transformers](https://github.com/lucidrains/x-transformers) by [lucidrains](https://github.com/lucidrains?tab=repositories).\r\n\r\n## BibTeX\r\n\r\n```\r\n@misc{rombach2021highresolution,\r\n      title={High-Resolution Image Synthesis with Latent Diffusion Models},\r\n      author={Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Bj\u00f6rn Ommer},\r\n      year={2021},\r\n      eprint={2112.10752},\r\n      archivePrefix={arXiv},\r\n      primaryClass={cs.CV}\r\n}\r\n```\r\n",
        "releases": []
    }
}