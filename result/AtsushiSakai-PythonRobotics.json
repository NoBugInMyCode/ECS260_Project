{
    "https://api.github.com/repos/AtsushiSakai/PythonRobotics": {
        "forks": 6639,
        "watchers": 24064,
        "stars": 24064,
        "languages": {
            "Python": 913811,
            "Shell": 254
        },
        "commits": [
            "2025-01-20T23:15:53Z",
            "2025-01-20T23:02:30Z",
            "2025-01-20T08:16:20Z",
            "2025-01-20T04:29:15Z",
            "2025-01-13T22:25:29Z",
            "2025-01-13T22:24:59Z",
            "2025-01-07T04:01:34Z",
            "2025-01-07T02:49:14Z",
            "2024-12-30T22:04:57Z",
            "2024-12-24T00:13:35Z",
            "2024-12-23T22:59:16Z",
            "2024-12-23T22:50:00Z",
            "2024-12-21T10:40:30Z",
            "2024-12-21T10:39:16Z",
            "2024-12-21T06:04:02Z",
            "2024-12-20T13:12:31Z",
            "2024-12-20T13:00:49Z",
            "2024-12-20T12:32:57Z",
            "2024-12-17T00:37:51Z",
            "2024-12-17T00:32:02Z",
            "2024-12-10T04:17:18Z",
            "2024-12-09T21:46:52Z",
            "2024-12-05T23:31:54Z",
            "2024-12-04T06:36:51Z",
            "2024-12-03T23:25:12Z",
            "2024-11-18T22:40:59Z",
            "2024-11-13T12:44:25Z",
            "2024-11-05T12:01:38Z",
            "2024-10-31T12:32:30Z",
            "2024-10-30T14:27:05Z"
        ],
        "creation_date": "2016-03-21T09:34:43Z",
        "contributors": 30,
        "topics": [
            "algorithm",
            "animation",
            "autonomous-driving",
            "autonomous-navigation",
            "autonomous-vehicles",
            "control",
            "cvxpy",
            "ekf",
            "hacktoberfest",
            "localization",
            "mapping",
            "path-planning",
            "python",
            "robot",
            "robotics",
            "slam"
        ],
        "subscribers": 515,
        "readme": "<img src=\"https://github.com/AtsushiSakai/PythonRobotics/raw/master/icon.png?raw=true\" align=\"right\" width=\"300\" alt=\"header pic\"/>\n\n# PythonRobotics\n![GitHub_Action_Linux_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Linux_CI/badge.svg)\n![GitHub_Action_MacOS_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/MacOS_CI/badge.svg)\n![GitHub_Action_Windows_CI](https://github.com/AtsushiSakai/PythonRobotics/workflows/Windows_CI/badge.svg)\n[![Build status](https://ci.appveyor.com/api/projects/status/sb279kxuv1be391g?svg=true)](https://ci.appveyor.com/project/AtsushiSakai/pythonrobotics)\n[![codecov](https://codecov.io/gh/AtsushiSakai/PythonRobotics/branch/master/graph/badge.svg)](https://codecov.io/gh/AtsushiSakai/PythonRobotics)\n\nPython codes for robotics algorithm.\n\n\n# Table of Contents\n   * [What is this?](#what-is-this)\n   * [Requirements](#requirements)\n   * [Documentation](#documentation)\n   * [How to use](#how-to-use)\n   * [Localization](#localization)\n      * [Extended Kalman Filter localization](#extended-kalman-filter-localization)\n      * [Particle filter localization](#particle-filter-localization)\n      * [Histogram filter localization](#histogram-filter-localization)\n   * [Mapping](#mapping)\n      * [Gaussian grid map](#gaussian-grid-map)\n      * [Ray casting grid map](#ray-casting-grid-map)\n      * [Lidar to grid map](#lidar-to-grid-map)\n      * [k-means object clustering](#k-means-object-clustering)\n      * [Rectangle fitting](#rectangle-fitting)\n   * [SLAM](#slam)\n      * [Iterative Closest Point (ICP) Matching](#iterative-closest-point-icp-matching)\n      * [FastSLAM 1.0](#fastslam-10)\n   * [Path Planning](#path-planning)\n      * [Dynamic Window Approach](#dynamic-window-approach)\n      * [Grid based search](#grid-based-search)\n         * [Dijkstra algorithm](#dijkstra-algorithm)\n         * [A* algorithm](#a-algorithm)\n         * [D* algorithm](#d-algorithm)\n         * [D* Lite algorithm](#d-lite-algorithm)\n         * [Potential Field algorithm](#potential-field-algorithm)\n         * [Grid based coverage path planning](#grid-based-coverage-path-planning)\n      * [State Lattice Planning](#state-lattice-planning)\n         * [Biased polar sampling](#biased-polar-sampling)\n         * [Lane sampling](#lane-sampling)\n      * [Probabilistic Road-Map (PRM) planning](#probabilistic-road-map-prm-planning)\n      * [Rapidly-Exploring Random Trees (RRT)](#rapidly-exploring-random-trees-rrt)\n         * [RRT*](#rrt)\n         * [RRT* with reeds-shepp path](#rrt-with-reeds-shepp-path)\n         * [LQR-RRT*](#lqr-rrt)\n      * [Quintic polynomials planning](#quintic-polynomials-planning)\n      * [Reeds Shepp planning](#reeds-shepp-planning)\n      * [LQR based path planning](#lqr-based-path-planning)\n      * [Optimal Trajectory in a Frenet Frame](#optimal-trajectory-in-a-frenet-frame)\n   * [Path Tracking](#path-tracking)\n      * [move to a pose control](#move-to-a-pose-control)\n      * [Stanley control](#stanley-control)\n      * [Rear wheel feedback control](#rear-wheel-feedback-control)\n      * [Linear\u2013quadratic regulator (LQR) speed and steering control](#linearquadratic-regulator-lqr-speed-and-steering-control)\n      * [Model predictive speed and steering control](#model-predictive-speed-and-steering-control)\n      * [Nonlinear Model predictive control with C-GMRES](#nonlinear-model-predictive-control-with-c-gmres)\n   * [Arm Navigation](#arm-navigation)\n      * [N joint arm to point control](#n-joint-arm-to-point-control)\n      * [Arm navigation with obstacle avoidance](#arm-navigation-with-obstacle-avoidance)\n   * [Aerial Navigation](#aerial-navigation)\n      * [drone 3d trajectory following](#drone-3d-trajectory-following)\n      * [rocket powered landing](#rocket-powered-landing)\n   * [Bipedal](#bipedal)\n      * [bipedal planner with inverted pendulum](#bipedal-planner-with-inverted-pendulum)\n   * [License](#license)\n   * [Use-case](#use-case)\n   * [Contribution](#contribution)\n   * [Citing](#citing)\n   * [Support](#support)\n   * [Sponsors](#sponsors)\n      * [JetBrains](#JetBrains)\n      * [1Password](#1password)\n   * [Authors](#authors)\n\n# What is this?\n\nThis is a Python code collection of robotics algorithms.\n\nFeatures:\n\n1. Easy to read for understanding each algorithm's basic idea.\n\n2. Widely used and practical algorithms are selected.\n\n3. Minimum dependency.\n\nSee this paper for more details:\n\n- [\\[1808\\.10703\\] PythonRobotics: a Python code collection of robotics algorithms](https://arxiv.org/abs/1808.10703) ([BibTeX](https://github.com/AtsushiSakai/PythonRoboticsPaper/blob/master/python_robotics.bib))\n\n\n# Requirements\n\nFor running each sample code:\n\n- [Python 3.12.x](https://www.python.org/)\n \n- [NumPy](https://numpy.org/)\n \n- [SciPy](https://scipy.org/)\n \n- [Matplotlib](https://matplotlib.org/)\n \n- [cvxpy](https://www.cvxpy.org/) \n\nFor development:\n  \n- [pytest](https://pytest.org/) (for unit tests)\n  \n- [pytest-xdist](https://pypi.org/project/pytest-xdist/) (for parallel unit tests)\n  \n- [mypy](http://mypy-lang.org/) (for type check)\n  \n- [sphinx](https://www.sphinx-doc.org/) (for document generation)\n  \n- [pycodestyle](https://pypi.org/project/pycodestyle/) (for code style check)\n\n# Documentation\n\nThis README only shows some examples of this project. \n\nIf you are interested in other examples or mathematical backgrounds of each algorithm, \n\nYou can check the full documentation online: [Welcome to PythonRobotics\u2019s documentation\\! \u2014 PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/index.html)\n\nAll animation gifs are stored here: [AtsushiSakai/PythonRoboticsGifs: Animation gifs of PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs)\n\n# How to use\n\n1. Clone this repo.\n\n   ```terminal\n   git clone https://github.com/AtsushiSakai/PythonRobotics.git\n   ```\n\n\n2. Install the required libraries.\n\n- using conda :\n\n  ```terminal\n  conda env create -f requirements/environment.yml\n  ```\n \n- using pip :\n\n  ```terminal\n  pip install -r requirements/requirements.txt\n  ```\n\n\n3. Execute python script in each directory.\n\n4. Add star to this repo if you like it :smiley:. \n\n# Localization\n\n## Extended Kalman Filter localization\n\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/extended_kalman_filter/animation.gif\" width=\"640\" alt=\"EKF pic\">\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/localization/extended_kalman_filter_localization_files/extended_kalman_filter_localization.html)\n\n## Particle filter localization\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/particle_filter/animation.gif)\n\nThis is a sensor fusion localization with Particle Filter(PF).\n\nThe blue line is true trajectory, the black line is dead reckoning trajectory,\n\nand the red line is an estimated trajectory with PF.\n\nIt is assumed that the robot can measure a distance from landmarks (RFID).\n\nThese measurements are used for PF localization.\n\nRef:\n\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\n\n\n## Histogram filter localization\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Localization/histogram_filter/animation.gif)\n\nThis is a 2D localization example with Histogram filter.\n\nThe red cross is true position, black points are RFID positions.\n\nThe blue grid shows a position probability of histogram filter.  \n\nIn this simulation, x,y are unknown, yaw is known.\n\nThe filter integrates speed input and range observations from RFID for localization.\n\nInitial position is not needed.\n\nRef:\n\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\n\n# Mapping\n\n## Gaussian grid map\n\nThis is a 2D Gaussian grid mapping example.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/gaussian_grid_map/animation.gif)\n\n## Ray casting grid map\n\nThis is a 2D ray casting grid mapping example.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/raycasting_grid_map/animation.gif)\n\n## Lidar to grid map\n\nThis example shows how to convert a 2D range measurement to a grid map.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/lidar_to_grid_map/animation.gif)\n\n## k-means object clustering\n\nThis is a 2D object clustering with k-means algorithm.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/kmeans_clustering/animation.gif)\n\n## Rectangle fitting\n\nThis is a 2D rectangle fitting for vehicle detection.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Mapping/rectangle_fitting/animation.gif)\n\n\n# SLAM\n\nSimultaneous Localization and Mapping(SLAM) examples\n\n## Iterative Closest Point (ICP) Matching\n\nThis is a 2D ICP matching example with singular value decomposition.\n\nIt can calculate a rotation matrix, and a translation vector between points and points.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/iterative_closest_point/animation.gif)\n\nRef:\n\n- [Introduction to Mobile Robotics: Iterative Closest Point Algorithm](https://cs.gmu.edu/~kosecka/cs685/cs685-icp.pdf)\n\n\n## FastSLAM 1.0\n\nThis is a feature based SLAM example using FastSLAM 1.0.\n\nThe blue line is ground truth, the black line is dead reckoning, the red line is the estimated trajectory with FastSLAM.\n\nThe red points are particles of FastSLAM.\n\nBlack points are landmarks, blue crosses are estimated landmark positions by FastSLAM.\n\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/SLAM/FastSLAM1/animation.gif)\n\n\nRef:\n\n- [PROBABILISTIC ROBOTICS](http://www.probabilistic-robotics.org/)\n\n- [SLAM simulations by Tim Bailey](http://www-personal.acfr.usyd.edu.au/tbailey/software/slam_simulations.htm)\n\n\n# Path Planning\n\n## Dynamic Window Approach\n\nThis is a 2D navigation sample code with Dynamic Window Approach.\n\n- [The Dynamic Window Approach to Collision Avoidance](https://www.ri.cmu.edu/pub_files/pub1/fox_dieter_1997_1/fox_dieter_1997_1.pdf)\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DynamicWindowApproach/animation.gif)\n\n\n## Grid based search\n\n### Dijkstra algorithm\n\nThis is a 2D grid based the shortest path planning with Dijkstra's algorithm.\n\n![PythonRobotics/figure_1.png at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/Dijkstra/animation.gif)\n\nIn the animation, cyan points are searched nodes.\n\n### A\\* algorithm\n\nThis is a 2D grid based the shortest path planning with A star algorithm.\n\n![PythonRobotics/figure_1.png at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/AStar/animation.gif)\n\nIn the animation, cyan points are searched nodes.\n\nIts heuristic is 2D Euclid distance.\n\n### D\\* algorithm\n\nThis is a 2D grid based the shortest path planning with D star algorithm.\n\n![figure at master \u00b7 nirnayroy/intelligentrobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStar/animation.gif)\n\nThe animation shows a robot finding its path avoiding an obstacle using the D* search algorithm.\n\nRef:\n\n- [D* Algorithm Wikipedia](https://en.wikipedia.org/wiki/D*)\n\n### D\\* Lite algorithm\n\nThis algorithm finds the shortest path between two points while rerouting when obstacles are discovered. It has been implemented here for a 2D grid.\n\n![D* Lite](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/DStarLite/animation.gif)\n\nThe animation shows a robot finding its path and rerouting to avoid obstacles as they are discovered using the D* Lite search algorithm.\n\nRefs:\n\n- [D* Lite](http://idm-lab.org/bib/abstracts/papers/aaai02b.pd)\n- [Improved Fast Replanning for Robot Navigation in Unknown Terrain](http://www.cs.cmu.edu/~maxim/files/dlite_icra02.pdf)\n\n### Potential Field algorithm\n\nThis is a 2D grid based path planning with Potential Field algorithm.\n\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/PotentialFieldPlanning/animation.gif)\n\nIn the animation, the blue heat map shows potential value on each grid.\n\nRef:\n\n- [Robotic Motion Planning:Potential Functions](https://www.cs.cmu.edu/~motionplanning/lecture/Chap4-Potential-Field_howie.pdf)\n\n### Grid based coverage path planning\n\nThis is a 2D grid based coverage path planning simulation.\n\n![PotentialField](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/GridBasedSweepCPP/animation.gif)\n\n## State Lattice Planning\n\nThis script is a path planning code with state lattice planning.\n\nThis code uses the model predictive trajectory generator to solve boundary problem.\n\nRef: \n\n- [Optimal rough terrain trajectory generation for wheeled mobile robots](http://journals.sagepub.com/doi/pdf/10.1177/0278364906075328)\n\n- [State Space Sampling of Feasible Motions for High-Performance Mobile Robot Navigation in Complex Environments](http://www.frc.ri.cmu.edu/~alonzo/pubs/papers/JFR_08_SS_Sampling.pdf)\n\n\n### Biased polar sampling\n\n![PythonRobotics/figure_1.png at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/BiasedPolarSampling.gif)\n\n\n### Lane sampling\n\n![PythonRobotics/figure_1.png at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/StateLatticePlanner/LaneSampling.gif)\n\n## Probabilistic Road-Map (PRM) planning \n\n![PRM](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ProbabilisticRoadMap/animation.gif)\n\nThis PRM planner uses Dijkstra method for graph search.\n\nIn the animation, blue points are sampled points,\n\nCyan crosses means searched points with Dijkstra method,\n\nThe red line is the final path of PRM.\n\nRef:\n\n- [Probabilistic roadmap \\- Wikipedia](https://en.wikipedia.org/wiki/Probabilistic_roadmap)\n\n\u3000\u3000\n\n## Rapidly-Exploring Random Trees (RRT)\n\n### RRT\\*\n\n![PythonRobotics/figure_1.png at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTstar/animation.gif)\n\nThis is a path planning code with RRT\\*\n\nBlack circles are obstacles, green line is a searched tree, red crosses are start and goal positions.\n\nRef:\n\n- [Incremental Sampling-based Algorithms for Optimal Motion Planning](https://arxiv.org/abs/1005.0416)\n\n- [Sampling-based Algorithms for Optimal Motion Planning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.419.5503&rep=rep1&type=pdf)\n\n### RRT\\* with reeds-shepp path\n\n![Robotics/animation.gif at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/RRTStarReedsShepp/animation.gif)\n\nPath planning for a car robot with RRT\\* and reeds shepp path planner.\n\n### LQR-RRT\\*\n\nThis is a path planning simulation with LQR-RRT\\*.\n\nA double integrator motion model is used for LQR local planner.\n\n![LQR_RRT](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRRRTStar/animation.gif)\n\nRef:\n\n- [LQR\\-RRT\\*: Optimal Sampling\\-Based Motion Planning with Automatically Derived Extension Heuristics](http://lis.csail.mit.edu/pubs/perez-icra12.pdf)\n\n- [MahanFathi/LQR\\-RRTstar: LQR\\-RRT\\* method is used for random motion planning of a simple pendulum in its phase plot](https://github.com/MahanFathi/LQR-RRTstar)\n\n\n## Quintic polynomials planning\n\nMotion planning with quintic polynomials.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/QuinticPolynomialsPlanner/animation.gif)\n\nIt can calculate a 2D path, velocity, and acceleration profile based on quintic polynomials.\n\nRef:\n\n- [Local Path Planning And Motion Control For Agv In Positioning](http://ieeexplore.ieee.org/document/637936/)\n\n## Reeds Shepp planning\n\nA sample code with Reeds Shepp path planning.\n\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/ReedsSheppPath/animation.gif?raw=true)\n\nRef:\n\n- [15.3.2 Reeds\\-Shepp Curves](http://planning.cs.uiuc.edu/node822.html) \n\n- [optimal paths for a car that goes both forwards and backwards](https://pdfs.semanticscholar.org/932e/c495b1d0018fd59dee12a0bf74434fac7af4.pdf)\n\n- [ghliu/pyReedsShepp: Implementation of Reeds Shepp curve\\.](https://github.com/ghliu/pyReedsShepp)\n\n\n## LQR based path planning\n\nA sample code using LQR based path planning for double integrator model.\n\n![RSPlanning](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/LQRPlanner/animation.gif?raw=true)\n\n\n## Optimal Trajectory in a Frenet Frame \n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathPlanning/FrenetOptimalTrajectory/animation.gif)\n\nThis is optimal trajectory generation in a Frenet Frame.\n\nThe cyan line is the target course and black crosses are obstacles.\n\nThe red line is the predicted path.\n\nRef:\n\n- [Optimal Trajectory Generation for Dynamic Street Scenarios in a Frenet Frame](https://www.researchgate.net/profile/Moritz_Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af.pdf)\n\n- [Optimal trajectory generation for dynamic street scenarios in a Frenet Frame](https://www.youtube.com/watch?v=Cj6tAQe7UCY)\n\n\n# Path Tracking\n\n## move to a pose control\n\nThis is a simulation of moving to a pose control\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/move_to_pose/animation.gif)\n\nRef:\n\n- [P. I. Corke, \"Robotics, Vision and Control\" \\| SpringerLink p102](https://link.springer.com/book/10.1007/978-3-642-20144-8)\n\n\n## Stanley control\n\nPath tracking simulation with Stanley steering control and PID speed control.\n\n![2](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/stanley_controller/animation.gif)\n\nRef:\n\n- [Stanley: The robot that won the DARPA grand challenge](http://robots.stanford.edu/papers/thrun.stanley05.pdf)\n\n- [Automatic Steering Methods for Autonomous Automobile Path Tracking](https://www.ri.cmu.edu/pub_files/2009/2/Automatic_Steering_Methods_for_Autonomous_Automobile_Path_Tracking.pdf)\n\n\n\n## Rear wheel feedback control\n\nPath tracking simulation with rear wheel feedback steering control and PID speed control.\n\n![PythonRobotics/figure_1.png at master \u00b7 AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/rear_wheel_feedback/animation.gif)\n\nRef:\n\n- [A Survey of Motion Planning and Control Techniques for Self-driving Urban Vehicles](https://arxiv.org/abs/1604.07446)\n\n\n## Linear\u2013quadratic regulator (LQR) speed and steering control\n\nPath tracking simulation with LQR speed and steering control.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/lqr_speed_steer_control/animation.gif)\n\nRef:\n\n- [Towards fully autonomous driving: Systems and algorithms \\- IEEE Conference Publication](http://ieeexplore.ieee.org/document/5940562/)\n\n\n## Model predictive speed and steering control\n\nPath tracking simulation with iterative linear model predictive speed and steering control.\n\n<img src=\"https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/model_predictive_speed_and_steer_control/animation.gif\" width=\"640\" alt=\"MPC pic\">\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/model_predictive_speed_and_steering_control/model_predictive_speed_and_steering_control.html)\n\n- [Real\\-time Model Predictive Control \\(MPC\\), ACADO, Python \\| Work\\-is\\-Playing](http://grauonline.de/wordpress/?page_id=3244)\n\n## Nonlinear Model predictive control with C-GMRES\n\nA motion planning and path tracking simulation with NMPC of C-GMRES \n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/PathTracking/cgmres_nmpc/animation.gif)\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/path_tracking/cgmres_nmpc/cgmres_nmpc.html)\n\n\n# Arm Navigation\n\n## N joint arm to point control\n\nN joint arm to a point control simulation.\n\nThis is an interactive simulation.\n\nYou can set the goal position of the end effector with left-click on the plotting area. \n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/n_joint_arm_to_point_control/animation.gif)\n\nIn this simulation N = 10, however, you can change it.\n\n## Arm navigation with obstacle avoidance \n\nArm navigation with obstacle avoidance simulation.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/ArmNavigation/arm_obstacle_navigation/animation.gif)\n\n\n# Aerial Navigation\n\n## drone 3d trajectory following \n\nThis is a 3d trajectory following simulation for a quadrotor.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/drone_3d_trajectory_following/animation.gif)\n\n## rocket powered landing\n\nThis is a 3d trajectory generation simulation for a rocket powered landing.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/AerialNavigation/rocket_powered_landing/animation.gif)\n\nRef:\n\n- [documentation](https://atsushisakai.github.io/PythonRobotics/modules/aerial_navigation/rocket_powered_landing/rocket_powered_landing.html)\n\n# Bipedal\n\n## bipedal planner with inverted pendulum\n\nThis is a bipedal planner for modifying footsteps for an inverted pendulum.\n\nYou can set the footsteps, and the planner will modify those automatically.\n\n![3](https://github.com/AtsushiSakai/PythonRoboticsGifs/raw/master/Bipedal/bipedal_planner/animation.gif)\n\n# License \n\nMIT\n\n# Use-case\n\nIf this project helps your robotics project, please let me know with creating an issue.\n\nYour robot's video, which is using PythonRobotics, is very welcome!!\n\nThis is a list of user's comment and references:[users\\_comments](https://github.com/AtsushiSakai/PythonRobotics/blob/master/users_comments.md)\n\n# Contribution\n\nAny contribution is welcome!! \n\nPlease check this document:[How To Contribute \u2014 PythonRobotics documentation](https://atsushisakai.github.io/PythonRobotics/how_to_contribute.html)\n\n# Citing\n\nIf you use this project's code for your academic work, we encourage you to cite [our papers](https://arxiv.org/abs/1808.10703) \n\nIf you use this project's code in industry, we'd love to hear from you as well; feel free to reach out to the developers directly.\n\n# <a id=\"support\"></a>Supporting this project\n\nIf you or your company would like to support this project, please consider:\n\n- [Sponsor @AtsushiSakai on GitHub Sponsors](https://github.com/sponsors/AtsushiSakai)\n\n- [Become a backer or sponsor on Patreon](https://www.patreon.com/myenigma)\n\n- [One-time donation via PayPal](https://www.paypal.me/myenigmapay/)\n\nIf you would like to support us in some other way, please contact with creating an issue.\n\n## <a id=\"sponsors\"></a>Sponsors\n\n### <a id=\"JetBrains\"></a>[JetBrains](https://www.jetbrains.com/)\n\nThey are providing a free license of their IDEs for this OSS development.   \n\n### [1Password](https://github.com/1Password/1password-teams-open-source)\n\nThey are providing a free license of their 1Password team license for this OSS project.   \n\n\n# Authors\n\n- [Contributors to AtsushiSakai/PythonRobotics](https://github.com/AtsushiSakai/PythonRobotics/graphs/contributors)\n\n",
        "releases": []
    }
}