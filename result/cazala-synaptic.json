{
    "https://api.github.com/repos/cazala/synaptic": {
        "forks": 663,
        "watchers": 6920,
        "stars": 6920,
        "languages": {
            "JavaScript": 100419
        },
        "commits": [
            "2019-02-14T15:08:19Z",
            "2019-02-14T14:59:09Z",
            "2018-03-24T22:03:51Z",
            "2018-02-15T19:08:19Z",
            "2018-02-15T19:07:56Z",
            "2018-02-15T19:06:34Z",
            "2018-02-12T13:12:33Z",
            "2017-11-22T13:18:27Z",
            "2017-11-01T18:48:40Z",
            "2017-11-01T14:13:36Z",
            "2017-11-01T14:09:09Z",
            "2017-10-22T01:45:21Z",
            "2017-10-22T01:45:16Z",
            "2017-10-22T01:44:27Z",
            "2017-10-22T01:43:04Z",
            "2017-10-22T01:41:16Z",
            "2017-10-22T01:40:45Z",
            "2017-10-02T02:08:13Z",
            "2017-09-26T19:28:35Z",
            "2017-09-26T19:26:35Z",
            "2017-09-26T19:25:50Z",
            "2017-09-06T17:38:34Z",
            "2017-09-06T17:37:07Z",
            "2017-09-06T17:36:48Z",
            "2017-09-06T17:35:33Z",
            "2017-09-06T17:35:24Z",
            "2017-09-06T17:34:28Z",
            "2017-09-06T17:33:15Z",
            "2017-08-30T13:10:19Z",
            "2017-08-29T14:25:02Z"
        ],
        "creation_date": "2014-09-30T18:07:03Z",
        "contributors": 30,
        "topics": [],
        "subscribers": 280,
        "readme": "Synaptic [![Build Status](https://travis-ci.org/cazala/synaptic.svg?branch=master)](https://travis-ci.org/cazala/synaptic) [![Join the chat at https://synapticjs.slack.com](https://synaptic-slack.now.sh/badge.svg)](https://synaptic-slack.now.sh/)\n========\n\n## Important: [Synaptic 2.x](https://github.com/cazala/synaptic/issues/140) is in stage of discussion now! Feel free to participate\n\nSynaptic is a javascript neural network library for **node.js** and the **browser**, its generalized algorithm is architecture-free, so you can build and train basically any type of first order or even [second order neural network](http://en.wikipedia.org/wiki/Recurrent_neural_network#Second_Order_Recurrent_Neural_Network) architectures.\n\nThis library includes a few built-in architectures like [multilayer perceptrons](http://en.wikipedia.org/wiki/Multilayer_perceptron), [multilayer long-short term memory](http://en.wikipedia.org/wiki/Long_short_term_memory) networks (LSTM), [liquid state machines](http://en.wikipedia.org/wiki/Liquid_state_machine) or [Hopfield](http://en.wikipedia.org/wiki/Hopfield_network) networks, and a trainer capable of training any given network, which includes built-in training tasks/tests like solving an XOR, completing a Distracted Sequence Recall task or an [Embedded Reber Grammar](http://www.willamette.edu/~gorr/classes/cs449/reber.html) test, so you can easily test and compare the performance of different architectures.\n\n\nThe algorithm implemented by this library has been taken from Derek D. Monner's paper:\n\n[A generalized LSTM-like training algorithm for second-order recurrent neural networks](http://www.overcomplete.net/papers/nn2012.pdf)\n\n\nThere are references to the equations in that paper commented through the source code.\n\n#### Introduction\n\nIf you have no prior knowledge about Neural Networks, you should start by [reading this guide](https://github.com/cazala/synaptic/wiki/Neural-Networks-101).\n\n\nIf you want a practical example on how to feed data to a neural network, then take a look at [this article](https://github.com/cazala/synaptic/wiki/Normalization-101).\n\nYou may also want to take a look at [this article](http://blog.webkid.io/neural-networks-in-javascript/).\n\n#### Demos\n\n- [Solve an XOR](http://caza.la/synaptic/#/xor)\n- [Discrete Sequence Recall Task](http://caza.la/synaptic/#/dsr)\n- [Learn Image Filters](http://caza.la/synaptic/#/image-filters)\n- [Paint an Image](http://caza.la/synaptic/#/paint-an-image)\n- [Self Organizing Map](http://caza.la/synaptic/#/self-organizing-map)\n- [Read from Wikipedia](http://caza.la/synaptic/#/wikipedia)\n- [Creating a Simple Neural Network (Video)](https://scrimba.com/casts/cast-1980)\n- [Learn how to shoot](https://sta-ger.bitbucket.io/apps/bot/index.html)\n- [Beer glass classifier](https://sta-ger.bitbucket.io/apps/beer/index.html)\n\nThe source code of these demos can be found in [this branch](https://github.com/cazala/synaptic/tree/gh-pages/scripts).\n\n#### Getting started\n\n- [Neurons](https://github.com/cazala/synaptic/wiki/Neurons/)\n- [Layers](https://github.com/cazala/synaptic/wiki/Layers/)\n- [Networks](https://github.com/cazala/synaptic/wiki/Networks/)\n- [Trainer](https://github.com/cazala/synaptic/wiki/Trainer/)\n- [Architect](https://github.com/cazala/synaptic/wiki/Architect/)\n\nTo try out the examples, checkout the [gh-pages](https://github.com/cazala/synaptic/tree/gh-pages) branch.\n\n`git checkout gh-pages`\n\n#### Other languages\n\nThis README is also available in other languages.\n\n- [Chinese Simplified | \u4e2d\u6587\u6587\u6863](https://github.com/cazala/synaptic/blob/master/README_Zh-CN.md), thanks to [@noraincode](https://github.com/noraincode).\n- [Chinese Traditional | \u7e41\u9ad4\u4e2d\u6587](https://github.com/cazala/synaptic/blob/master/README_Zh-TW.md), by [@NoobTW](https://github.com/noobtw).\n- [Japanese | \u65e5\u672c\u8a9e](https://github.com/cazala/synaptic/blob/master/README_Ja-JP.md), thanks to [@oshirogo](https://github.com/dscripps).  \n\n## Overview\n\n### Installation\n\n##### In node\n\nYou can install synaptic with [npm](http://npmjs.org):\n\n```cmd\nnpm install synaptic --save\n```\n\n##### In the browser\n\nYou can install synaptic with [bower](http://bower.io):\n\n```cmd\nbower install synaptic\n```\n\nOr you can simply use the CDN link, kindly provided by [CDNjs](https://cdnjs.com/)\n\n```html\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/synaptic/1.1.4/synaptic.js\"></script>\n```\n\n### Usage\n\n```javascript\nvar synaptic = require('synaptic'); // this line is not needed in the browser\nvar Neuron = synaptic.Neuron,\n\tLayer = synaptic.Layer,\n\tNetwork = synaptic.Network,\n\tTrainer = synaptic.Trainer,\n\tArchitect = synaptic.Architect;\n```\n\nNow you can start to create networks, train them, or use built-in networks from the [Architect](https://github.com/cazala/synaptic/wiki/Architect/).\n\n### Examples\n\n##### Perceptron\n\nThis is how you can create a simple **perceptron**:\n\n![perceptron](http://www.codeproject.com/KB/dotnet/predictor/network.jpg).\n\n```javascript\nfunction Perceptron(input, hidden, output)\n{\n\t// create the layers\n\tvar inputLayer = new Layer(input);\n\tvar hiddenLayer = new Layer(hidden);\n\tvar outputLayer = new Layer(output);\n\n\t// connect the layers\n\tinputLayer.project(hiddenLayer);\n\thiddenLayer.project(outputLayer);\n\n\t// set the layers\n\tthis.set({\n\t\tinput: inputLayer,\n\t\thidden: [hiddenLayer],\n\t\toutput: outputLayer\n\t});\n}\n\n// extend the prototype chain\nPerceptron.prototype = new Network();\nPerceptron.prototype.constructor = Perceptron;\n```\n\nNow you can test your new network by creating a trainer and teaching the perceptron to learn an XOR\n\n```javascript\nvar myPerceptron = new Perceptron(2,3,1);\nvar myTrainer = new Trainer(myPerceptron);\n\nmyTrainer.XOR(); // { error: 0.004998819355993572, iterations: 21871, time: 356 }\n\nmyPerceptron.activate([0,0]); // 0.0268581547421616\nmyPerceptron.activate([1,0]); // 0.9829673642853368\nmyPerceptron.activate([0,1]); // 0.9831714267395621\nmyPerceptron.activate([1,1]); // 0.02128894618097928\n```\n\n##### Long Short-Term Memory\n\nThis is how you can create a simple **long short-term memory** network with input gate, forget gate, output gate, and peephole connections:\n\n![long short-term memory](http://people.idsia.ch/~juergen/lstmcell4.jpg)\n\n```javascript\nfunction LSTM(input, blocks, output)\n{\n\t// create the layers\n\tvar inputLayer = new Layer(input);\n\tvar inputGate = new Layer(blocks);\n\tvar forgetGate = new Layer(blocks);\n\tvar memoryCell = new Layer(blocks);\n\tvar outputGate = new Layer(blocks);\n\tvar outputLayer = new Layer(output);\n\n\t// connections from input layer\n\tvar input = inputLayer.project(memoryCell);\n\tinputLayer.project(inputGate);\n\tinputLayer.project(forgetGate);\n\tinputLayer.project(outputGate);\n\n\t// connections from memory cell\n\tvar output = memoryCell.project(outputLayer);\n\n\t// self-connection\n\tvar self = memoryCell.project(memoryCell);\n\n\t// peepholes\n\tmemoryCell.project(inputGate);\n\tmemoryCell.project(forgetGate);\n\tmemoryCell.project(outputGate);\n\n\t// gates\n\tinputGate.gate(input, Layer.gateType.INPUT);\n\tforgetGate.gate(self, Layer.gateType.ONE_TO_ONE);\n\toutputGate.gate(output, Layer.gateType.OUTPUT);\n\n\t// input to output direct connection\n\tinputLayer.project(outputLayer);\n\n\t// set the layers of the neural network\n\tthis.set({\n\t\tinput: inputLayer,\n\t\thidden: [inputGate, forgetGate, memoryCell, outputGate],\n\t\toutput: outputLayer\n\t});\n}\n\n// extend the prototype chain\nLSTM.prototype = new Network();\nLSTM.prototype.constructor = LSTM;\n```\n\nThese are examples for explanatory purposes, the [Architect](https://github.com/cazala/synaptic/wiki/Architect/) already includes Multilayer Perceptrons and\nMultilayer LSTM network architectures.\n\n## Contribute\n\n**Synaptic** is an Open Source project that started in Buenos Aires, Argentina. Anybody in the world is welcome to contribute to the development of the project.\n\nIf you want to contribute feel free to send PR's, just make sure to run **npm run test** and **npm run build** before submitting it. This way you'll run all the test specs and build the web distribution files.\n\n## Support\n\nIf you like this project and you want to show your support, you can buy me a beer with [magic internet money](https://i.imgur.com/mScSiOo.jpg):\n\n```\nBTC: 16ePagGBbHfm2d6esjMXcUBTNgqpnLWNeK\nETH: 0xa423bfe9db2dc125dd3b56f215e09658491cc556\nLTC: LeeemeZj6YL6pkTTtEGHFD6idDxHBF2HXa\nXMR: 46WNbmwXpYxiBpkbHjAgjC65cyzAxtaaBQjcGpAZquhBKw2r8NtPQniEgMJcwFMCZzSBrEJtmPsTR54MoGBDbjTi2W1XmgM\n```\n\n<3\n",
        "releases": [
            {
                "name": "v1.1.4",
                "date": "2017-10-22T01:47:24Z"
            },
            {
                "name": "v1.1.3",
                "date": "2017-09-26T19:29:57Z"
            },
            {
                "name": "v1.1.2",
                "date": "2017-09-06T17:40:10Z"
            },
            {
                "name": "v1.1.1",
                "date": "2017-08-29T14:27:44Z"
            },
            {
                "name": "v1.1.0",
                "date": "2017-08-27T16:36:24Z"
            },
            {
                "name": "v1.0.10",
                "date": "2017-03-15T22:12:46Z"
            },
            {
                "name": "v1.0.9",
                "date": "2016-09-20T10:19:25Z"
            },
            {
                "name": "v1.0.8",
                "date": "2016-07-25T18:41:27Z"
            },
            {
                "name": "v1.0.7",
                "date": "2016-07-09T19:53:05Z"
            },
            {
                "name": "v1.0.6",
                "date": "2016-07-08T22:12:23Z"
            },
            {
                "name": "v1.0.5",
                "date": "2016-07-05T00:57:51Z"
            },
            {
                "name": "v1.0.4",
                "date": "2016-03-17T13:39:19Z"
            },
            {
                "name": "v1.0.3",
                "date": "2016-03-02T16:31:33Z"
            },
            {
                "name": "v1.0.2",
                "date": "2015-09-01T14:43:46Z"
            },
            {
                "name": "v1.0.1",
                "date": "2015-07-20T06:13:39Z"
            },
            {
                "name": "v1.0.0",
                "date": "2015-07-13T02:17:04Z"
            }
        ]
    }
}