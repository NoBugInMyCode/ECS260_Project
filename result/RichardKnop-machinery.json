{
    "https://api.github.com/repos/RichardKnop/machinery": {
        "forks": 925,
        "watchers": 7613,
        "stars": 7613,
        "languages": {
            "Go": 779995,
            "Shell": 4106,
            "Makefile": 1094
        },
        "commits": [
            "2024-12-26T20:24:50Z",
            "2024-12-26T20:21:29Z",
            "2024-12-26T20:18:01Z",
            "2024-12-26T20:17:08Z",
            "2024-05-22T23:37:33Z",
            "2024-05-22T23:36:40Z",
            "2024-04-08T13:51:58Z",
            "2024-03-19T09:50:30Z",
            "2024-01-10T15:13:17Z",
            "2024-01-10T15:11:50Z",
            "2023-10-12T20:40:29Z",
            "2023-10-12T20:38:37Z",
            "2023-10-12T20:38:09Z",
            "2023-10-12T20:37:13Z",
            "2023-07-04T15:42:12Z",
            "2021-12-09T16:22:25Z",
            "2021-12-09T16:21:21Z",
            "2021-09-28T19:33:33Z",
            "2021-09-28T19:32:45Z",
            "2021-08-06T15:56:29Z",
            "2021-06-21T21:15:37Z",
            "2021-06-21T18:53:42Z",
            "2021-06-12T22:25:20Z",
            "2021-04-13T15:02:55Z",
            "2021-03-31T15:17:06Z",
            "2021-03-20T13:31:35Z",
            "2021-03-08T20:59:51Z",
            "2021-02-23T01:39:50Z",
            "2021-02-23T01:30:28Z",
            "2021-02-23T01:17:49Z"
        ],
        "creation_date": "2015-04-05T19:46:34Z",
        "contributors": 30,
        "topics": [
            "amqp",
            "aws-sqs",
            "go",
            "golang",
            "memcached",
            "mongodb",
            "queue",
            "rabbitmq",
            "redis",
            "task",
            "task-scheduler"
        ],
        "subscribers": 162,
        "readme": "[1]: https://raw.githubusercontent.com/RichardKnop/assets/master/machinery/example_worker.png\n[2]: https://raw.githubusercontent.com/RichardKnop/assets/master/machinery/example_worker_receives_tasks.png\n[3]: http://patreon_public_assets.s3.amazonaws.com/sized/becomeAPatronBanner.png\n\n## Machinery\n\nMachinery is an asynchronous task queue/job queue based on distributed message passing.\n\n[![Travis Status for RichardKnop/machinery](https://travis-ci.org/RichardKnop/machinery.svg?branch=master&label=linux+build)](https://travis-ci.org/RichardKnop/machinery)\n[![godoc for RichardKnop/machinery](https://godoc.org/github.com/nathany/looper?status.svg)](http://godoc.org/github.com/RichardKnop/machinery/v1)\n[![codecov for RichardKnop/machinery](https://codecov.io/gh/RichardKnop/machinery/branch/master/graph/badge.svg)](https://codecov.io/gh/RichardKnop/machinery)\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/RichardKnop/machinery)](https://goreportcard.com/report/github.com/RichardKnop/machinery)\n[![GolangCI](https://golangci.com/badges/github.com/RichardKnop/machinery.svg)](https://golangci.com)\n[![OpenTracing Badge](https://img.shields.io/badge/OpenTracing-enabled-blue.svg)](http://opentracing.io)\n\n[![Sourcegraph for RichardKnop/machinery](https://sourcegraph.com/github.com/RichardKnop/machinery/-/badge.svg)](https://sourcegraph.com/github.com/RichardKnop/machinery?badge)\n[![Donate Bitcoin](https://img.shields.io/badge/donate-bitcoin-orange.svg)](https://richardknop.github.io/donate/)\n\n---\n\n* [V2 Experiment](#v2-experiment)\n* [First Steps](#first-steps)\n* [Configuration](#configuration)\n  * [Lock](#lock)\n  * [Broker](#broker)\n  * [DefaultQueue](#defaultqueue)\n  * [ResultBackend](#resultbackend)\n  * [ResultsExpireIn](#resultsexpirein)\n  * [AMQP](#amqp-2)\n  * [DynamoDB](#dynamodb)\n  * [Redis](#redis-2)\n  * [GCPPubSub](#gcppubsub)\n* [Custom Logger](#custom-logger)\n* [Server](#server)\n* [Workers](#workers)\n* [Tasks](#tasks)\n  * [Registering Tasks](#registering-tasks)\n  * [Signatures](#signatures)\n  * [Supported Types](#supported-types)\n  * [Sending Tasks](#sending-tasks)\n  * [Delayed Tasks](#delayed-tasks)\n  * [Retry Tasks](#retry-tasks)\n  * [Get Pending Tasks](#get-pending-tasks)\n  * [Keeping Results](#keeping-results)\n* [Workflows](#workflows)\n  * [Groups](#groups)\n  * [Chords](#chords)\n  * [Chains](#chains)\n* [Periodic Tasks & Workflows](#periodic-tasks--workflows)\n  * [Periodic Tasks](#periodic-tasks)\n  * [Periodic Groups](#periodic-groups)\n  * [Periodic Chains](#periodic-chains)\n  * [Periodic Chords](#periodic-chords)\n* [Development](#development)\n  * [Requirements](#requirements)\n  * [Dependencies](#dependencies)\n  * [Testing](#testing)\n\n### V2\n\nI recommend using V2 in order to avoid having to import all dependencies for brokers and backends you are not using.\n\nInstead of factory, you will need to inject broker and backend objects to the server constructor:\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v2\"\n  backendsiface \"github.com/RichardKnop/machinery/v2/backends/iface\"\n  brokersiface \"github.com/RichardKnop/machinery/v2/brokers/iface\"\n  locksiface \"github.com/RichardKnop/machinery/v2/locks/iface\"\n)\n\nvar broker brokersiface.Broker\nvar backend backendsiface.Backend\nvar lock locksiface.Lock\nserver := machinery.NewServer(cnf, broker, backend, lock)\n// server.NewWorker(\"machinery\", 10)\n```\n\n### First Steps\n\nTo install recommended v2 release:\n\n```sh\ngo get github.com/RichardKnop/machinery/v2\n```\n\nIf you want to use legacy v1 version, you still can:\n\n```sh\ngo get github.com/RichardKnop/machinery\n```\n\nFirst, you will need to define some tasks. Look at sample tasks in `v2/example/tasks/tasks.go` to see a few examples.\n\nSecond, you will need to launch a worker process with one of these commands (v2 is recommended since it doesn't import dependencies for all brokers / backends, only those you actually need):\n\n```sh\ncd v2/\ngo run example/amqp/main.go worker\ngo run example/redigo/main.go worker // Redis with redigo driver\ngo run example/go-redis/main.go worker // Redis with Go Redis driver\n\ngo run example/amqp/main.go worker\ngo run example/redis/main.go worker\n```\n\n![Example worker][1]\n\nFinally, once you have a worker running and waiting for tasks to consume, send some tasks with one of these commands (v2 is recommended since it doesn't import dependencies for all brokers / backends, only those you actually need):\n\n```sh\ncd v2\ngo run v2/example/amqp/main.go send\ngo run v2/example/redigo/main.go send // Redis with redigo driver\ngo run v2/example/go-redis/main.go send // Redis with Go Redis driver\n```\n\nYou will be able to see the tasks being processed asynchronously by the worker:\n\n![Example worker receives tasks][2]\n\n### Configuration\n\nThe [config](/v2/config/config.go) package has convenience methods for loading configuration from environment variables or a YAML file. For example, load configuration from environment variables:\n\n```go\ncnf, err := config.NewFromEnvironment()\n```\n\nOr load from YAML file:\n\n```go\ncnf, err := config.NewFromYaml(\"config.yml\", true)\n```\n\nSecond boolean flag enables live reloading of configuration every 10 seconds. Use `false` to disable live reloading.\n\nMachinery configuration is encapsulated by a `Config` struct and injected as a dependency to objects that need it.\n\n#### Lock\n\n##### Redis\n\nUse Redis URL in one of these formats:\n\n```\nredis://[password@]host[port][/db_num]\n```\n\nFor example:\n\n1. `redis://localhost:6379`, or with password `redis://password@localhost:6379`\n\n#### Broker\n\nA message broker. Currently supported brokers are:\n\n##### AMQP\n\nUse AMQP URL in the format:\n\n```\namqp://[username:password@]@host[:port]\n```\n\nFor example:\n\n1. `amqp://guest:guest@localhost:5672`\n\nAMQP also supports multiples brokers urls. You need to specify the URL separator in the `MultipleBrokerSeparator` field.\n\n##### Redis\n\nUse Redis URL in one of these formats:\n\n```\nredis://[password@]host[port][/db_num]\nredis+socket://[password@]/path/to/file.sock[:/db_num]\n```\n\nFor example:\n\n1. `redis://localhost:6379`, or with password `redis://password@localhost:6379`\n2. `redis+socket://password@/path/to/file.sock:/0`\n\n##### AWS SQS\n\nUse AWS SQS URL in the format:\n\n```\nhttps://sqs.us-east-2.amazonaws.com/123456789012\n```\n\nSee [AWS SQS docs](https://docs.aws.amazon.com/sdk-for-go/v1/developer-guide/configuring-sdk.html) for more information.\nAlso, configuring `AWS_REGION` is required, or an error would be thrown.\n\nTo use a manually configured SQS Client:\n\n```go\nvar sqsClient = sqs.New(session.Must(session.NewSession(&aws.Config{\n  Region:         aws.String(\"YOUR_AWS_REGION\"),\n  Credentials:    credentials.NewStaticCredentials(\"YOUR_AWS_ACCESS_KEY\", \"YOUR_AWS_ACCESS_SECRET\", \"\"),\n  HTTPClient:     &http.Client{\n    Timeout: time.Second * 120,\n  },\n})))\nvar visibilityTimeout = 20\nvar cnf = &config.Config{\n  Broker:          \"YOUR_SQS_URL\"\n  DefaultQueue:    \"machinery_tasks\",\n  ResultBackend:   \"YOUR_BACKEND_URL\",\n  SQS: &config.SQSConfig{\n    Client: sqsClient,\n    // if VisibilityTimeout is nil default to the overall visibility timeout setting for the queue\n    // https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html\n    VisibilityTimeout: &visibilityTimeout,\n    WaitTimeSeconds: 30,\n  },\n}\n```\n\n##### GCP Pub/Sub\n\nUse GCP Pub/Sub URL in the format:\n\n```\ngcppubsub://YOUR_GCP_PROJECT_ID/YOUR_PUBSUB_SUBSCRIPTION_NAME\n```\n\nTo use a manually configured Pub/Sub Client:\n\n```go\npubsubClient, err := pubsub.NewClient(\n    context.Background(),\n    \"YOUR_GCP_PROJECT_ID\",\n    option.WithServiceAccountFile(\"YOUR_GCP_SERVICE_ACCOUNT_FILE\"),\n)\n\ncnf := &config.Config{\n  Broker:          \"gcppubsub://YOUR_GCP_PROJECT_ID/YOUR_PUBSUB_SUBSCRIPTION_NAME\"\n  DefaultQueue:    \"YOUR_PUBSUB_TOPIC_NAME\",\n  ResultBackend:   \"YOUR_BACKEND_URL\",\n  GCPPubSub: config.GCPPubSubConfig{\n    Client: pubsubClient,\n  },\n}\n```\n\n#### DefaultQueue\n\nDefault queue name, e.g. `machinery_tasks`.\n\n#### ResultBackend\n\nResult backend to use for keeping task states and results.\n\nCurrently supported backends are:\n\n##### Redis\n\nUse Redis URL in one of these formats:\n\n```\nredis://[password@]host[port][/db_num]\nredis+socket://[password@]/path/to/file.sock[:/db_num]\n```\n\nFor example:\n\n1. `redis://localhost:6379`, or with password `redis://password@localhost:6379`\n2. `redis+socket://password@/path/to/file.sock:/0`\n3. cluster `redis://host1:port1,host2:port2,host3:port3`\n4. cluster with password `redis://pass@host1:port1,host2:port2,host3:port3`\n\n##### Memcache\n\nUse Memcache URL in the format:\n\n```\nmemcache://host1[:port1][,host2[:port2],...[,hostN[:portN]]]\n```\n\nFor example:\n\n1. `memcache://localhost:11211` for a single instance, or\n2. `memcache://10.0.0.1:11211,10.0.0.2:11211` for a cluster\n\n##### AMQP\n\nUse AMQP URL in the format:\n\n```\namqp://[username:password@]@host[:port]\n```\n\nFor example:\n\n1. `amqp://guest:guest@localhost:5672`\n\n> Keep in mind AMQP is not recommended as a result backend. See [Keeping Results](https://github.com/RichardKnop/machinery#keeping-results)\n\n##### MongoDB\n\nUse Mongodb URL in the format:\n\n```\nmongodb://[username:password@]host1[:port1][,host2[:port2],...[,hostN[:portN]]][/[database][?options]]\n```\n\nFor example:\n\n1. `mongodb://localhost:27017/taskresults`\n\nSee [MongoDB docs](https://docs.mongodb.org/manual/reference/connection-string/) for more information.\n\n\n#### ResultsExpireIn\n\nHow long to store task results for in seconds. Defaults to `3600` (1 hour).\n\n#### AMQP\n\nRabbitMQ related configuration. Not necessary if you are using other broker/backend.\n\n* `Exchange`: exchange name, e.g. `machinery_exchange`\n* `ExchangeType`: exchange type, e.g. `direct`\n* `QueueBindingArguments`: an optional map of additional arguments used when binding to an AMQP queue\n* `BindingKey`: The queue is bind to the exchange with this key, e.g. `machinery_task`\n* `PrefetchCount`: How many tasks to prefetch (set to `1` if you have long running tasks)\n* `DelayedQueue`: delayed queue name to be used for task retry or delayed task (if empty it will follow auto create and delate delayed queues)\n\n#### DynamoDB\n\nDynamoDB related configuration. Not necessary if you are using other backend.\n* `TaskStatesTable`: Custom table name for saving task states. Default one is `task_states`, and make sure to create this table in your AWS admin first, using `TaskUUID` as table's primary key.\n* `GroupMetasTable`: Custom table name for saving group metas. Default one is `group_metas`, and make sure to create this table in your AWS admin first, using `GroupUUID` as table's primary key.\nFor example:\n\n```\ndynamodb:\n  task_states_table: 'task_states'\n  group_metas_table: 'group_metas'\n```\nIf these tables are not found, an fatal error would be thrown.\n\nIf you wish to expire the records, you can configure the `TTL` field in AWS admin for these tables. The `TTL` field is set based on the `ResultsExpireIn` value in the Server's config. See https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/howitworks-ttl.html for more information.\n\n#### Redis\n\nRedis related configuration. Not necessary if you are using other backend.\n\nSee: [config](/v1/config/config.go) (TODO)\n\n#### GCPPubSub\n\nGCPPubSub related configuration. Not necessary if you are using other backend.\n\nSee: [config](/v1/config/config.go) (TODO)\n\n### Custom Logger\n\nYou can define a custom logger by implementing the following interface:\n\n```go\ntype Interface interface {\n  Print(...interface{})\n  Printf(string, ...interface{})\n  Println(...interface{})\n\n  Fatal(...interface{})\n  Fatalf(string, ...interface{})\n  Fatalln(...interface{})\n\n  Panic(...interface{})\n  Panicf(string, ...interface{})\n  Panicln(...interface{})\n}\n```\n\nThen just set the logger in your setup code by calling `Set` function exported by `github.com/RichardKnop/machinery/v1/log` package:\n\n```go\nlog.Set(myCustomLogger)\n```\n\n### Server\n\nA Machinery library must be instantiated before use. The way this is done is by creating a `Server` instance. `Server` is a base object which stores Machinery configuration and registered tasks. E.g.:\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/config\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nvar cnf = &config.Config{\n  Broker:        \"amqp://guest:guest@localhost:5672/\",\n  DefaultQueue:  \"machinery_tasks\",\n  ResultBackend: \"amqp://guest:guest@localhost:5672/\",\n  AMQP: &config.AMQPConfig{\n    Exchange:     \"machinery_exchange\",\n    ExchangeType: \"direct\",\n    BindingKey:   \"machinery_task\",\n  },\n}\n\nserver, err := machinery.NewServer(cnf)\nif err != nil {\n  // do something with the error\n}\n```\n\n### Workers\n\nIn order to consume tasks, you need to have one or more workers running. All you need to run a worker is a `Server` instance with registered tasks. E.g.:\n\n```go\nworker := server.NewWorker(\"worker_name\", 10)\nerr := worker.Launch()\nif err != nil {\n  // do something with the error\n}\n```\n\nEach worker will only consume registered tasks. For each task on the queue the Worker.Process() method will be run\nin a goroutine. Use the second parameter of `server.NewWorker` to limit the number of concurrently running Worker.Process()\ncalls (per worker). Example: 1 will serialize task execution while 0 makes the number of concurrently executed tasks unlimited (default).\n\n### Tasks\n\nTasks are a building block of Machinery applications. A task is a function which defines what happens when a worker receives a message.\n\nEach task needs to return an error as a last return value. In addition to error tasks can now return any number of arguments.\n\nExamples of valid tasks:\n\n```go\nfunc Add(args ...int64) (int64, error) {\n  sum := int64(0)\n  for _, arg := range args {\n    sum += arg\n  }\n  return sum, nil\n}\n\nfunc Multiply(args ...int64) (int64, error) {\n  sum := int64(1)\n  for _, arg := range args {\n    sum *= arg\n  }\n  return sum, nil\n}\n\n// You can use context.Context as first argument to tasks, useful for open tracing\nfunc TaskWithContext(ctx context.Context, arg Arg) error {\n  // ... use ctx ...\n  return nil\n}\n\n// Tasks need to return at least error as a minimal requirement\nfunc DummyTask(arg string) error {\n  return errors.New(arg)\n}\n\n// You can also return multiple results from the task\nfunc DummyTask2(arg1, arg2 string) (string, string, error) {\n  return arg1, arg2, nil\n}\n```\n\n#### Registering Tasks\n\nBefore your workers can consume a task, you need to register it with the server. This is done by assigning a task a unique name:\n\n```go\nserver.RegisterTasks(map[string]interface{}{\n  \"add\":      Add,\n  \"multiply\": Multiply,\n})\n```\n\nTasks can also be registered one by one:\n\n```go\nserver.RegisterTask(\"add\", Add)\nserver.RegisterTask(\"multiply\", Multiply)\n```\n\nSimply put, when a worker receives a message like this:\n\n```json\n{\n  \"UUID\": \"48760a1a-8576-4536-973b-da09048c2ac5\",\n  \"Name\": \"add\",\n  \"RoutingKey\": \"\",\n  \"ETA\": null,\n  \"GroupUUID\": \"\",\n  \"GroupTaskCount\": 0,\n  \"Args\": [\n    {\n      \"Type\": \"int64\",\n      \"Value\": 1,\n    },\n    {\n      \"Type\": \"int64\",\n      \"Value\": 1,\n    }\n  ],\n  \"Immutable\": false,\n  \"RetryCount\": 0,\n  \"RetryTimeout\": 0,\n  \"OnSuccess\": null,\n  \"OnError\": null,\n  \"ChordCallback\": null\n}\n```\n\nIt will call Add(1, 1). Each task should return an error as well so we can handle failures.\n\nIdeally, tasks should be idempotent which means there will be no unintended consequences when a task is called multiple times with the same arguments.\n\n#### Signatures\n\nA signature wraps calling arguments, execution options (such as immutability) and success/error callbacks of a task so it can be sent across the wire to workers. Task signatures implement a simple interface:\n\n```go\n// Arg represents a single argument passed to invocation fo a task\ntype Arg struct {\n  Type  string\n  Value interface{}\n}\n\n// Headers represents the headers which should be used to direct the task\ntype Headers map[string]interface{}\n\n// Signature represents a single task invocation\ntype Signature struct {\n  UUID           string\n  Name           string\n  RoutingKey     string\n  ETA            *time.Time\n  GroupUUID      string\n  GroupTaskCount int\n  Args           []Arg\n  Headers        Headers\n  Immutable      bool\n  RetryCount     int\n  RetryTimeout   int\n  OnSuccess      []*Signature\n  OnError        []*Signature\n  ChordCallback  *Signature\n}\n```\n\n`UUID` is a unique ID of a task. You can either set it yourself or it will be automatically generated.\n\n`Name` is the unique task name by which it is registered against a Server instance.\n\n`RoutingKey` is used for routing a task to correct queue. If you leave it empty, the default behaviour will be to set it to the default queue's binding key for direct exchange type and to the default queue name for other exchange types.\n\n`ETA` is  a timestamp used for delaying a task. if it's nil, the task will be published for workers to consume immediately. If it is set, the task will be delayed until the ETA timestamp.\n\n`GroupUUID`, `GroupTaskCount` are useful for creating groups of tasks.\n\n`Args` is a list of arguments that will be passed to the task when it is executed by a worker.\n\n`Headers` is a list of headers that will be used when publishing the task to AMQP queue.\n\n`Immutable` is a flag which defines whether a result of the executed task can be modified or not. This is important with `OnSuccess` callbacks. Immutable task will not pass its result to its success callbacks while a mutable task will prepend its result to args sent to callback tasks. Long story short, set Immutable to false if you want to pass result of the first task in a chain to the second task.\n\n`RetryCount` specifies how many times a failed task should be retried (defaults to 0). Retry attempts will be spaced out in time, after each failure another attempt will be scheduled further to the future.\n\n`RetryTimeout` specifies how long to wait before resending task to the queue for retry attempt. Default behaviour is to use fibonacci sequence to increase the timeout after each failed retry attempt.\n\n`OnSuccess` defines tasks which will be called after the task has executed successfully. It is a slice of task signature structs.\n\n`OnError` defines tasks which will be called after the task execution fails. The first argument passed to error callbacks will be the error string returned from the failed task.\n\n`ChordCallback` is used to create a callback to a group of tasks.\n\n#### Supported Types\n\nMachinery encodes tasks to JSON before sending them to the broker. Task results are also stored in the backend as JSON encoded strings. Therefor only types with native JSON representation can be supported. Currently supported types are:\n\n* `bool`\n* `int`\n* `int8`\n* `int16`\n* `int32`\n* `int64`\n* `uint`\n* `uint8`\n* `uint16`\n* `uint32`\n* `uint64`\n* `float32`\n* `float64`\n* `string`\n* `[]bool`\n* `[]int`\n* `[]int8`\n* `[]int16`\n* `[]int32`\n* `[]int64`\n* `[]uint`\n* `[]uint8`\n* `[]uint16`\n* `[]uint32`\n* `[]uint64`\n* `[]float32`\n* `[]float64`\n* `[]string`\n\n#### Sending Tasks\n\nTasks can be called by passing an instance of `Signature` to an `Server` instance. E.g:\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n)\n\nsignature := &tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nasyncResult, err := server.SendTask(signature)\nif err != nil {\n  // failed to send the task\n  // do something with the error\n}\n```\n\n#### Delayed Tasks\n\nYou can delay a task by setting the `ETA` timestamp field on the task signature.\n\n```go\n// Delay the task by 5 seconds\neta := time.Now().UTC().Add(time.Second * 5)\nsignature.ETA = &eta\n```\n\n#### Retry Tasks\n\nYou can set a number of retry attempts before declaring task as failed. Fibonacci sequence will be used to space out retry requests over time. (See `RetryTimeout` for details.)\n\n```go\n// If the task fails, retry it up to 3 times\nsignature.RetryCount = 3\n```\n\nAlternatively, you can return `tasks.ErrRetryTaskLater` from your task and specify duration after which the task should be retried, e.g.:\n\n```go\nreturn tasks.NewErrRetryTaskLater(\"some error\", 4 * time.Hour)\n```\n\n#### Get Pending Tasks\n\nTasks currently waiting in the queue to be consumed by workers can be inspected, e.g.:\n\n```go\nserver.GetBroker().GetPendingTasks(\"some_queue\")\n```\n\n> Currently only supported by Redis broker.\n\n#### Keeping Results\n\nIf you configure a result backend, the task states and results will be persisted. Possible states:\n\n```go\nconst (\n\t// StatePending - initial state of a task\n\tStatePending = \"PENDING\"\n\t// StateReceived - when task is received by a worker\n\tStateReceived = \"RECEIVED\"\n\t// StateStarted - when the worker starts processing the task\n\tStateStarted = \"STARTED\"\n\t// StateRetry - when failed task has been scheduled for retry\n\tStateRetry = \"RETRY\"\n\t// StateSuccess - when the task is processed successfully\n\tStateSuccess = \"SUCCESS\"\n\t// StateFailure - when processing of the task fails\n\tStateFailure = \"FAILURE\"\n)\n```\n\n> When using AMQP as a result backend, task states will be persisted in separate queues for each task. Although RabbitMQ can scale up to thousands of queues, it is strongly advised to use a better suited result backend (e.g. Memcache) when you are expecting to run a large number of parallel tasks.\n\n```go\n// TaskResult represents an actual return value of a processed task\ntype TaskResult struct {\n  Type  string      `bson:\"type\"`\n  Value interface{} `bson:\"value\"`\n}\n\n// TaskState represents a state of a task\ntype TaskState struct {\n  TaskUUID  string        `bson:\"_id\"`\n  State     string        `bson:\"state\"`\n  Results   []*TaskResult `bson:\"results\"`\n  Error     string        `bson:\"error\"`\n}\n\n// GroupMeta stores useful metadata about tasks within the same group\n// E.g. UUIDs of all tasks which are used in order to check if all tasks\n// completed successfully or not and thus whether to trigger chord callback\ntype GroupMeta struct {\n  GroupUUID      string   `bson:\"_id\"`\n  TaskUUIDs      []string `bson:\"task_uuids\"`\n  ChordTriggered bool     `bson:\"chord_triggered\"`\n  Lock           bool     `bson:\"lock\"`\n}\n```\n\n`TaskResult` represents a slice of return values of a processed task.\n\n`TaskState` struct will be serialized and stored every time a task state changes.\n\n`GroupMeta` stores useful metadata about tasks within the same group. E.g. UUIDs of all tasks which are used in order to check if all tasks completed successfully or not and thus whether to trigger chord callback.\n\n`AsyncResult` object allows you to check for the state of a task:\n\n```go\ntaskState := asyncResult.GetState()\nfmt.Printf(\"Current state of %v task is:\\n\", taskState.TaskUUID)\nfmt.Println(taskState.State)\n```\n\nThere are couple of convenient methods to inspect the task status:\n\n```go\nasyncResult.GetState().IsCompleted()\nasyncResult.GetState().IsSuccess()\nasyncResult.GetState().IsFailure()\n```\n\nYou can also do a synchronous blocking call to wait for a task result:\n\n```go\nresults, err := asyncResult.Get(time.Duration(time.Millisecond * 5))\nif err != nil {\n  // getting result of a task failed\n  // do something with the error\n}\nfor _, result := range results {\n  fmt.Println(result.Interface())\n}\n```\n\n#### Error Handling\n\nWhen a task returns with an error, the default behavior is to first attempty to retry the task if it's retriable, otherwise log the error and then eventually call any error callbacks.\n\nTo customize this, you can set a custom error handler on the worker which can do more than just logging after retries fail and error callbacks are trigerred:\n\n```go\nworker.SetErrorHandler(func (err error) {\n  customHandler(err)\n})\n```\n\n### Workflows\n\nRunning a single asynchronous task is fine but often you will want to design a workflow of tasks to be executed in an orchestrated way. There are couple of useful functions to help you design workflows.\n\n#### Groups\n\n`Group` is a set of tasks which will be executed in parallel, independent of each other. E.g.:\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nsignature1 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nsignature2 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n  },\n}\n\ngroup, _ := tasks.NewGroup(&signature1, &signature2)\nasyncResults, err := server.SendGroup(group, 0) //The second parameter specifies the number of concurrent sending tasks. 0 means unlimited.\nif err != nil {\n  // failed to send the group\n  // do something with the error\n}\n```\n\n`SendGroup` returns a slice of `AsyncResult` objects. So you can do a blocking call and wait for the result of groups tasks:\n\n```go\nfor _, asyncResult := range asyncResults {\n  results, err := asyncResult.Get(time.Duration(time.Millisecond * 5))\n  if err != nil {\n    // getting result of a task failed\n    // do something with the error\n  }\n  for _, result := range results {\n    fmt.Println(result.Interface())\n  }\n}\n```\n\n#### Chords\n\n`Chord` allows you to define a callback to be executed after all tasks in a group finished processing, e.g.:\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nsignature1 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nsignature2 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n  },\n}\n\nsignature3 := tasks.Signature{\n  Name: \"multiply\",\n}\n\ngroup := tasks.NewGroup(&signature1, &signature2)\nchord, _ := tasks.NewChord(group, &signature3)\nchordAsyncResult, err := server.SendChord(chord, 0) //The second parameter specifies the number of concurrent sending tasks. 0 means unlimited.\nif err != nil {\n  // failed to send the chord\n  // do something with the error\n}\n```\n\nThe above example executes task1 and task2 in parallel, aggregates their results and passes them to task3. Therefore what would end up happening is:\n\n```\nmultiply(add(1, 1), add(5, 5))\n```\n\nMore explicitly:\n\n```\n(1 + 1) * (5 + 5) = 2 * 10 = 20\n```\n\n`SendChord` returns `ChordAsyncResult` which follows AsyncResult's interface. So you can do a blocking call and wait for the result of the callback:\n\n```go\nresults, err := chordAsyncResult.Get(time.Duration(time.Millisecond * 5))\nif err != nil {\n  // getting result of a chord failed\n  // do something with the error\n}\nfor _, result := range results {\n  fmt.Println(result.Interface())\n}\n```\n\n#### Chains\n\n`Chain` is simply a set of tasks which will be executed one by one, each successful task triggering the next task in the chain. E.g.:\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nsignature1 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nsignature2 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n  },\n}\n\nsignature3 := tasks.Signature{\n  Name: \"multiply\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 4,\n    },\n  },\n}\n\nchain, _ := tasks.NewChain(&signature1, &signature2, &signature3)\nchainAsyncResult, err := server.SendChain(chain)\nif err != nil {\n  // failed to send the chain\n  // do something with the error\n}\n```\n\nThe above example executes task1, then task2 and then task3. When a task is completed successfully, the result is appended to the end of list of arguments for the next task in the chain. Therefore what would end up happening is:\n\n```\nmultiply(4, add(5, 5, add(1, 1)))\n```\n\nMore explicitly:\n\n```\n  4 * (5 + 5 + (1 + 1))   # task1: add(1, 1)        returns 2\n= 4 * (5 + 5 + 2)         # task2: add(5, 5, 2)     returns 12\n= 4 * (12)                # task3: multiply(4, 12)  returns 48\n= 48\n```\n\n`SendChain` returns `ChainAsyncResult` which follows AsyncResult's interface. So you can do a blocking call and wait for the result of the whole chain:\n\n```go\nresults, err := chainAsyncResult.Get(time.Duration(time.Millisecond * 5))\nif err != nil {\n  // getting result of a chain failed\n  // do something with the error\n}\nfor _, result := range results {\n  fmt.Println(result.Interface())\n}\n```\n\n### Periodic Tasks & Workflows\n\nMachinery now supports scheduling periodic tasks and workflows. See examples bellow.\n\n#### Periodic Tasks\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n)\n\nsignature := &tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\nerr := server.RegisterPeriodicTask(\"0 6 * * ?\", \"periodic-task\", signature)\nif err != nil {\n  // failed to register periodic task\n}\n```\n\n#### Periodic Groups\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nsignature1 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nsignature2 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n  },\n}\n\ngroup, _ := tasks.NewGroup(&signature1, &signature2)\nerr := server.RegisterPeriodicGroup(\"0 6 * * ?\", \"periodic-group\", group)\nif err != nil {\n  // failed to register periodic group\n}\n```\n\n#### Periodic Chains\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nsignature1 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nsignature2 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n  },\n}\n\nsignature3 := tasks.Signature{\n  Name: \"multiply\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 4,\n    },\n  },\n}\n\nchain, _ := tasks.NewChain(&signature1, &signature2, &signature3)\nerr := server.RegisterPeriodicChain(\"0 6 * * ?\", \"periodic-chain\", chain)\nif err != nil {\n  // failed to register periodic chain\n}\n```\n\n#### Chord\n\n```go\nimport (\n  \"github.com/RichardKnop/machinery/v1/tasks\"\n  \"github.com/RichardKnop/machinery/v1\"\n)\n\nsignature1 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n    {\n      Type:  \"int64\",\n      Value: 1,\n    },\n  },\n}\n\nsignature2 := tasks.Signature{\n  Name: \"add\",\n  Args: []tasks.Arg{\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n    {\n      Type:  \"int64\",\n      Value: 5,\n    },\n  },\n}\n\nsignature3 := tasks.Signature{\n  Name: \"multiply\",\n}\n\ngroup := tasks.NewGroup(&signature1, &signature2)\nchord, _ := tasks.NewChord(group, &signature3)\nerr := server.RegisterPeriodicChord(\"0 6 * * ?\", \"periodic-chord\", chord)\nif err != nil {\n  // failed to register periodic chord\n}\n```\n\n### Development\n\n#### Requirements\n\n* Go\n* RabbitMQ (optional)\n* Redis\n* Memcached (optional)\n* MongoDB (optional)\n\nOn OS X systems, you can install requirements using [Homebrew](http://brew.sh/):\n\n```sh\nbrew install go\nbrew install rabbitmq\nbrew install redis\nbrew install memcached\nbrew install mongodb\n```\n\nOr optionally use the corresponding [Docker](http://docker.io/) containers:\n\n```\ndocker run -d -p 5672:5672 rabbitmq\ndocker run -d -p 6379:6379 redis\ndocker run -d -p 11211:11211 memcached\ndocker run -d -p 27017:27017 mongo\ndocker run -d -p 6831:6831/udp -p 16686:16686 jaegertracing/all-in-one:latest\n```\n\n#### Dependencies\n\nSince Go 1.11, a new recommended dependency management system is via [modules](https://github.com/golang/go/wiki/Modules).\n\nThis is one of slight weaknesses of Go as dependency management is not a solved problem. Previously Go was officially recommending to use the [dep tool](https://github.com/golang/dep) but that has been abandoned now in favor of modules.\n\n#### Testing\n\nEasiest (and platform agnostic) way to run tests is via `docker-compose`:\n\n```sh\nmake ci\n```\n\nThis will basically run docker-compose command:\n\n```sh\n(docker-compose -f docker-compose.test.yml -p machinery_ci up --build -d) && (docker logs -f machinery_sut &) && (docker wait machinery_sut)\n```\n\nAlternative approach is to setup a development environment on your machine.\n\nIn order to enable integration tests, you will need to install all required services (RabbitMQ, Redis, Memcache, MongoDB) and export these environment variables:\n\n```sh\nexport AMQP_URL=amqp://guest:guest@localhost:5672/\nexport REDIS_URL=localhost:6379\nexport MEMCACHE_URL=localhost:11211\nexport MONGODB_URL=localhost:27017\n```\n\nTo run integration tests against an SQS instance, you will need to create a \"test_queue\" in SQS and export these environment variables:\n\n```sh\nexport SQS_URL=https://YOUR_SQS_URL\nexport AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID\nexport AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY\nexport AWS_DEFAULT_REGION=YOUR_AWS_DEFAULT_REGION\n```\n\nThen just run:\n\n```sh\nmake test\n```\n\nIf the environment variables are not exported, `make test` will only run unit tests.\n",
        "releases": [
            {
                "name": "v2.0.13",
                "date": "2024-03-19T09:53:10Z"
            },
            {
                "name": "v1.10.8",
                "date": "2024-03-19T09:52:54Z"
            },
            {
                "name": "v2.0.12",
                "date": "2024-03-19T09:25:23Z"
            },
            {
                "name": "v1.10.7",
                "date": "2024-03-19T09:24:56Z"
            },
            {
                "name": "Release v2.0.11",
                "date": "2021-06-05T19:54:52Z"
            },
            {
                "name": "Release v1.10.6",
                "date": "2021-06-05T19:53:56Z"
            },
            {
                "name": "Release v2.0.10",
                "date": "2021-02-23T01:32:54Z"
            },
            {
                "name": "Release v1.10.5",
                "date": "2021-02-23T01:19:15Z"
            },
            {
                "name": "Release v1.10.4",
                "date": "2021-02-23T00:43:53Z"
            },
            {
                "name": "Release v1.10.3",
                "date": "2021-02-14T14:53:35Z"
            },
            {
                "name": "Release v1.10.2",
                "date": "2021-02-05T18:54:35Z"
            },
            {
                "name": "Release v1.10.1",
                "date": "2021-02-02T18:10:05Z"
            },
            {
                "name": "Release v1.10.0",
                "date": "2020-12-04T18:39:05Z"
            },
            {
                "name": "Release v1.9.9",
                "date": "2020-11-23T21:04:26Z"
            },
            {
                "name": "Release v1.9.8",
                "date": "2020-11-21T21:07:32Z"
            },
            {
                "name": "Release v1.9.7",
                "date": "2020-11-14T12:53:03Z"
            },
            {
                "name": "Release v1.9.6",
                "date": "2020-11-05T23:39:06Z"
            },
            {
                "name": "Release v1.9.5",
                "date": "2020-10-23T13:44:24Z"
            },
            {
                "name": "Release v1.9.4",
                "date": "2020-10-18T01:51:09Z"
            },
            {
                "name": "Release v1.9.3",
                "date": "2020-10-18T01:50:29Z"
            },
            {
                "name": "Release v1.9.2",
                "date": "2020-09-07T19:34:26Z"
            },
            {
                "name": "Release v1.9.1",
                "date": "2020-07-16T13:07:18Z"
            },
            {
                "name": "Release v1.9.0",
                "date": "2020-07-16T09:14:35Z"
            },
            {
                "name": "Release v1.8.9",
                "date": "2020-07-15T13:37:47Z"
            },
            {
                "name": "Release v1.8.8",
                "date": "2020-07-13T17:15:49Z"
            },
            {
                "name": "Release v1.8.7",
                "date": "2020-06-30T18:23:13Z"
            },
            {
                "name": "Release v1.8.6",
                "date": "2020-06-13T19:28:04Z"
            },
            {
                "name": "Release v1.8.5",
                "date": "2020-06-01T10:32:37Z"
            },
            {
                "name": "Release v1.8.4",
                "date": "2020-05-25T20:56:13Z"
            },
            {
                "name": "Release v1.8.3",
                "date": "2020-05-25T20:55:24Z"
            },
            {
                "name": "Release v1.8.2",
                "date": "2020-05-19T15:21:07Z"
            },
            {
                "name": "Release v1.8.1",
                "date": "2020-05-18T10:20:56Z"
            },
            {
                "name": "Release v1.8.0",
                "date": "2020-05-12T17:44:40Z"
            },
            {
                "name": "Release v1.7.9",
                "date": "2020-05-11T10:22:04Z"
            },
            {
                "name": "Release v1.7.8",
                "date": "2020-05-05T15:58:49Z"
            },
            {
                "name": "Release v1.7.7",
                "date": "2020-05-04T19:59:42Z"
            },
            {
                "name": "Release v1.7.6",
                "date": "2020-04-22T22:30:36Z"
            },
            {
                "name": "Release v1.7.5",
                "date": "2020-04-21T00:33:23Z"
            },
            {
                "name": "Release v1.7.4",
                "date": "2020-03-04T13:56:44Z"
            },
            {
                "name": "Release v1.7.3",
                "date": "2019-12-31T14:31:43Z"
            },
            {
                "name": "Release v1.7.2",
                "date": "2019-12-17T14:50:41Z"
            },
            {
                "name": "Release v1.7.1",
                "date": "2019-10-30T12:31:55Z"
            },
            {
                "name": "Release v1.7.0",
                "date": "2019-10-11T12:38:03Z"
            },
            {
                "name": "Release v1.6.9",
                "date": "2019-09-09T13:33:56Z"
            },
            {
                "name": "Release v1.6.8",
                "date": "2019-08-13T09:36:51Z"
            },
            {
                "name": "Release v1.6.7",
                "date": "2019-07-12T11:28:23Z"
            },
            {
                "name": "Release v1.6.6",
                "date": "2019-07-12T10:40:29Z"
            },
            {
                "name": "Release v1.6.5",
                "date": "2019-06-11T14:46:05Z"
            },
            {
                "name": "Release v1.6.4",
                "date": "2019-05-21T12:20:17Z"
            },
            {
                "name": "Release v1.6.3",
                "date": "2019-05-19T15:34:32Z"
            },
            {
                "name": "Release v1.6.2",
                "date": "2019-04-15T09:25:15Z"
            },
            {
                "name": "Release v1.6.1",
                "date": "2019-04-07T22:49:33Z"
            },
            {
                "name": "Release v1.6.0",
                "date": "2019-03-20T14:05:49Z"
            },
            {
                "name": "Release v1.5.9",
                "date": "2019-03-15T14:11:18Z"
            },
            {
                "name": "Release v1.5.8",
                "date": "2019-03-08T16:52:25Z"
            },
            {
                "name": "Release v1.5.7",
                "date": "2019-03-01T17:32:12Z"
            },
            {
                "name": "Release v1.5.6",
                "date": "2019-02-19T17:44:09Z"
            },
            {
                "name": "Release v1.5.5",
                "date": "2019-01-10T21:32:07Z"
            },
            {
                "name": "Release v1.5.4",
                "date": "2018-12-15T18:28:53Z"
            },
            {
                "name": "Release v1.5.3",
                "date": "2018-11-22T03:39:12Z"
            },
            {
                "name": "Release v1.5.2",
                "date": "2018-11-21T10:34:10Z"
            },
            {
                "name": "Release v1.5.1",
                "date": "2018-11-05T07:02:28Z"
            },
            {
                "name": "Release v1.5.0",
                "date": "2018-11-01T04:01:24Z"
            },
            {
                "name": "Release v1.4.9",
                "date": "2018-10-18T10:43:38Z"
            },
            {
                "name": "Release v1.4.8",
                "date": "2018-10-07T15:09:45Z"
            },
            {
                "name": "Release v1.4.7",
                "date": "2018-10-07T10:36:17Z"
            },
            {
                "name": "Release v1.4.6",
                "date": "2018-10-07T10:29:01Z"
            },
            {
                "name": "Release v1.4.5",
                "date": "2018-09-24T08:48:46Z"
            },
            {
                "name": "Release v1.4.4",
                "date": "2018-09-08T14:43:38Z"
            },
            {
                "name": "Release v1.4.3",
                "date": "2018-08-23T08:45:17Z"
            },
            {
                "name": "Release v1.4.2",
                "date": "2018-08-04T15:52:19Z"
            },
            {
                "name": "Release v1.4.1",
                "date": "2018-07-12T15:24:10Z"
            },
            {
                "name": "Release v1.4",
                "date": "2018-06-22T02:37:36Z"
            },
            {
                "name": "Release v1.3.6",
                "date": "2018-05-26T09:12:24Z"
            },
            {
                "name": "Release v1.3.5",
                "date": "2018-05-04T02:16:11Z"
            },
            {
                "name": "Release v1.3.4",
                "date": "2018-04-30T07:58:52Z"
            },
            {
                "name": "Release v1.3.3",
                "date": "2018-04-29T13:15:01Z"
            },
            {
                "name": "Release v1.3.2",
                "date": "2018-04-22T03:06:22Z"
            },
            {
                "name": "Release v1.3.1",
                "date": "2018-04-05T13:42:55Z"
            },
            {
                "name": "Release v1.3",
                "date": "2018-03-20T15:45:50Z"
            },
            {
                "name": "Release v1.2.2",
                "date": "2018-03-04T15:36:38Z"
            },
            {
                "name": "Release v1.2.1",
                "date": "2018-03-01T15:19:36Z"
            },
            {
                "name": "Release v1.2",
                "date": "2018-02-23T03:54:58Z"
            },
            {
                "name": "Fixed Config Loading Bug",
                "date": "2017-12-28T19:58:27Z"
            },
            {
                "name": "AWS SQS Improvements",
                "date": "2017-12-21T06:54:15Z"
            },
            {
                "name": "Added Support for AWS SQS Broker",
                "date": "2017-12-20T07:05:08Z"
            },
            {
                "name": "Fixed AdjustRoutingKey Bug With Redis Broker",
                "date": "2017-12-05T15:29:54Z"
            },
            {
                "name": "Ack Task After Processing",
                "date": "2017-12-04T13:49:02Z"
            },
            {
                "name": "Redis Delayed Task Gix",
                "date": "2017-12-04T06:24:32Z"
            },
            {
                "name": "Config Creation Refactoring",
                "date": "2017-11-21T08:34:38Z"
            },
            {
                "name": "Add a non blocking LaunchAsync method to worker",
                "date": "2017-11-15T08:44:15Z"
            },
            {
                "name": "Improved Ctrl+C Handling",
                "date": "2017-11-14T10:47:59Z"
            },
            {
                "name": "Wait For Tasks To Finish When Quitting",
                "date": "2017-11-11T13:13:36Z"
            },
            {
                "name": "Updated Dependencies",
                "date": "2017-11-01T08:37:34Z"
            },
            {
                "name": "Travis CI gometalinter bugfix",
                "date": "2017-11-01T08:02:02Z"
            },
            {
                "name": "Return Arguments Are Now Appended To Success Callbacks",
                "date": "2017-11-01T07:27:01Z"
            },
            {
                "name": "MongoDB Backend Improvement",
                "date": "2017-10-05T13:42:09Z"
            },
            {
                "name": "SendGroup Error Channel Size Fix",
                "date": "2017-09-07T16:21:00Z"
            },
            {
                "name": "SendGroup Concurrency Fix",
                "date": "2017-09-05T16:21:36Z"
            },
            {
                "name": "Release v1.0.1",
                "date": "2017-08-28T21:58:39Z"
            },
            {
                "name": "Initial Release",
                "date": "2017-08-27T00:41:14Z"
            }
        ]
    }
}