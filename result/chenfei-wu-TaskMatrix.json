{
    "https://api.github.com/repos/microsoft/TaskMatrix": {
        "forks": 3307,
        "watchers": 34539,
        "stars": 34539,
        "languages": {
            "Python": 97167,
            "HTML": 22957,
            "Dockerfile": 396
        },
        "commits": [
            "2023-06-29T08:44:29Z",
            "2023-06-29T08:44:03Z",
            "2023-05-31T05:32:09Z",
            "2023-05-29T13:08:22Z",
            "2023-05-25T06:04:33Z",
            "2023-05-25T05:58:54Z",
            "2023-05-25T05:57:59Z",
            "2023-05-24T10:30:24Z",
            "2023-05-24T10:22:09Z",
            "2023-05-24T10:20:22Z",
            "2023-05-22T07:59:26Z",
            "2023-05-22T07:58:56Z",
            "2023-05-19T05:29:14Z",
            "2023-05-17T09:05:38Z",
            "2023-04-26T02:10:00Z",
            "2023-04-25T13:10:50Z",
            "2023-04-24T11:37:10Z",
            "2023-04-24T11:32:52Z",
            "2023-04-23T02:54:59Z",
            "2023-04-20T09:39:21Z",
            "2023-04-20T09:38:45Z",
            "2023-04-20T09:37:44Z",
            "2023-04-19T23:54:38Z",
            "2023-04-19T08:00:38Z",
            "2023-04-19T05:18:02Z",
            "2023-04-19T03:52:38Z",
            "2023-04-17T11:56:21Z",
            "2023-04-17T11:16:01Z",
            "2023-04-17T08:08:48Z",
            "2023-04-17T07:28:37Z"
        ],
        "creation_date": "2023-03-02T09:04:28Z",
        "contributors": 15,
        "topics": [],
        "subscribers": 302,
        "readme": "# TaskMatrix\n\n**TaskMatrix** connects ChatGPT and a series of Visual Foundation Models to enable **sending** and **receiving** images during chatting.\n\nSee our paper: [<font size=5>Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models</font>](https://arxiv.org/abs/2303.04671)\n\n<a src=\"https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue\" href=\"https://huggingface.co/spaces/microsoft/visual_chatgpt\">\n    <img src=\"https://img.shields.io/badge/%F0%9F%A4%97-Open%20in%20Spaces-blue\" alt=\"Open in Spaces\">\n</a>\n\n<a src=\"https://colab.research.google.com/assets/colab-badge.svg\" href=\"https://colab.research.google.com/drive/1P3jJqKEWEaeNcZg8fODbbWeQ3gxOHk2-?usp=sharing\">\n    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\">\n</a>\n\n## Updates:\n- Now TaskMatrix supports [GroundingDINO](https://github.com/IDEA-Research/GroundingDINO) and [segment-anything](https://github.com/facebookresearch/segment-anything)! Thanks **@jordddan** for his efforts. For the image editing case, `GroundingDINO` is first used to locate bounding boxes guided by given text, then `segment-anything` is used to generate the related mask, and finally stable diffusion inpainting is used to edit image based on the mask. \n    - Firstly, run `python visual_chatgpt.py --load \"Text2Box_cuda:0,Segmenting_cuda:0,Inpainting_cuda:0,ImageCaptioning_cuda:0\"`\n    - Then, say `find xxx in the image` or `segment xxx in the image`. `xxx` is an object. TaskMatrix will return the detection or segmentation result!\n\n\n- Now TaskMatrix can support Chinese! Thanks to **@Wang-Xiaodong1899** for his efforts.\n- We propose the **template** idea in TaskMatrix!\n    - A template is a **pre-defined execution flow** that assists ChatGPT in assembling complex tasks involving multiple foundation models. \n    - A template contains the **experiential solution** to complex tasks as determined by humans. \n    - A template can **invoke multiple foundation models** or even **establish a new ChatGPT session**\n    - To define a **template**, simply adding a class with attributes `template_model = True`\n- Thanks to **@ShengmingYin** and **@thebestannie** for providing a template example in `InfinityOutPainting` class (see the following gif)\n    - Firstly, run `python visual_chatgpt.py --load \"Inpainting_cuda:0,ImageCaptioning_cuda:0,VisualQuestionAnswering_cuda:0\"`\n    - Secondly, say `extend the image to 2048x1024` to TaskMatrix!\n    - By simply creating an `InfinityOutPainting` template, TaskMatrix can seamlessly extend images to any size through collaboration with existing `ImageCaptioning`, `Inpainting`, and `VisualQuestionAnswering` foundation models, **without the need for additional training**.\n- **TaskMatrix needs the effort of the community! We crave your contribution to add new and interesting features!**\n<img src=\"./assets/demo_inf.gif\" width=\"750\">\n\n\n## Insight & Goal:\nOn the one hand, **ChatGPT (or LLMs)** serves as a **general interface** that provides a broad and diverse understanding of a\nwide range of topics. On the other hand, **Foundation Models** serve as **domain experts** by providing deep knowledge in specific domains.\nBy leveraging **both general and deep knowledge**, we aim at building an AI that is capable of handling various tasks.\n\n\n## Demo \n<img src=\"./assets/demo_short.gif\" width=\"750\">\n\n##  System Architecture \n\n \n<p align=\"center\"><img src=\"./assets/figure.jpg\" alt=\"Logo\"></p>\n\n\n## Quick Start\n\n```\n# clone the repo\ngit clone https://github.com/microsoft/TaskMatrix.git\n\n# Go to directory\ncd visual-chatgpt\n\n# create a new environment\nconda create -n visgpt python=3.8\n\n# activate the new environment\nconda activate visgpt\n\n#  prepare the basic environments\npip install -r requirements.txt\npip install  git+https://github.com/IDEA-Research/GroundingDINO.git\npip install  git+https://github.com/facebookresearch/segment-anything.git\n\n# prepare your private OpenAI key (for Linux)\nexport OPENAI_API_KEY={Your_Private_Openai_Key}\n\n# prepare your private OpenAI key (for Windows)\nset OPENAI_API_KEY={Your_Private_Openai_Key}\n\n# Start TaskMatrix !\n# You can specify the GPU/CPU assignment by \"--load\", the parameter indicates which \n# Visual Foundation Model to use and where it will be loaded to\n# The model and device are separated by underline '_', the different models are separated by comma ','\n# The available Visual Foundation Models can be found in the following table\n# For example, if you want to load ImageCaptioning to cpu and Text2Image to cuda:0\n# You can use: \"ImageCaptioning_cpu,Text2Image_cuda:0\"\n\n# Advice for CPU Users\npython visual_chatgpt.py --load ImageCaptioning_cpu,Text2Image_cpu\n\n# Advice for 1 Tesla T4 15GB  (Google Colab)                       \npython visual_chatgpt.py --load \"ImageCaptioning_cuda:0,Text2Image_cuda:0\"\n                                \n# Advice for 4 Tesla V100 32GB                            \npython visual_chatgpt.py --load \"Text2Box_cuda:0,Segmenting_cuda:0,\n    Inpainting_cuda:0,ImageCaptioning_cuda:0,\n    Text2Image_cuda:1,Image2Canny_cpu,CannyText2Image_cuda:1,\n    Image2Depth_cpu,DepthText2Image_cuda:1,VisualQuestionAnswering_cuda:2,\n    InstructPix2Pix_cuda:2,Image2Scribble_cpu,ScribbleText2Image_cuda:2,\n    SegText2Image_cuda:2,Image2Pose_cpu,PoseText2Image_cuda:2,\n    Image2Hed_cpu,HedText2Image_cuda:3,Image2Normal_cpu,\n    NormalText2Image_cuda:3,Image2Line_cpu,LineText2Image_cuda:3\"\n\n```\n\n## GPU memory usage\nHere we list the GPU memory usage of each visual foundation model, you can specify which one you like:\n\n| Foundation Model        | GPU Memory (MB) |\n|------------------------|-----------------|\n| ImageEditing           | 3981            |\n| InstructPix2Pix        | 2827            |\n| Text2Image             | 3385            |\n| ImageCaptioning        | 1209            |\n| Image2Canny            | 0               |\n| CannyText2Image        | 3531            |\n| Image2Line             | 0               |\n| LineText2Image         | 3529            |\n| Image2Hed              | 0               |\n| HedText2Image          | 3529            |\n| Image2Scribble         | 0               |\n| ScribbleText2Image     | 3531            |\n| Image2Pose             | 0               |\n| PoseText2Image         | 3529            |\n| Image2Seg              | 919             |\n| SegText2Image          | 3529            |\n| Image2Depth            | 0               |\n| DepthText2Image        | 3531            |\n| Image2Normal           | 0               |\n| NormalText2Image       | 3529            |\n| VisualQuestionAnswering| 1495            |\n\n## Acknowledgement\nWe appreciate the open source of the following projects:\n\n[Hugging Face](https://github.com/huggingface) &#8194;\n[LangChain](https://github.com/hwchase17/langchain) &#8194;\n[Stable Diffusion](https://github.com/CompVis/stable-diffusion) &#8194; \n[ControlNet](https://github.com/lllyasviel/ControlNet) &#8194; \n[InstructPix2Pix](https://github.com/timothybrooks/instruct-pix2pix) &#8194; \n[CLIPSeg](https://github.com/timojl/clipseg) &#8194;\n[BLIP](https://github.com/salesforce/BLIP) &#8194;\n\n## Contact Information\nFor help or issues using the TaskMatrix, please submit a GitHub issue.\n\nFor other communications, please contact Chenfei WU (chewu@microsoft.com) or Nan DUAN (nanduan@microsoft.com).\n\n## Trademark Notice\n\nTrademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft\u2019s Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party\u2019s policies.\n\n## Disclaimer\nThe recommended models in this Repo are just examples, used for scientific research exploring the concept of task automation and benchmarking with the paper published at [Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models](https://arxiv.org/abs/2303.04671). Users can replace the models in this Repo according to their research needs. When using the recommended models in this Repo, you need to comply with the licenses of these models respectively. Microsoft shall not be held liable for any infringement of third-party rights resulting from your usage of this repo. Users agree to defend, indemnify and hold Microsoft harmless from and against all damages, costs, and attorneys' fees in connection with any claims arising from this Repo. If anyone believes that this Repo infringes on your rights, please notify the project owner [email](chewu@microsoft.com).\n",
        "releases": []
    }
}