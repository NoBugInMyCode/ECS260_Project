{
    "https://api.github.com/repos/alibaba/MNN": {
        "forks": 1698,
        "watchers": 8939,
        "stars": 8939,
        "languages": {
            "C++": 98442726,
            "C": 2770348,
            "Assembly": 1649384,
            "Python": 1177046,
            "Cuda": 1106653,
            "Objective-C++": 352903,
            "CMake": 160815,
            "Shell": 117997,
            "Metal": 107284,
            "Java": 90626,
            "GLSL": 39726,
            "PowerShell": 31030,
            "Objective-C": 8868,
            "Ruby": 8456,
            "Swift": 5265,
            "Batchfile": 1148,
            "Dockerfile": 902
        },
        "commits": [
            "2025-01-22T10:46:40Z",
            "2025-01-22T06:47:50Z",
            "2025-01-21T01:09:00Z",
            "2025-01-20T12:41:42Z",
            "2025-01-13T01:29:35Z",
            "2025-01-10T12:53:29Z",
            "2025-01-03T12:17:25Z",
            "2025-01-03T10:42:00Z",
            "2025-01-02T08:06:06Z",
            "2025-01-01T02:42:53Z",
            "2025-01-01T02:22:13Z",
            "2024-12-31T09:20:33Z",
            "2024-12-31T08:05:48Z",
            "2024-12-31T08:03:13Z",
            "2024-12-31T07:36:20Z",
            "2024-12-31T07:34:08Z",
            "2024-12-30T01:13:43Z",
            "2024-12-30T01:07:21Z",
            "2024-12-23T07:59:05Z",
            "2024-12-23T07:31:02Z",
            "2024-12-22T10:06:25Z",
            "2024-12-22T09:45:01Z",
            "2024-12-20T09:18:13Z",
            "2024-12-20T08:25:31Z",
            "2024-12-20T04:01:22Z",
            "2024-12-20T06:31:50Z",
            "2024-12-20T03:14:30Z",
            "2024-12-19T12:58:57Z",
            "2024-12-12T06:03:02Z",
            "2024-12-19T08:20:00Z"
        ],
        "creation_date": "2019-04-15T07:40:18Z",
        "contributors": 30,
        "topics": [
            "arm",
            "convolution",
            "deep-learning",
            "deep-neural-networks",
            "embedded-devices",
            "machine-learning",
            "ml",
            "mnn",
            "vulkan",
            "winograd-algorithm"
        ],
        "subscribers": 198,
        "readme": "![MNN](doc/banner.png)\n\n[\u4e2d\u6587\u7248\u672c](README_CN.md)\n\n[MNN Homepage](http://www.mnn.zone)\n\n## Intro\nMNN is a highly efficient and lightweight deep learning framework. It supports inference and training of deep learning models and has industry-leading performance for inference and training on-device. At present, MNN has been integrated into more than 30 apps of Alibaba Inc, such as Taobao, Tmall, Youku, DingTalk, Xianyu, etc., covering more than 70 usage scenarios such as live broadcast, short video capture, search recommendation, product searching by image, interactive marketing, equity distribution, security risk control. In addition, MNN is also used on embedded devices, such as IoT.\n\n[MNN-LLM](https://github.com/alibaba/MNN/tree/master/transformers/llm) is a large language model runtime solution developed based on the MNN engine. The mission of this project is to deploy LLM models locally on everyone's platforms(Mobile Phone/PC/IOT). It supports popular large language models such as Qianwen, Baichuan, Zhipu, LLAMA, and others. [MNN-LLM User guide](https://mnn-docs.readthedocs.io/en/latest/transformers/llm.html)\n\n[MNN-Diffusion](https://github.com/alibaba/MNN/tree/master/transformers/diffusion) is a stable diffusion model runtime solution developed based on the MNN engine. The mission of this project is to deploy stable diffusion models locally on everyone's platforms. [MNN-Diffusion User guide](https://mnn-docs.readthedocs.io/en/latest/transformers/diffusion.html)\n\n![architecture](doc/architecture.png)\n\nInside Alibaba, [MNN](https://mp.weixin.qq.com/s/5I1ISpx8lQqvCS8tGd6EJw) works as the basic module of the compute container in the [Walle](https://mp.weixin.qq.com/s/qpeCETty0BqqNJV9CMJafA) System, the first end-to-end, general-purpose, and large-scale production system for device-cloud collaborative machine learning, which has been published in the top system conference OSDI\u201922. The key design principles of MNN and the extensive benchmark testing results (vs. TensorFlow, TensorFlow Lite, PyTorch, PyTorch Mobile, TVM) can be found in the OSDI paper. The scripts and instructions for benchmark testing are put in the path \u201c/benchmark\u201d. If MNN or the design of Walle helps your research or production use, please cite our OSDI paper as follows:\n\n    @inproceedings {proc:osdi22:walle,\n        author = {Chengfei Lv and Chaoyue Niu and Renjie Gu and Xiaotang Jiang and Zhaode Wang and Bin Liu and Ziqi Wu and Qiulin Yao and Congyu Huang and Panos Huang and Tao Huang and Hui Shu and Jinde Song and Bin Zou and Peng Lan and Guohuan Xu and Fei Wu and Shaojie Tang and Fan Wu and Guihai Chen},\n        title = {Walle: An {End-to-End}, {General-Purpose}, and {Large-Scale} Production System for {Device-Cloud} Collaborative Machine Learning},\n        booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)},\n        year = {2022},\n        isbn = {978-1-939133-28-1},\n        address = {Carlsbad, CA},\n        pages = {249--265},\n        url = {https://www.usenix.org/conference/osdi22/presentation/lv},\n        publisher = {USENIX Association},\n        month = jul,\n    }\n\n\n## Documentation and Workbench\nMNN's docs are in place in [Read the docs](https://mnn-docs.readthedocs.io/en/latest).\n\nYou can also read docs/README to build docs's html.\n\nMNN Workbench could be downloaded from [MNN's homepage](http://www.mnn.zone), which provides pretrained models, visualized training tools, and one-click deployment of models to devices.\n\n## Key Features\n### Lightweight\n- Optimized for devices, no dependencies, can be easily deployed to mobile devices and a variety of embedded devices.\n- iOS platform: static library size will full option for armv7+arm64 platforms is about 12MB, size increase of linked executables is about 2M.\n- Android platform: core so size is about 800KB (armv7a - c++_shared).\n- Using MNN_BUILD_MINI can reduce package size by about 25%, with a limit of fixed model input size\n- Support FP16 / Int8 quantize, can reduce model size 50%-70%\n\n### Versatility\n- Supports `Tensorflow`, `Caffe`, `ONNX`,`Torchscripts` and supports common neural networks such as `CNN`, `RNN`, `GAN`, `Transformer`.\n- Supports AI model with multi-inputs or multi-outputs, every kind of dimension format, dynamic inputs, controlflow.\n- MNN supports approximate full OPs used for the AI Model. The converter supports 178 `Tensorflow` OPs, 52 `Caffe` OPs, 163 `Torchscripts` OPs, 158 `ONNX` OPs.\n- Supports iOS 8.0+, Android 4.3+, and embedded devices with POSIX interface.\n- Supports hybrid computing on multiple devices. Currently supports CPU and GPU.\n\n\n### High performance\n- Implements core computing with lots of optimized assembly code to make full use of the ARM / x64 CPU.\n- Use Metal / OpenCL / Vulkan to support GPU inference on mobile.\n- Use CUDA and tensorcore to support NVIDIA GPU for better performance\n- Convolution and transposition convolution algorithms are efficient and stable. The Winograd convolution algorithm is widely used to better symmetric convolutions such as 3x3,4x4,5x5,6x6,7x7.\n- Twice speed increase for the new architecture ARM v8.2 with FP16 half-precision calculation support. 2.5 faster to use sdot for ARM v8.2 and VNNI.\n\n### Ease of use\n- Support use MNN's OP to do numerical calculating like numpy.\n- Support lightweight image process module like OpenCV, which is only 100k.\n- Support build model and train it on PC / mobile.\n- MNN Python API helps ML engineers to easily use MNN to infer, train, and process images, without dipping their toes in C++ code.\n\nThe Architecture / Precision MNN supported is shown below:\n\n- S \uff1aSupport and work well, deeply optimized, recommend to use\n- A \uff1aSupport and work well, can use\n- B \uff1aSupport but has bug or not optimized, no recommend to use\n- C \uff1aNot Support\n\n| Architecture / Precision |  | Normal | FP16 | BF16 | Int8 |\n| --- | --- | --- | --- | --- | --- |\n| CPU | Native | B | C | B | B |\n|  | x86/x64-SSE4.1 | A | B | B | A |\n|  | x86/x64-AVX2 | S | B | B | A |\n|  | x86/x64-AVX512 | S | B | B | S |\n|  | ARMv7a | S | S (ARMv8.2) | S | S |\n|  | ARMv8 | S | S (ARMv8.2) | S(ARMv8.6) | S |\n| GPU | OpenCL | A | S | C | C |\n|  | Vulkan | A | A | C | C |\n|  | Metal | A | S | C | C |\n|  | CUDA | A | S | C | C |\n| NPU | CoreML | B | B | C | C |\n|  | HIAI | B | C | C | B |\n|  | NNAPI | B | B | C | C |\n\n\n\n## Tools\n\nBase on MNN (Tensor compute engine), we provided a series of tools for inference, train and general computation.\n\n- MNN-Converter: Convert other models to MNN models for inference, such as Tensorflow(lite), Caffe, ONNX, Torchscripts. And do graph optimization to reduce computation.\n- MNN-Compress: Compress model to reduce size and increase performance / speed\n- MNN-Express: Support model with controlflow, use MNN's OP to do general-purpose computing.\n- MNN-CV: An OpenCV-like library, but based on MNN and then much more lightweight.\n- MNN-Train: Support train MNN model.\n\n## How to Discuss and Get Help From the MNN Community\n\nThe group discussions are predominantly Chinese. But we welcome and will help English speakers.\n\nDingtalk discussion groups:\n\nGroup #1 (Full): 23329087\n\nGroup #2 (Full): 23350225\n\nGroup #3: QR code:\n\n![MNN-3](doc/dingdingmnn3.png)\n\n## Historical Paper\n\nThe preliminary version of MNN, as mobile inference engine and with the focus on manual optimization, has also been published in MLSys 2020. Please cite the paper, if MNN previously helped your research:\n\n\n    @inproceedings{alibaba2020mnn,\n      author = {Jiang, Xiaotang and Wang, Huan and Chen, Yiliu and Wu, Ziqi and Wang, Lichuan and Zou, Bin and Yang, Yafeng and Cui, Zongyang and Cai, Yu and Yu, Tianhang and Lv, Chengfei and Wu, Zhihua},\n      title = {MNN: A Universal and Efficient Inference Engine},\n      booktitle = {MLSys},\n      year = {2020}\n    }\n\n\n## License\nApache 2.0\n\n## Acknowledgement\nMNN participants: Taobao Technology Department, Search Engineering Team, DAMO Team, Youku and other Alibaba Group employees.\n\nMNN refers to the following projects:\n- [Caffe](https://github.com/BVLC/caffe)\n- [flatbuffer](https://github.com/google/flatbuffers)\n- [gemmlowp](https://github.com/google/gemmlowp)\n- [Google Vulkan demo](http://www.github.com/googlesamples/android-vulkan-tutorials)\n- [Halide](https://github.com/halide/Halide)\n- [Mace](https://github.com/XiaoMi/mace)\n- [ONNX](https://github.com/onnx/onnx)\n- [protobuffer](https://github.com/protocolbuffers/protobuf)\n- [skia](https://github.com/google/skia)\n- [Tensorflow](https://github.com/tensorflow/tensorflow)\n- [ncnn](https://github.com/Tencent/ncnn)\n- [paddle-mobile](https://github.com/PaddlePaddle/paddle-mobile)\n- [stb](https://github.com/nothings/stb)\n- [rapidjson](https://github.com/Tencent/rapidjson)\n- [pybind11](https://github.com/pybind/pybind11)\n- [pytorch](https://github.com/pytorch/pytorch)\n- [bolt](https://github.com/huawei-noah/bolt)\n- [libyuv](https://chromium.googlesource.com/libyuv/libyuv)\n- [libjpeg](https://github.com/libjpeg-turbo/libjpeg-turbo)\n- [opencv](https://github.com/opencv/opencv)\n",
        "releases": [
            {
                "name": "3.0\u53d1\u5e03\u3010\u591a\u6a21\u6001\u5927\u6a21\u578b\u652f\u6301\u3001\u52a8\u6001\u91cf\u5316\u529f\u80fd\u5b8c\u5584\u3001Web SIMD\u652f\u6301\u53ca\u5176\u4ed6Bug\u4fee\u590d\u3011",
                "date": "2024-11-20T01:43:43Z"
            },
            {
                "name": "\u3010LLM\u76f8\u5173\u6027\u80fd\u4f18\u5316\uff0c\u5f62\u72b6\u7f13\u5b58\u673a\u5236\u30112.9.0",
                "date": "2024-05-15T02:15:34Z"
            },
            {
                "name": "2.8.1",
                "date": "2023-12-29T08:08:23Z"
            },
            {
                "name": "2.8.0",
                "date": "2023-12-05T08:50:54Z"
            },
            {
                "name": "2.7.2",
                "date": "2023-12-04T08:21:53Z"
            },
            {
                "name": "2.7.1",
                "date": "2023-09-28T07:41:49Z"
            },
            {
                "name": "\u3010\u5185\u5b58\u5206\u914d\u4f18\u5316\u3001\u6027\u80fd\u4f18\u5316\u3001Bugfix\u30112.7.0",
                "date": "2023-09-04T08:37:05Z"
            },
            {
                "name": "2.6.3",
                "date": "2023-09-28T07:42:36Z"
            },
            {
                "name": "\u3010\u65b0\u589eInt8 \u91cf\u5316\u7b97\u5b50\uff0cOpenCL\u540e\u7aef\u9002\u914d recordable queue\u30112.6.0",
                "date": "2023-07-05T08:11:44Z"
            },
            {
                "name": "2.5.0",
                "date": "2023-04-27T09:09:26Z"
            },
            {
                "name": "2.4.0 NNAPI\u540e\u7aef/CUDA\u540e\u7aef\u652f\u6301\u91cf\u5316\u6a21\u578b",
                "date": "2023-03-01T02:34:40Z"
            },
            {
                "name": "2.3.1",
                "date": "2023-02-15T09:26:29Z"
            },
            {
                "name": "2.3.0 \u57fa\u4e8e\u51e0\u4f55\u8ba1\u7b97\u5b9e\u73b0\u6c42\u5bfc/\u652f\u6301\u6a21\u578b\u6743\u91cd\u5206\u79bb\u6a21\u5f0f",
                "date": "2022-12-30T09:27:20Z"
            },
            {
                "name": "2.2.0 NNAPI / ARMv8.6 \u77e9\u9635\u4e58\u6307\u4ee4\u652f\u6301",
                "date": "2022-10-31T01:57:22Z"
            },
            {
                "name": "2.1.0 Eager \u6a21\u5f0f / CUDA \u540e\u7aef\u6539\u9020 / Winograd Int8 \u8ba1\u7b97\u5b9e\u73b0",
                "date": "2022-08-31T12:33:26Z"
            },
            {
                "name": "",
                "date": "2022-06-29T08:56:31Z"
            },
            {
                "name": "Bugfix / Feature",
                "date": "2021-07-29T03:30:25Z"
            },
            {
                "name": "MNN 1.2.0 Release Notes",
                "date": "2021-06-18T10:08:42Z"
            },
            {
                "name": "More Op and bugfix",
                "date": "2021-04-21T01:55:40Z"
            },
            {
                "name": "Support BF16, Speed Up FP16, AVX512, Full Quantization",
                "date": "2021-04-21T01:50:44Z"
            },
            {
                "name": "OpenCL Speed Up",
                "date": "2021-04-20T10:07:01Z"
            },
            {
                "name": "Add HIAI-NPU, While/Loop refract",
                "date": "2021-04-20T10:00:00Z"
            },
            {
                "name": "Add oneDNN, TensorArray support, Bugfix ",
                "date": "2021-04-20T09:53:45Z"
            },
            {
                "name": "Bugfix and speed up",
                "date": "2021-01-06T08:20:33Z"
            },
            {
                "name": "MNN 1.1.0 Release Notes",
                "date": "2020-11-05T09:20:12Z"
            },
            {
                "name": "Advancing Our Amazing DL Engine: MNN 1.0.0",
                "date": "2020-05-08T02:54:21Z"
            },
            {
                "name": "X86-Optimize and Plugin support",
                "date": "2020-04-15T11:04:17Z"
            },
            {
                "name": "Bugfix and low level arm speed up.",
                "date": "2020-04-07T05:10:37Z"
            },
            {
                "name": "ARM v8.2+ support and Vulkan backend enhance",
                "date": "2020-03-23T14:34:19Z"
            },
            {
                "name": "Support quantization aware training",
                "date": "2020-03-23T04:45:28Z"
            },
            {
                "name": "0.2.1.9",
                "date": "2020-03-09T06:36:01Z"
            },
            {
                "name": "0.2.1.7",
                "date": "2020-01-17T12:08:11Z"
            },
            {
                "name": "0.2.1.6",
                "date": "2019-12-31T05:04:33Z"
            },
            {
                "name": "",
                "date": "2019-11-15T06:23:42Z"
            },
            {
                "name": "0.2.1.2",
                "date": "2019-10-29T07:14:05Z"
            },
            {
                "name": "0.2.1.0",
                "date": "2019-09-26T13:03:10Z"
            },
            {
                "name": "",
                "date": "2019-09-01T11:25:53Z"
            },
            {
                "name": "",
                "date": "2019-08-22T12:15:56Z"
            },
            {
                "name": "",
                "date": "2019-08-15T09:31:50Z"
            },
            {
                "name": "",
                "date": "2019-08-07T08:47:19Z"
            },
            {
                "name": "",
                "date": "2019-08-05T02:41:38Z"
            },
            {
                "name": "",
                "date": "2019-08-05T02:41:12Z"
            },
            {
                "name": "beta 0.2.0.3",
                "date": "2019-07-11T05:58:48Z"
            },
            {
                "name": "",
                "date": "2019-07-02T10:01:54Z"
            },
            {
                "name": "0.2.0.1",
                "date": "2019-06-24T03:36:53Z"
            },
            {
                "name": "beta 0.2.0.0",
                "date": "2019-06-17T12:12:20Z"
            },
            {
                "name": "beta 0.1.1.6",
                "date": "2019-06-10T13:12:15Z"
            },
            {
                "name": "",
                "date": "2019-06-05T02:47:09Z"
            },
            {
                "name": "",
                "date": "2019-05-24T03:32:16Z"
            },
            {
                "name": "0.1.1.3",
                "date": "2019-05-17T07:01:09Z"
            },
            {
                "name": "0.1.1.2",
                "date": "2019-05-14T11:58:28Z"
            }
        ]
    }
}