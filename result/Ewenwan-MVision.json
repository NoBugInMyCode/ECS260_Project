{
    "https://api.github.com/repos/Ewenwan/MVision": {
        "forks": 2791,
        "watchers": 8131,
        "stars": 8131,
        "languages": {
            "C++": 4830070,
            "Python": 2444785,
            "C": 2370638,
            "Makefile": 2316009,
            "CMake": 462459,
            "Shell": 19783,
            "Cuda": 15100,
            "MATLAB": 14732
        },
        "commits": [
            "2024-07-09T10:25:36Z",
            "2024-07-09T10:22:32Z",
            "2020-12-13T07:52:09Z",
            "2020-09-06T06:16:03Z",
            "2020-08-28T10:40:43Z",
            "2020-08-28T10:40:00Z",
            "2020-08-28T10:38:28Z",
            "2020-08-28T10:37:43Z",
            "2020-08-18T07:17:10Z",
            "2020-08-18T07:13:17Z",
            "2020-08-18T07:12:18Z",
            "2020-08-14T09:41:04Z",
            "2020-07-27T09:01:17Z",
            "2020-07-27T05:58:06Z",
            "2020-07-23T01:57:04Z",
            "2020-07-07T09:39:24Z",
            "2020-07-05T04:51:34Z",
            "2020-07-05T03:22:47Z",
            "2020-07-05T02:49:33Z",
            "2020-07-04T14:41:37Z",
            "2020-07-04T14:40:23Z",
            "2020-07-04T14:05:39Z",
            "2020-07-04T13:39:49Z",
            "2020-07-04T13:05:52Z",
            "2020-07-04T09:21:19Z",
            "2020-07-04T08:25:22Z",
            "2020-07-04T08:06:58Z",
            "2020-07-04T07:31:37Z",
            "2020-07-04T06:47:28Z",
            "2020-07-04T05:16:31Z"
        ],
        "creation_date": "2017-09-24T06:25:27Z",
        "contributors": 2,
        "topics": [
            "cnn",
            "deep-learning",
            "machine-vision",
            "opencv",
            "pcl",
            "robot",
            "slam"
        ],
        "subscribers": 380,
        "readme": "# MVision\u3000Machine Vision \u673a\u5668\u89c6\u89c9\n[AI\u7b97\u6cd5\u5de5\u7a0b\u5e08\u624b\u518c \u6570\u5b66\u57fa\u7840 \u7edf\u8ba1\u5b66\u4e60 \u6df1\u5ea6\u5b66\u4e60 \u81ea\u7136\u8bed\u8a00\u5904\u7406 \u5de5\u5177\u4f7f\u7528](http://www.huaxiaozhuan.com/)\n\n[AI \u5b89\u5168\u6570\u636e\u79d1\u5b66\u548c\u7b97\u6cd5 ](https://github.com/Ewenwan/AI-Security-Learning)\n\n[\u6fb3\u5927\u5229\u4e9a\u673a\u5668\u4eba\u89c6\u89c9\u7814\u7a76\u4e2d\u5fc3](https://www.roboticvision.org/)\n\n[NIPS Neural Information Processing Systems](https://papers.nips.cc/)\n\n[icml Proceedings of Machine Learning Research PMLR](http://proceedings.mlr.press/index.html)\n\n[ICDM IEEE International Conference on Data Mining](http://www.cs.uvm.edu/~icdm/)\n\n[Computer Vision and Pattern Recognition arxiv.org \u6700\u65b0\u63d0\u4ea4\u7684\u8bba\u6587](https://arxiv.org/list/cs.CV/recent)\n\n[papercept \u4f1a\u8bae\u8bba\u6587\u6295\u9012](https://controls.papercept.net/conferences/scripts/start.pl)\n\n[easychair \u4f1a\u8bae\u8bba\u6587\u6295\u9012](https://easychair.org/my/roles.cgi?welcome=1)\n\n[DBLP \u8ba1\u7b97\u673a\u6838\u5fc3\u6280\u672f\u6587\u732e](https://dblp.uni-trier.de/)\n\n[\u6280\u672f\u5218 \u589e\u5f3a\u73b0\u5b9e\u3001\u56fe\u50cf\u8bc6\u522b\u3001\u6df1\u5ea6\u5b66\u4e60\u3001\u673a\u5668\u4eba](http://liuxiao.org/category/robots/)\n\n[\u6f2b\u8c08 SLAM \u6280\u672f\uff08\u4e0a\uff09](https://cloud.tencent.com/developer/article/1005894)\n\n[\u6f2b\u8c08 SLAM \u6280\u672f\uff08\u4e0b\uff09](https://cloud.tencent.com/developer/article/1005893)\n\n[\u4f18\u79c0\u7684\u535a\u5ba2\u8bba\u6587\u7b14\u8bb0](https://github.com/Ewenwan/antkillerfarm.github.com)\n\n[CSCI 1430: Introduction to Computer Vision \u8ba1\u7b97\u673a\u89c6\u89c9\u8bfe\u7a0b](http://cs.brown.edu/courses/csci1430/#schedule)\n\n[\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u7b97\u6cd5 \u4e66\u7c4d](http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf)\n\n[Computer vision:models, learning and inference \u4e66\u7c4d](http://web4.cs.ucl.ac.uk/staff/s.prince/book/book.pdf)\n\n[TLD\uff1atracking-learning-detection \u8ddf\u8e2a\u7b97\u6cd5](https://github.com/Ewenwan/opencv_TLD)\n\n[\u673a\u5668\u4eba\u9009\u4fee\u8bfe](http://www.diag.uniroma1.it/%7Elanari/EIR/)\n\n[Andrew Davison\u7684\u8bfe\u7a0b\uff1a Robotics Lecture Course (course code 333)](http://www.doc.ic.ac.uk/~ajd/Robotics/index.html)\n\n[Simultaneous Localization and Mapping: Part I ](http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial1.pdf)\n\n[Simultaneous Localization and Mapping: Part II ](http://www.doc.ic.ac.uk/~ajd/Robotics/RoboticsResources/SLAMTutorial2.pdf)\n\n[\u745e\u58eb\u82cf\u9ece\u4e16\u7406\u5de5\u7684\u5b66\u751f\u7ec3\u4e60](http://www.csc.kth.se/~kootstra/index.php?item=313&menu=300)\n\n[\u4e66\u7c4d Robotics, Vision & Control \u63a8\u8350\uff01\uff01\uff01\uff01](http://petercorke.com/wordpress/)\n\n[Robotics, Vision & Control.PDF \u767e\u5ea6\u7f51\u76d8](https://pan.baidu.com/s/1c1TcEgo)\n\n[Robotics, Vision and Control csdn](https://download.csdn.net/download/u013834525/10169878)\n\n[\u4f18\u8fbe\u5b66\u57ce \u673a\u5668\u4eba\u4eba\u5de5\u667a\u80fd\u8bfe\u7a0b](https://classroom.udacity.com/courses/cs373)\n\n[\u5b66\u4e60\u65e0\u4eba\u9a7e\u9a76\u8f66\uff0c\u4f60\u6240\u5fc5\u987b\u77e5\u9053\u7684](https://zhuanlan.zhihu.com/p/27686577)\n\n[\u5f3a\u5316\u5b66\u4e60\u4ece\u5165\u95e8\u5230\u653e\u5f03\u7684\u8d44\u6599](https://zhuanlan.zhihu.com/p/34918639?utm_source=wechat_session&utm_medium=social&wechatShare=1&from=singlemessage&isappinstalled=0)\n\n[\u53f0\u5927 \u673a\u5668\u5b66\u4e60\u6df1\u5ea6\u5b66\u4e60\u8bfe\u7a0b](http://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html)\n\n[\u65af\u5766\u798fCS231\u8ba1\u7b97\u673a\u89c6\u89c92017](http://www.mooc.ai/course/268/learn?lessonid=1819#lesson/1819)\n\n[\u6df1\u5ea6\u5b66\u4e60\u7a0b\u5e8f\u793a\u4f8b cs231n\u7b49](https://github.com/autoliuweijie/DeepLearning)\n\n[2018 MIT 6.S094 \u9ebb\u7701\u7406\u5de5\u6df1\u5ea6\u5b66\u4e60\u548c\u81ea\u52a8\u9a7e\u9a76\u8bfe\u7a0b \u4e2d\u6587](http://www.mooc.ai/course/483/notes)\n\n[MIT  \u6df1\u5ea6\u5b66\u4e60\u548c\u81ea\u52a8\u9a7e\u9a76\u8bfe\u7a0b \u82f1\u6587](https://selfdrivingcars.mit.edu/)\n\n[DeepTraffic](https://selfdrivingcars.mit.edu/deeptraffic/)\n\n[SegFuse: Dynamic Driving Scene Segmentation](https://selfdrivingcars.mit.edu/segfuse/)\n\n[DeepTesla - End-to-End Steering Model](https://selfdrivingcars.mit.edu/deeptesla/)\n\n[\u4e2d\u6587slam\u9996\u9875](http://www.slamcn.org/index.php/%E9%A6%96%E9%A1%B5)\n\n[ORB-LSD-SVO\u6bd4\u8f83-\u5218\u6d69\u654f_bilibili](https://www.bilibili.com/video/av5934066/)\n\n[LSD\u7b97\u6cd5\u4ee3\u7801\u89e3\u6790](http://www.cnblogs.com/shhu1993/p/7136033.html)\n\n[SVO\u7b97\u6cd5\u4ee3\u7801\u89e3\u6790](http://www.cnblogs.com/shhu1993/p/7135847.html)\n\n[DSO \u534a\u95f2\u5c45\u58eb \u89e3\u6790](https://zhuanlan.zhihu.com/p/29177540)\n\n[\u8def\u5f84\u89c4\u5212A*\u7b97\u6cd5\u53caSLAM\u81ea\u4e3b\u5730\u56fe\u521b\u5efa\u5bfc\u822a\u7b97\u6cd5](http://www.voidcn.com/article/p-yfjpnwte-tz.html)\n\n[\u51af\u5175\u7684blog slam](http://www.fengbing.net)\n\n[imu\u548c\u5355\u76ee\u7684\u6570\u636e\u878d\u5408\u5f00\u6e90\u4ee3\u7801\uff08EKF)](https://github.com/ethz-asl/rovio)\n\n[imu\u548c\u5355\u76ee\u7684\u6570\u636e\u878d\u5408\u5f00\u6e90\u4ee3\u7801(\u975e\u7ebf\u6027\u4f18\u5316\uff09](https://github.com/ethz-asl/okvis_ros)\n\n[\u53cc\u76ee\u7acb\u4f53\u5339\u914d](https://wenku.baidu.com/view/08f86102e518964bcf847c6c.html)\n\n[\u8ba1\u7b97\u673a\u89c6\u89c9\u7684\u4e00\u4e9b\u5e93\u6587\u4ef6](https://blog.csdn.net/garfielder007/article/details/50533052)\n\n[\u4eba\u8138\u68c0\u6d4b\u603b\u7ed3](https://blog.csdn.net/neu_chenguangq/article/details/52983093)\n\n[\u884c\u4e3a\u8bc6\u522b\u603b\u7ed3](https://blog.csdn.net/neu_chenguangq/article/details/79504214)\n\n[Free-SpaceEstimation \u65e0\u969c\u788d\u7269\u7a7a\u95f4\u4f30\u8ba1 \u7a20\u5bc6\u5730\u56fe \u6805\u683c\u5730\u56fe \u52a8\u6001\u89c4\u5212 \u9ad8\u5ea6\u5206\u5272 \u8def\u9762\u4fe1\u606f\u63d0\u53d6](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/05_free_space.pdf)\n\n[2D Object Detection 2d\u76ee\u6807\u68c0\u6d4b RCNN ](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/05_2D_detection.pdf)\n\n[3D Object Detection 3D\u76ee\u6807\u68c0\u6d4b \u52a8\u673a](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/06_3D_detection.pdf)\n\n[Semantic Segmentation \u8bed\u4e49\u5206\u5272](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/07_segmentation.pdf)\n\n[Instance-level Segmentation \u5b9e\u4f8b\u5206\u5272](http://www.cs.toronto.edu/~urtasun/courses/CSC2541/08_instance.pdf)\n\n[Tracking \u8ddf\u8e2a ]()\n\n[Kalibr calibration toolbox \u6807\u5b9a\u591a\u76ee\u76f8\u673a\u7cfb\u7edf\u3001\u76f8\u673a IMU \u76f8 \u5bf9 \u4f4d \u59ff \u548c \u5377 \u5e18 \u5feb \u95e8 \u76f8 \u673a  ](https://github.com/Ewenwan/kalibr)\n\n[\u970d\u592b\u68ee\u6797(Hough Forest) \u968f\u673a\u68ee\u6797\u548c\u970d\u592b\u6295\u7968\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u5e94\u7528\uff0c\u53ef\u4ee5\u7528\u5728\u7269\u4f53\u68c0\u6d4b\uff0c\u8ddf\u8e2a\u548c\u52a8\u4f5c\u8bc6\u522b](https://github.com/Ewenwan/HoughForest)\n\n[\u767e\u5ea6\u81ea\u52a8\u9a7e\u9a76\u5f00\u6e90\u6846\u67b6 apollo](https://github.com/Ewenwan/apollo)\n\n[\u4ea4\u901a\u6807\u5fd7\u68c0\u6d4b\u8bc6\u522b \u6570\u636e\u96c6](https://cg.cs.tsinghua.edu.cn/traffic-sign/)\n\n[Halcon \u4f7f\u7528\u53c2\u8003](https://blog.csdn.net/maweifei/article/details/52613392)\n\n[\u6709\u4ee3\u7801\u7684\u8bba\u6587](https://github.com/Ewenwan/pwc)\n\n[\u56fe\u50cf\u5904\u7406\u57fa\u672c\u7b97\u6cd5\u4ee3\u7801](http://www.cnblogs.com/Imageshop/p/3430742.html)\n\n# \u611f\u8c22\u652f\u6301\n\n![](https://github.com/Ewenwan/EwenWan/blob/master/zf.jpg)\n\n# \u65e0\u4eba\u9a7e\u9a76\u7684\u5404\u4e2a\u65b9\u9762\u77e5\u8bc6\n[\u53c2\u8003](https://blog.csdn.net/qq_40027052/article/details/78485120)\n\n    1. \u611f\u77e5\uff08Perception\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u7684\u6280\u672f\u70b9\u5305\u62ec\u573a\u666f\u7406\u89e3\u3001\u4ea4\u901a\u72b6\u51b5\u5206\u6790\u3001\u8def\u9762\u68c0\u6d4b\u3001\u7a7a\u95f4\u68c0\u6d4b\u3001\n        \u969c\u788d\u7269\u68c0\u6d4b\u3001\u884c\u4eba\u68c0\u6d4b\u3001\u8def\u6cbf\u68c0\u6d4b\u3001\u8f66\u9053\u68c0\u6d4b\u3002\u8fd8\u6709\u4e00\u4e2a\u6bd4\u8f83\u65b0\u9896\u6709\u8da3\u7684\u662f\u901a\u8fc7\u80ce\u538b\u53bb\u68c0\u6d4b\u9053\u8def\u8d28\u91cf\u3002\n        \u5728\u65e0\u4eba\u9a7e\u9a76\u884c\u4e1a\uff0c\u6709\u4e00\u5957\u901a\u7528\u7684\u6570\u636e\u96c6\u2014\u2014KITTI\u6570\u636e\u96c6\uff0c\u91cc\u9762\u6709\u4e0d\u540c\u7684\u6570\u636e\uff0c\u5305\u62ec\u53cc\u76ee\u89c6\u89c9\u7684\u6570\u636e\u3001\u5b9a\u4f4d\u5bfc\u822a\u7684\u6570\u636e\u7b49\u3002\n        \u7269\u4f53\u68c0\u6d4b\uff08Object Detection\uff09\uff1a\n            \u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u662f\u9488\u5bf9\u56fa\u5b9a\u7269\u4f53\u7684\u68c0\u6d4b\u3002\u4e00\u822c\u7684\u65b9\u6cd5\u662fHOG\uff08 \u65b9\u5411\u68af\u5ea6\u76f4\u65b9\u56fe\uff09\uff0c\u7136\u540e\u518d\u52a0\u4e00\u4e2aSVM\u7684\u5206\u7c7b\u5668\u3002\n            \u800c\u5bf9\u4e8e\u52a8\u6001\u7269\u4f53\u7684\u68c0\u6d4b\uff0c\u4e3b\u8981\u4f7f\u7528\u7684\u662fDPM\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5148\u628a\u624b\u548c\u811a\u8bc6\u522b\u51fa\u6765\uff0c\u518d\u8fdb\u884c\u7ec4\u5408\u3002\n            \u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5 RCNN YOLO\n       \u573a\u666f\u5206\u5272\uff08Segmentation\uff09 \u00a0\uff1a\n            \u4eba\u884c\u9053\u662f\u4e00\u4e2a\u573a\u666f\uff0c\u9053\u8def\u662f\u4e00\u4e2a\u573a\u666f\uff0c\u5728\u573a\u666f\u4e2d\u5bf9\u4e0d\u540c\u7684\u7269\u4f53\u8fdb\u884c\u5206\u7c7b\uff0c\u662f\u4e00\u4e2a\u5f88\u91cd\u8981\u7684\u95ee\u9898\u3002\n            \u4f20\u7edf\u7684\u65b9\u6cd5\u662f\u91c7\u7528CRF\uff08 \u6761\u4ef6\u968f\u673a\u573a\uff09\uff0c\u57fa\u672c\u539f\u7406\u5728\u4e8e\u56fe\u50cf\u90fd\u662f\u7531\u50cf\u7d20\u70b9\u7ec4\u6210\u7684\uff0c\n            \u82e5\u4e24\u4e2a\u50cf\u7d20\u70b9\u90fd\u6bd4\u8f83\u50cf\u8f66\uff0c\u90a3\u5c31\u628a\u4e8c\u8005\u8fde\u63a5\u8d77\u6765\uff0c\u5f62\u6210\u5bf9\u8f66\u8f86\u7684\u8bc6\u522b\u3002\n\n            \u8fd0\u7528\u6df1\u5ea6\u5b66\u4e60\u7684\u65b9\u6cd5\u5219\u4f7f\u7528\u7684\u662f\u53e6\u4e00\u79cd\u6a21\u578b\uff0c\u88ab\u79f0\u4e3aPSPnet\uff08\u8bed\u4e49\u5206\u5272\uff09\u3002\n            \u8fd9\u662f\u91d1\u5b57\u5854\u578b\u7684\u573a\u666f\u5206\u89e3\u6a21\u578b\uff0c\u5c06\u4e00\u4e2a\u573a\u666f\u4e0d\u65ad\u5730\u538b\u7f29\uff0c\u628a\u7c7b\u4f3c\u7684\u7269\u4f53\u805a\u7c7b\uff0c\u7136\u540e\u518d\u505a\u5224\u65ad\u3002\n       \u53cc\u76ee \u5149\u6d41\uff08Optical Flow\uff09\u573a\u666f\u6d41\uff08Scene Flow\uff09\uff1a\n            \u5149\u6d41\u662f\u9488\u5bf92D\u56fe\u50cf\u6765\u8bf4\u7684\uff0c\u5982\u679c\u8bf4\u4e00\u4e2a\u56fe\u7247\u6d41\u5230\u53e6\u5916\u4e00\u4e2a\u56fe\u7247\uff0c\u90fd\u662f2D\u7684\u7269\u4f53\u79fb\u52a8\uff0c\u90a3\u5c31\u7528\u5149\u6d41\u6765\u505a\u3002\n            \u5982\u679c\u662f3D\u7684\u7269\u4f53\u6d41\u52a8\uff0c\u90a3\u6211\u4eec\u5c31\u7528\u573a\u666f\u6d41\uff08Scene Flow\uff09\uff0c\u573a\u666f\u6d41\u5728\u4f20\u7edf\u7684\u65b9\u6cd5\u5c31\u662f\u4f7f\u7528\u7684\u662fSGBM\uff0c\n            \u5229\u7528\u7684\u662f\u53cc\u76ee\u6210\u50cf\u7684\u6280\u672f\uff0c\u628a\u5de6\u56fe\u548c\u53f3\u56fe\u5408\u8d77\u6765\u63d0\u53d6\u51fa\u7a7a\u95f4\u7684\u70b9\uff0c\u7528\u5149\u6d41\u5728\u4e0a\u9762\u505a\uff0c\u5c31\u80fd\u628a\u573a\u666f\u7684\u6d41\u52a8\u5206\u6790\u51fa\u6765\u3002\n\n            \u5149\u6d41\u4e5f\u53ef\u4ee5\u5229\u7528\u6df1\u5ea6\u5b66\u4e60\u7684\u6a21\u578b\u6765\u505a\uff0c\u628a\u5de6\u53f3\u4e24\u56fe\u7528\u540c\u6837\u7684\u6a21\u578b\u6765\u63d0\u53d6\u7279\u5f81\uff0c\u7ecf\u8fc7\u8ba1\u7b97\u5c31\u80fd\u5f97\u51fa\u4e00\u4e2a\u6df1\u5ea6\u7684\u4fe1\u606f\u3002\n            \u4f46\u662f\u8fd9\u4e2a\u65b9\u5f0f\u7684\u8ba1\u7b97\u91cf\u975e\u5e38\u5927\u3002\n\n       \u7269\u4f53\u8ffd\u8e2a\uff08Object Tracking\uff09\uff1a \u00a0 \u00a0\n            \u8fd9\u4e5f\u662f\u65e0\u4eba\u9a7e\u9a76\u4e2d\u4e00\u4e2a\u6bd4\u8f83\u91cd\u8981\u7684\u6280\u672f\u3002\u5982\u4f55\u9884\u6d4b\u884c\u4eba\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u3001\u600e\u4e48\u53bb\u8ddf\u8e2a\u8fd9\u4e2a\u884c\u4eba\uff0c\u4e5f\u6709\u4e00\u7cfb\u5217\u95ee\u9898\u3002\n            \u91cc\u9762\u7528\u5230\u7684\u662f\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u8fd9\u4e2a\u6280\u672f\u53eb\u505aMDP\uff0c\u8ddf\u8e2a\u4e00\u4e2a\u4eba\uff0c\u968f\u65f6\u8ddf\u8e2a\u5176\u4e0b\u4e00\u4e2a\u52a8\u4f5c\uff0c\u9884\u6d4b\u5176\u4e0b\u4e00\u4e2a\u52a8\u4f5c\u3002\n            \u4ee5\u4e0a\u5176\u5b9e\u90fd\u662f\u4e00\u4e9b\u4f20\u7edf\u7684\u611f\u77e5\u65b9\u6cd5\uff0c\u800c\u8fd9\u4e9b\u5e74\u968f\u7740\u6df1\u5ea6\u5b66\u4e60\u7684\u4e0d\u65ad\u8fdb\u6b65\uff0c\u5e94\u7528\u4e5f\u975e\u5e38\u5e7f\u6cdb\u3002\n            \n    2. \u8fd0\u52a8\u89c4\u5212\uff08Motion Planning\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u7684\u6280\u672f\u70b9\u5305\u62ec\u8fd0\u52a8\u89c4\u5212\u3001\u8f68\u8ff9\u89c4\u5212\u3001\u901f\u5ea6\u89c4\u5212\u3001\u8fd0\u52a8\u6a21\u578b\u3002\n        \u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u8fdb\u5c55\u5305\u62ec\u901a\u8fc7\u8d5b\u8f66\u6e38\u620f\u53bb\u5b66\u4e60\u57fa\u4e8e\u7f51\u683c\u7684\u8fd0\u52a8\u89c4\u5212\uff0c\u91cd\u91cf\u7ea7\u8d27\u8f66\u7684\u907f\u969c\u89c4\u5212\uff0c\u666e\u4e16\u7684\u9002\u7528\u4e8e\u65e0\u4eba\u9a7e\u9a76\u7684\u53cc\u8f6e\u6a21\u578b\u7b49\u7b49\u3002\n\n    3. \u9632\u78b0\u649e\uff08CollisionAvoidance\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u5982\u4f55\u901a\u8fc7\u8f66\u5185\u7684\u611f\u77e5\u7cfb\u7edf\u4ee5\u53caV2X \u7cfb\u7edf\u53bb\u8f85\u52a9\u9632\u78b0\u649e\u3002\n        \u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u8fdb\u5c55\u5305\u62ec\u5982\u4f55\u5b9e\u65f6\u5730\u53bb\u8bc4\u4f30\u5f53\u524d\u9a7e\u9a76\u884c\u4e3a\u7684\u5371\u9669\u6027\uff0c\u5982\u4f55\u901a\u8fc7\u5f53\u524d\u9053\u8def\u7684\u62d3\u6251\u53bb\u589e\u5f3a\u81ea\u884c\u8f66\u9a91\u58eb\u7684\u5b89\u5168\u6027\u7b49\u7b49\u3002\n\n    4. \u5730\u56fe\u4e0e\u5b9a\u4f4d\uff08Mapping andLocalization\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u5982\u4f55\u901a\u8fc7\u4e0d\u540c\u7684\u4f20\u611f\u5668\uff0c\u5305\u62ec\u6fc0\u5149\u96f7\u8fbe\u3001\u89c6\u89c9\u3001GNSS\uff0c\u4ee5\u53ca V2X \u53bb\u5efa\u56fe\u4e0e\u5b9a\u4f4d\u3002\n        \u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u8fdb\u5c55\u5305\u62ec\u5982\u4f55\u5728\u4e00\u4e9b\u7279\u6b8a\u7684\u573a\u666f\u53bb\u5b9a\u4f4d\uff0c\u6bd4\u5982\u5728\u957f\u96a7\u9053\u91cc\u9762\uff0c\u65e2\u6ca1\u6709 GNSS \u4fe1\u53f7\uff0c\u4e5f\u6ca1\u6709\u592a\u597d\u7684\u6fc0\u5149\u6216\u8005\u89c6\u89c9\u7279\u5f81\u7684\u65f6\u5019\u5982\u4f55\u5b9a\u4f4d\u3002\n\n    5. \u5408\u4f5c\u7cfb\u7edf\uff08CooperativeSystems\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u5982\u4f55\u534f\u540c\u591a\u4e2a\u65e0\u4eba\u8f66\u53bb\u5b8c\u6210\u4e00\u4e9b\u4efb\u52a1\uff0c\u6bd4\u5982\u5728\u591a\u4e2a\u65e0\u4eba\u8f66\u540c\u65f6\u5728\u4e00\u4e2a\u5341\u5b57\u8def\u53e3\u51fa\u73b0\u65f6\u5982\u4f55\u8c03\u5ea6\uff0c\n        \u8fd8\u6709\u5c31\u662f\u5f53\u6709\u591a\u4e2a\u65e0\u4eba\u8f66\u540c\u65f6\u5728\u505c\u8f66\u573a\u8bd5\u5982\u4f55\u6709\u5e8f\u7684\u505c\u8f66\u3002\n\n    6. \u63a7\u5236\u7b56\u7565\uff08Control Strategy\uff09\uff1a\n        \u4e3b\u8981\u7814\u7a76\u5728\u4e0d\u540c\u7684\u7ec6\u5206\u573a\u666f\u4e0b\u7684\u63a7\u5236\u7b56\u7565\uff0c\u6bd4\u5982\u5728\u5341\u5b57\u8def\u53e3\u5982\u4f55\u63a7\u5236\uff0c\u8f6c\u7ebf\u5982\u4f55\u63a7\u5236\uff0c\u5728\u611f\u77e5\u6570\u636e\u4e0d\u53ef\u9760\u65f6\u5982\u4f55\u5c3d\u91cf\u5b89\u5168\u7684\u63a7\u5236\u7b49\u7b49\u3002\n\n    7. \u8f66\u8f86\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\uff08VehicleDetection and Tracking\uff09\uff1a\n        \u4e3b\u8981\u5173\u6ce8\u5982\u4f55\u901a\u8fc7\u6fc0\u5149\u96f7\u8fbe\u3001\u89c6\u89c9\uff0c\u4ee5\u53ca\u6beb\u7c73\u6ce2\u96f7\u8fbe\u8fdb\u884c\u8f66\u8f86\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u3002\n        \u6bd4\u8f83\u6709\u8da3\u7684\u5de5\u4f5c\u5305\u62ec\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u4e0e\u6df1\u5ea6\u89c6\u89c9\u7684\u7ed3\u5408\u8fdb\u884c\u8f66\u8f86\u8ddf\u8e2a\uff0c\n        \u901a\u8fc7\u5355\u76ee\u89c6\u89c9\u6df1\u5ea6\u5b66\u4e60\u53bb\u5c3d\u91cf\u4f30\u8ba1\u8f66\u4f53\u5927\u5c0f\uff0c\u901a\u8fc7\u4f20\u7edf\u89c6\u89c9\u8fb9\u7f18\u68c0\u6d4b\u65b9\u6cd5\u53bb\u5224\u65ad\u662f\u5426\u8f66\u4f53\u7b49\u7b49\u3002\n\n    8. \u9759\u6001\u7269\u4f53\u68c0\u6d4b\uff08Static ObjectDetection\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u901a\u8fc7\u89c6\u89c9\u4ee5\u53ca\u6fc0\u5149\u96f7\u8fbe\u53bb\u68c0\u6d4b\u4e00\u4e9b\u9759\u6001\u7684\u7269\u4f53\uff0c\n        \u5305\u62ec\u4ea4\u901a\u706f\u3001\u4ea4\u901a\u6307\u793a\u724c\u3001\u8def\u6cbf\u3001\u8def\u9762\u7b49\u7b49\uff0c\u6bcf\u4e2a\u7269\u4f53\u54c1\u7c7b\u7684\u68c0\u6d4b\u90fd\u662f\u4e00\u4e2a\u7ec6\u5206\u65b9\u5411\u3002\n\n    9. \u52a8\u6001\u7269\u4f53\u68c0\u6d4b\uff08Moving ObjectDetection\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u901a\u8fc7\u89c6\u89c9\u3001\u6fc0\u5149\u96f7\u8fbe\u3001\u6beb\u7c73\u6ce2\u96f7\u8fbe\uff0c\u4ee5\u53ca\u4f20\u611f\u5668\u878d\u5408\u7684\u65b9\u6cd5\u53bb\u68c0\u6d4b\u4e00\u4e9b\u52a8\u6001\u7684\u7269\u4f53\uff0c\n        \u5305\u62ec\u884c\u4eba\u3001\u8f66\u8f86\u3001\u81ea\u884c\u8f66\u9a91\u58eb\u7b49\u7b49\uff0c\u5e76\u6839\u636e\u8fd9\u4e9b\u52a8\u6001\u7269\u4f53\u7684\u52a8\u4f5c\u53bb\u9884\u6d4b\u884c\u4e3a\u3002\n\n    10. \u9053\u8def\u4e0e\u8def\u53e3\u68c0\u6d4b\uff08Road andIntersection Detection\uff09\uff1a\n        \u9053\u8def\u4e0e\u8def\u53e3\u68c0\u6d4b\u7531\u4e8e\u5176\u7279\u6b8a\u6027\u4ee5\u53ca\u5bf9\u5b89\u5168\u7684\u5f71\u54cd\uff0c\u88ab\u5355\u72ec\u5217\u51fa\u4f5c\u4e3a\u4e00\u4e2a\u7ec6\u5206\u7684\u5c0f\u65b9\u5411\u3002\n        \u7814\u7a76\u7684\u524d\u6cbf\u4e00\u822c\u6d89\u53ca\u4e00\u4e9b\u7ec6\u5206\u573a\u666f\uff0c\u6bd4\u5982\u5efa\u7b51\u5de5\u5730\u7684\u68c0\u6d4b\u3001\u505c\u8f66\u4f4d\u7684\u68c0\u6d4b\u7b49\u7b49\u3002\n\n    11. \u51b3\u7b56\u7cfb\u7edf\uff08Planning andDecision\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u6bcf\u4e2a\u65e0\u4eba\u8f66\u7684\u52a8\u4f5c\u7684\u51b3\u7b56\uff0c\u6bd4\u5982\u52a0\u901f\u3001\u5239\u8f66\u3001\u6362\u7ebf\u3001\u8d85\u8f66\u3001\u8c03\u5934\u7b49\u7b49\u3002\n        \u7814\u7a76\u7684\u524d\u6cbf\u4e00\u822c\u6d89\u53ca\u5728\u9ad8\u901f\u884c\u9a76\u4e2d\u5982\u4f55\u5b89\u5168\u7684\u6362\u7ebf\uff0c\u5728\u901a\u8fc7\u89c6\u89c9\u7406\u89e3\u4e86\u573a\u666f\u540e\u5982\u4f55\u51b3\u7b56\uff0c\u5728\u611f\u77e5\u4fe1\u606f\u7f3a\u5931\u7684\u65f6\u5019\uff08\u6bd4\u5982\u5728\u96a7\u9053\u91cc\u9762\uff09\u5982\u4f55\u51b3\u7b56\u7b49\u7b49\u3002\n\n    12. \u4e3b\u52a8\u4e0e\u88ab\u52a8\u5b89\u5168\uff08Active andPassive Safety\uff09\uff1a\n        \u4e3b\u8981\u6d89\u53ca\u5982\u4f55\u901a\u8fc7\u4e0d\u540c\u4f20\u611f\u5668\u7684\u611f\u77e5\u53bb\u786e\u4fdd\u65e0\u4eba\u9a7e\u9a76\u4ee5\u53ca\u884c\u4eba\u5b89\u5168\uff0c\n        \u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u7814\u7a76\u5305\u62ec\u901a\u8fc7\u5bf9 CAN \u603b\u7ebf\u7684\u5f02\u5e38\u68c0\u6d4b\u53bb\u8bc4\u4f30\u8f66\u8f86\u7684\u5b89\u5168\u6027\uff0c\u901a\u8fc7\u5bf9\u505c\u8f66\u573a\u7684\u89c6\u9891\u76d1\u63a7\u53bb\u8bad\u7ec3\u81ea\u52a8\u6cca\u8f66\u6a21\u578b\u7b49\u7b49\u3002\n\n    13. \u65e0\u4eba\u8f66\u4e0e\u4ea4\u901a\u7684\u4ea4\u4e92\uff08AutonomousVehicles: Interaction with Traffic\uff09\uff1a\n        \u4e3b\u8981\u7814\u7a76\u65e0\u4eba\u8f66\u5982\u4f55\u4e0e\u73b0\u6709\u7684\u4ea4\u901a\u751f\u6001\u5171\u5b58\uff0c\u7279\u522b\u662f\u4f20\u7edf\u8f66\u4e0e\u65e0\u4eba\u8f66\u7684\u5171\u5b58\u3002\n        \u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u7814\u7a76\u5305\u62ec V2X \u865a\u62df\u4ea4\u901a\u6807\u5fd7\uff0c\u901a\u8fc7\u89c6\u89c9\u53bb\u8bc4\u4f30\u65c1\u8fb9\u8f66\u9053\u53f8\u673a\u7684\u9a7e\u9a76\u884c\u4e3a\u7b49\u7b49\u3002\n\n    14. \u89c6\u89c9\u5b9a\u4f4d\uff08SLAM and VisualOdometry\uff09\uff1a\n        \u4e3b\u8981\u7814\u7a76\u5982\u4f55\u7528\u89c6\u89c9\u4e0e\u6fc0\u5149\u96f7\u8fbe\u8fdb\u884c\u5b9e\u65f6\u5b9a\u4f4d\u4e0e\u5efa\u56fe\u3002\n        \u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u7814\u7a76\u5305\u62ec\u89c6\u89c9\u7684\u7ebf\u4e0a\u6821\u51c6\uff0c\u4f7f\u7528\u8f66\u9053\u7ebf\u8fdb\u884c\u5b9e\u65f6\u5b9a\u4f4d\u4e0e\u5bfc\u822a\u7b49\u7b49\u3002\n\n    15. \u73af\u5883\u5b66\u4e60\u4e0e\u5efa\u56fe\uff08Mapping andLearning the Environment\uff09\uff1a\n        \u4e3b\u8981\u7814\u7a76\u5982\u4f55\u5efa\u7acb\u7cbe\u51c6\u7684\u73af\u5883\u4fe1\u606f\u56fe\u3002\u6bd4\u8f83\u6709\u8da3\u7684\u4e00\u4e9b\u7814\u7a76\u5305\u62ec\u4f7f\u7528\u4f4e\u7a7a\u65e0\u4eba\u673a\u53bb\u521b\u5efa\u7ed9\u65e0\u4eba\u9a7e\u9a76\u4f7f\u7528\u7684\u5730\u56fe\uff0c\n        \u4ee5\u53ca\u901a\u8fc7\u505c\u8f66\u573a\u76d1\u63a7\u6444\u50cf\u5934\u5efa\u7acb\u8f85\u52a9\u81ea\u52a8\u6cca\u8f66\u7684\u5730\u56fe\u7b49\u7b49\u3002\n\n## \u65e0\u4eba\u9a7e\u9a76\u9762\u8bd5\u77e5\u8bc6\u70b9\n[\u53c2\u8003\u535a\u5ba2](https://blog.csdn.net/xiangxianghehe/article/details/82528180)\n```\n1. \u6df1\u5ea6\u5b66\u4e60\u76f8\u5173\n    \u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u7684\u533a\u522b\uff0c\u5404\u81ea\u9002\u7528\u4e8e\u4ec0\u4e48\u95ee\u9898\n    CNN\u57fa\u672c\u539f\u7406\uff0cCNN\u7684\u90a3\u4e9b\u90e8\u5206\u662f\u795e\u7ecf\u5143\n    CNN\u53bb\u6389\u6fc0\u6d3b\u51fd\u6570\u4f1a\u600e\u4e48\u6837\n    \u4ecb\u7ecdYOLO/SSD/RCNN/Faster-RCNN/Mask-RCNN\u7b97\u6cd5\n    YOLO v1/v2/v3 \u533a\u522b\u7ec6\u8282\uff0cSSD\u5982\u4f55\u6539\u8fdb\u6709\u601d\u8003\u8fc7\u561b\uff0c\u77e5\u9053DSSD\u548cFSSD\u561b\n    \u662f\u5426\u4e86\u89e3RPN\uff0cRoI pooling,\u548cRoIAlign\n    YOLO/SSD\u91cc\u9762\u6709\u5168\u8fde\u63a5\u5c42\u561b\n    YOLO/SSD\u7b97\u6cd5\u601d\u60f3\u5982\u4f55\u7528\u5230\u4e09\u7ef4\u70b9\u4e91\u76ee\u6807\u68c0\u6d4b\n    \u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5one-stage\u548ctwo-stage\u533a\u522b\u70b9\u5728\u54ea\u91cc\n    two-stage\u7b97\u6cd5\u76f8\u6bd4\u4e8eone-stage\u6709\u4f55\u4f18\u52bf\n    \u5355\u5f20\u56fe\u7247\u7269\u4f53\u8d8a\u591a\u8d8a\u5bc6\u96c6\uff0cYOLO/SSD/Faster-RCNN\u4e2d\u8ba1\u7b97\u91cf\u662f\u5426\u4e5f\u968f\u7740\u589e\u52a0\n    CVPR/ECCV 2018 \u6700\u65b0\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u6709\u4e86\u89e3\u8fc7\u561b\n    \u5982\u4f55\u7406\u89e3\u4e0a\u91c7\u6837\uff0c\u548c\u4e0b\u91c7\u6837\u7684\u533a\u522b\u662f\u4ec0\u4e48\n    \u4e0a\u91c7\u6837(UNSampling)\u4e0e\u4e0a\u6c60\u5316(UnPooling)\u533a\u522b\n    \u5168\u8fde\u63a5\u5c42\u7406\u8bba\u4e0a\u53ef\u4ee5\u66ff\u4ee3\u5377\u79ef\u5c42\u561b\n    \u795e\u7ecf\u7f51\u7edc\u91cc\u9762\u53ef\u4ee5\u7528\u4ec0\u4e48\u65b9\u6cd5\u66ff\u6362\u6389pooling\n    \u795e\u7ecf\u7f51\u7edc\u63d0\u53d6\u7279\u5f81\u7684\u65b9\u5f0f\u6709\u54ea\u4e9b\n    \u4ecb\u7ecd\u4e0b\u4f60\u4e86\u89e3\u7684\u8f7b\u91cf\u7ea7CNN\u6a21\u578b\n    \u7f51\u7edc\u6a21\u578b\u538b\u7f29\u65b9\u9762\u7684\u526a\u679d\uff0c\u91cf\u5316\u548c\u4e8c\u503c\u5316\u7f16\u7801\n    \u57fa\u4e8e\u89c6\u9891\u7684C3D\u4e09\u7ef4\u7f51\u7edc\u6a21\u578b\u6709\u542c\u8bf4\u8fc7\u561b\n    2.5D\u5377\u79ef\u5462\n    \u4ec0\u4e48\u662f\u7a7a\u6d1e\u5377\u79ef\uff0c\u4ec0\u4e48\u662f\u53cd\u5377\u79ef\uff0c\u4f5c\u7528\u662f\u4ec0\u4e48\n    \u5982\u4f55\u4e00\u5f20RGB\u56fe\u7247\u751f\u6210\u4e09\u7ef4\u6a21\u578b\n    PNG/JPG\u5b58\u50a8\u56fe\u50cf\u7684\u539f\u7406\n    global average pooling \u548caverage pooling\u533a\u522b\n    FPN\u7684\u539f\u7406\uff0c\u4e3a\u4ec0\u4e48\u4e0d\u540c\u5c3a\u5ea6feature map\u878d\u5408\u4f1a\u6709\u6548\u679c\u63d0\u5347\n    \u65e0\u76d1\u7763/\u534a\u76d1\u7763\u6df1\u5ea6\u5b66\u4e60\u6709\u4e86\u89e3\u8fc7\u561b\n    GAN\u7684\u539f\u7406\n    \u57fa\u4e8eRGB\u56fe\u7684\u6df1\u5ea6\u4fe1\u606f\u4f30\u8ba1\u6709\u4e86\u89e3\u8fc7\u561b\n    MobileNet V1/V2\u533a\u522b\n    ShuffleNet\u548cSqueezeNet\n    \u6a21\u578b\u91cf\u5316\u65b9\u6cd5\u6709\u54ea\u4e9b\n    \u53cc\u7ebf\u6027\u63d2\u503c\uff0c\u91cf\u5316\u5bf9\u9f50\n    Relu\u4e3a\u4ec0\u4e48\u6bd4sigmod\u597d\n    \u76ee\u6807\u8bc6\u522b\u7b97\u6cd5\u5e38\u7528\u8bc4\u6d4b\u65b9\u5f0f\n    IOU\u548cmAP\uff0cAUC\u548cROC\u5206\u522b\u662f\u4ec0\u4e48\n    \u4ecb\u7ecd\u4e0b\u5e38\u89c1\u635f\u5931\u51fd\u6570\uff0csoftmax\u4e00\u822c\u548c\u54ea\u4e2a\u6fc0\u6d3b\u51fd\u6570\u4f7f\u7528\n    \u4ecb\u7ecd\u4e0bPointNet/PointNet++/VoxelNet\u4ee5\u53ca\u4ed6\u4eec\u7684\u4f18\u7f3a\u70b9\n    PointCNN\u4ecb\u7ecd\u4e00\u4e0b\n    \u65cb\u8f6c\u77e9\u9635\u662f\u4ec0\u4e48\uff0c\u6709\u4ec0\u4e48\u6027\u8d28\uff0cPointNet\u4e2dT-Net\u65cb\u8f6c\u77e9\u9635\u7684\u635f\u5931\u51fd\u6570\u5982\u4f55\u8bbe\u8ba1\n    \u5982\u4f55\u8ba1\u7b97\u65cb\u8f6c\u77e9\u9635\n    \u4ecb\u7ecd\u4e0b\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5e38\u89c1\u7684\u53c2\u6570\u7c7b\u7b97\u6cd5\u548c\u975e\u53c2\u6570\u7c7b\u7b97\u6cd5\n    \u968f\u673a\u68af\u5ea6\u4e0b\u964d\n    \u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u5982\u4f55\u89e3\u51b3\u8fc7\u62df\u5408\u548c\u6b20\u62df\u5408\n    L1\u6b63\u5219\u5316\u548cL2\u6b63\u5219\u5316\u533a\u522b\uff0c\u5177\u4f53\u6709\u4f55\u7528\u9014\n    L1\u6b63\u5219\u5316\u76f8\u6bd4\u4e8e L2\u6b63\u5219\u5316\u4e3a\u4f55\u5177\u6709\u7a00\u758f\u89e3\n    \n2. C++\u5f00\u53d1\u76f8\u5173\n    c++\u5e38\u89c1\u5bb9\u5668\uff0cvector\u5bb9\u5668capacity\u548csize\u533a\u522b\uff0c\u5982\u4f55\u52a8\u6001\u589e\u957f\n    vector\u904d\u5386\u6709\u54ea\u51e0\u79cd\u65b9\u5f0f\uff08\u5c3d\u53ef\u80fd\u591a\uff09\n    cv:Mat \u6709\u51e0\u79cd\u8bbf\u95ee\u65b9\u5f0f\n    map\u5bb9\u5668\u589e\u5220\u6539\u67e5\uff0c\u548cunorder_map\u533a\u522b\uff0cmap\u5e95\u5c42\u5982\u4f55\u5b9e\u73b0\n    c++\u667a\u80fd\u6307\u9488\n    c++14/17\u65b0\u7279\u6027\n    c++\u548cc\u8bed\u8a00\u533a\u522b\n    c++\u5982\u4f55\u5b9e\u73b0\u591a\u6001\uff0c\u6709\u51e0\u79cd\u65b9\u5f0f\uff0c\u52a8\u6001\u591a\u6001\u548c\u9759\u6001\u591a\u6001\u533a\u522b\n    \u6a21\u677f\u4e86\u89e3\u561b\n    c++\u7ee7\u627f\u591a\u6001\n    c++\u6df1\u62f7\u8d1d\u4e0e\u6d45\u62f7\u8d1d\n    \u62f7\u8d1d\u6784\u9020\u51fd\u6570\u548c\u59d4\u6258\u6784\u9020\u51fd\u6570\n    c++\u9762\u5411\u5bf9\u8c61\n    \u53f3\u503c\u5f15\u7528\uff0cmove\u8bed\u4e49\uff0c\u5b8c\u7f8e\u8f6c\u53d1\n    emplace_back\u548cpush_back\u533a\u522b\n    Eigen\u5e93\u4e86\u89e3\u561b\n    \u5982\u4f55\u5b9e\u73b0\u4e00\u4e2ac++\u7684\u5355\u4f8b\u6a21\u5f0f\n    \u5185\u8054\u51fd\u6570\u548c\u5b8f\u7684\u533a\u522b\n    \u5982\u4f55\u5b9e\u73b0\u4e00\u4e2a\u53ea\u5728\u5806\u6216\u8005\u6808\u4e0a\u521d\u59cb\u5316\u7684\u7c7b\n    \u5982\u4f55\u67e5\u627e\u5bb9\u5668\u5185\u6240\u6709\u7b26\u5408\u6761\u4ef6\u7684\u5143\u7d20\n    \n3. Python\u5f00\u53d1\u76f8\u5173\n    list tuple\u533a\u522b\n    \u751f\u6210\u5668\u548c\u8fed\u4ee3\u5668\n    Python\u7c7b\u7684\u5b9a\u4e49\u548c\u5b9e\u4f8b\u5316\u65b9\u6cd5\n    \n4. \u6570\u636e\u7ed3\u6784\u76f8\u5173\n    \u7ea2\u9ed1\u6811\u7ed3\u6784\uff0c\u67e5\u627e\u65f6\u95f4\u590d\u6742\u5ea6\n    \u5806\u6392\u5e8f\u7684\u65f6\u95f4\u590d\u6742\u5ea6\n    Top K\u6392\u5e8f\n    \u5982\u4f55\u7528O(1)\u590d\u6742\u5ea6\u67e5\u627e\u5230stack\u91cc\u9762\u7684\u6700\u5c0f\u503c\n    \u516b\u7687\u540e\n    C++\u81ea\u5df1\u5b9e\u73b0\u4e00\u4e2a\u961f\u5217\n    \u6570\u7ec4\u548c\u94fe\u8868\u7684\u533a\u522b\n    \u4ec0\u4e48\u662fkd-tree\uff0c\u5982\u4f55\u5b9e\u73b0\n    \u9752\u86d9\u8df3\u53f0\u9636\u7684\u9012\u5f52\u548c\u975e\u9012\u5f52\u5b9e\u73b0\n    \n5. \u64cd\u4f5c\u7cfb\u7edf\u76f8\u5173\n    \u5982\u4f55\u8c03\u8bd5\u6808\u6ea2\u51fa\n    \u8ba1\u7b97\u673a\u5185\u5b58\u5806\u548c\u6808\u7684\u533a\u522b\n    \u7ebf\u7a0b\u540c\u6b65\u7684\u65b9\u5f0f\uff0c\u4e92\u65a5\u9501\u548c\u4fe1\u53f7\u91cf\u7684\u5bf9\u6bd4\n    \u8fdb\u7a0b\u548c\u7ebf\u7a0b\u7684\u533a\u522b\n    \u56fe\u7247\u5b58\u50a8\u539f\u7406\u4ecb\u7ecd\u4e00\u4e0b\n    \n6. \u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u76f8\u5173\n    Tensorflow\u7ed3\u6784\u6846\u67b6\uff0c\u5982\u4f55\u7528Tensorflow\u5b9e\u73b0\u4e00\u4e2a\u53cd\u5411\u6c42\u68af\u5ea6\n    Tensorflow\u5982\u4f55\u5408\u5e76\u4e24\u4e2aTensor\n    caffe\u548cPytorch\u4e86\u89e3\u561b\n    caffe\u548cTensorflow\u533a\u522b\u5728\u4ec0\u4e48\u5730\u65b9\n    Tensorflow serving\u548cTensorRT\u6709\u4e86\u89e3\u8fc7\u561b\n    caffe\u7ed3\u6784\u6846\u67b6\n    \n7. \u89c6\u89c9SLAM\u76f8\u5173\n    SLAM\u4e3b\u8981\u5206\u4e3a\u54ea\u51e0\u4e2a\u6a21\u5757\n    ORB-SLAM2\u7684\u4f18\u7f3a\u70b9\u5206\u6790\uff0c\u5982\u4f55\u6539\u8fdb\n    ORB\u548cFAST\u5bf9\u6bd4\n    BA\u548c\u5361\u5c14\u66fc\u6ee4\u6ce2\n    ORB-SLAM2\u7684\u4e09\u4e2a\u7ebf\u7a0b\u662f\u4ec0\u4e48\n    ORB-SLAM2\u7684\u5b9a\u4f4d\u5982\u4f55\u5b9e\u73b0\n    \u5982\u4f55\u7406\u89e3ORB-SLAM2\u7684\u56fe\u4f18\u5316\n    \u7ed3\u6784\u5149\u3001TOF\u3001\u53cc\u76ee\u89c6\u89c9\u539f\u7406\n    \u76f4\u63a5\u6cd5\u3001\u534a\u76f4\u63a5\u6cd5\u3001\u7279\u5f81\u70b9\u6cd5\u533a\u522b\u4e0e\u8054\u7cfb\n    Apollo\u7684\u611f\u77e5\u6a21\u5757\u539f\u7406\n    Apollo\u76842D\u548c3D\u8ddf\u8e2a\n    \u5982\u4f55\u6c42\u89e3\u65cb\u8f6c\u77e9\u9635\n    \u5982\u679c\u53ea\u670932\u7ebf\u96f7\u8fbe\uff0c\u4e2a\u6570\u4e0d\u9650\uff0c\u80fd\u5b9e\u73b0360\u5ea6\u89c6\u89d2\u8986\u76d6\u5417\uff0c\u5982\u4f55\u5b9e\u73b0\uff0c64\u7ebf\u5462\uff1f\n```\n\n##  \u516c\u53f8\n[\u89c6\u89c9\u9886\u57df\u7684\u90e8\u5206\u56fd\u5185\u516c\u53f8](http://www.ipcv.org/cvcom/)\n###  \u521d\u521b\u516c\u53f8\uff1a\n[\u56fe\u666e\u79d1\u6280](http://www.tuputech.com/)---[Face++](http://www.faceplusplus.com.cn/)---[Linkface](http://www.linkface.cn/index.html)---[Minieye](http://www.minieye.cc/cn/)---[\u77e5\u56feCogtu](http://www.cogtu.com/?lang=zh)---[\u5546\u6c64\u79d1\u6280Sensetime](http://www.sensetime.com/cn)---[\u4eae\u98ce\u53f0Hiscene](http://www.hiscene.com/)---[\u638c\u8d62\u79d1\u6280](http://www.zhangying.mobi/index.html)---[\u683c\u7075\u6df1\u77b3DeepPG](http://www.deepglint.com/)---[\u51cc\u611f\u79d1\u6280usens](http://www.lagou.com/gongsi/j114187.html)---[\u56fe\u68eeTuSimple](http://www.tusimple.com/)---[\u4e2d\u79d1\u89c6\u62d3Seetatech(\u5c71\u4e16\u5149)](http://www.seetatech.com/)---[\u7b2c\u56db\u8303\u5f0f](https://www.4paradigm.com/product/prophet)\n\n### \u4e0a\u5e02\u516c\u53f8\uff1a\n[\u767e\u5ea6DL\u5b9e\u9a8c\u5ba4](http://idl.baidu.com/)---[\u817e\u8baf\u4f18\u56fe](http://youtu.qq.com/)---[\u963f\u91cc\u9ad8\u5fb7](http://www.newsmth.net/nForum/#!article/Career_Upgrade/429476)---[\u66b4\u98ce\u9b54\u955c](http://www.newsmth.net/nForum/#!article/Career_PHD/225254)---[\u641c\u72d7](http://www.newsmth.net/nForum/#!article/Career_PHD/224449)---[\u4e50\u89c6tv](http://www.newsmth.net/nForum/#!article/Career_PHD/222651)---[\u5947\u864e360](http://www.newsmth.net/nForum/#!article/Career_PHD/222379)---[\u4eac\u4e1c\u5b9e\u9a8c\u5ba4](http://www.newsmth.net/nForum/#!article/Career_PHD/223133/a>)---[\u963f\u91cc\u5df4\u5df4](http://www.newsmth.net/nForum/#!article/Career_PHD/222007)---[\u8054\u60f3\u7814\u7a76\u9662](http://www.newsmth.net/nForum/#!article/Career_PHD/220225)---[\u534e\u4e3a\u7814\u7a76\u9662](http://www.newsmth.net/nForum/#!article/Career_PHD/225976)\n\n### \u77e5\u540d\u5916\u4f01\uff1a\n[\u4f73\u80fd\u4fe1\u606f](http://www.newsmth.net/nForum/#!article/Career_PHD/222548)---[\u7d22\u5c3c\u7814\u7a76\u9662](http://www.newsmth.net/nForum/#!article/Career_PHD/223437)---[\u5bcc\u58eb\u901a\u7814\u53d1\u4e2d\u5fc3](http://www.newsmth.net/nForum/#!article/Career_PHD/220654)---[\u5fae\u8f6f\u7814\u7a76\u9662](https://careers.microsoft.com/?rg=cn)---[\u82f1\u7279\u5c14\u7814\u7a76\u9662](http://www.newsmth.net/nForum/#!article/Career_PHD/221175)---[\u4e09\u661f\u7814\u7a76\u9662](http://www.yingjiesheng.com/job-001-742-124.html)\n\n\n\n## 0 \u8ba1\u7b97\u6444\u5f71\u3000\u6444\u5f71\u51e0\u4f55\n[\u8ba1\u7b97\u6444\u5f71\u65b9\u9762\u7684\u90e8\u5206\u8bfe\u7a0b\u8bb2\u4e49](http://www.ipcv.org/cp-lecture/)\n[\u76f8\u673a\u5185\u90e8\u56fe\u50cf\u5904\u7406\u6d41\u7a0b](http://www.comp.nus.edu.sg/~brown/ICIP2013_Brown.html)\n[pdf](http://www.comp.nus.edu.sg/~brown/ICIP2013_Tutorial_Brown.pdf)\n\n    \u76f8\u673a = \u5149\u6d4b\u91cf\u88c5\u7f6e(Camera = light-measuring device)\n        \u7167\u660e\u5149\u6e90(Illumination source)\uff08\u8f90\u5c04(radiance)\uff09 --> \n        \u573a\u666f\u5143\u7d20(Scene Element)   --->\n        \u6210\u50cf\u7cfb\u7edf(Imaging System)  --->\n        \u5185\u90e8\u56fe\u50cf\u5e73\u9762(Internal Image Plane) --->\n        \u8f93\u51fa\uff08\u6570\u5b57\uff09\u56fe\u50cf(Output (digital) image) \n    \u56fe\u50cf = \u8f90\u5c04\u80fd\u91cf\u6d4b\u91cf(Image = radiant-energy measurement)  \n    \n    \n    \u73b0\u4ee3\u6444\u5f71\u6d41\u6c34\u7ebf\u3000Modern photography pipeline \n    \u573a\u666f\u8f90\u5c04\u3000--->\u3000\u76f8\u673a\u524d\u7aef(\u955c\u5934\u8fc7\u6ee4\u5668 \u955c\u5934Lens \u5feb\u95e8Shutter \u5b54\u5f84)\u3000--->\u3000\n    \u76f8\u673a\u5185\u90e8(ccd\u54cd\u5e94response\uff08RAW\uff09 CCD\u63d2\u503cDemosaicing \uff08\u539f\uff09)\u3000--->\u3000\n    \u76f8\u673a\u540e\u7aef\u5904\u7406(\u76f4\u65b9\u56fe\u5747\u8861Hist equalization\u3001\u7a7a\u95f4\u626d\u66f2Spatial warping)--->\u3000\u8f93\u51fa\n    \n\n\n    \u900f\u8fc7\u68f1\u955c\u7684\u767d\u5149 \u3000\u201cWhite light\u201d through a prism  ------> \u6298\u5c04\u5149(Refracted light)----> \u5149\u8c31 Spectral \u3000\n    \u6211\u4eec\u7684\u773c\u775b\u6709\u4e09\u4e2a\u53d7\u4f53\uff08\u9525\u7ec6\u80de\uff09\uff0c\u5b83\u4eec\u5bf9\u53ef\u89c1\u5149\u4f5c\u51fa\u53cd\u5e94\u5e76\u4ea7\u751f\u989c\u8272\u611f\u3002\n    \n[CSC320S: Introduction to Visual Computing \u89c6\u89c9\u8ba1\u7b97\u5bfc\u8bba ](http://www.cs.toronto.edu/~kyros/courses/320/)\n\n[Facebook surround 360 \u300a\u5168\u666f\u56fe\u62fc\u63a5\u300b](https://github.com/facebook/Surround360)\n\n        \u8f93\u5165\uff1a17\u5f20raw\u56fe\u50cf\uff0c\u5305\u62ec14\u5f20side images\u30012\u5f20top images\u30011\u5f20bottom image\n        \u8f93\u51fa\uff1a3D\u7acb\u4f53360\u5ea6\u5168\u666f\u56fe\u50cf  \n[\u535a\u5ba2\u7b14\u8bb0](https://blog.csdn.net/electech6/article/details/53618965)   \n        \n\n[\u6df1\u5ea6\u6444\u5f71\u98ce\u683c\u8f6c\u6362 Deep Photo Style Transfer](https://github.com/luanfujun/deep-photo-styletransfer)\n\n### \u56fe\u50cf\u5f62\u53d8 Image warping\n[\u53c2\u8003](http://www.ipcv.org/image-warping/)\n### \u8272\u5f69\u589e\u5f3a/\u8f6c\u6362\u3000Color transfer\n[\u53c2\u8003](http://www.ipcv.org/colortransfer/)\n### \u56fe\u50cf\u4fee\u8865 Image repair\n[\u53c2\u8003](http://www.ipcv.org/imagerepair/)\n### \u56fe\u50cf\u53bb\u566a Image denoise\n[\u53c2\u8003](http://www.ipcv.org/imagedenoise/)\n### \u56fe\u50cf\u53bb\u6a21\u7cca Image deblur \n[\u53c2\u8003](http://www.ipcv.org/imagedeblur/)\n###  \u56fe\u50cf\u6ee4\u6ce2 Image filter\n[\u53c2\u8003](http://www.ipcv.org/imagefilter/)\n\n###  \u8d85\u5206\u8fa8\u7387 Super-resolution\n[\u53c2\u8003](http://www.ipcv.org/code-superresolution/)  \n\n\n## 1\u3000\u4e09\u7ef4\u91cd\u5efa 3D Modeling\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/3dd/)\n### \u76f8\u673a\u77eb\u6b63\u3000Camera calibration\n[\u53c2\u8003](http://www.ipcv.org/poseestimation/)\n### \u975e\u521a\u4f53\u91cd\u5efa\u3000Non-rigid modeling\u3000\n[\u53c2\u8003](http://www.ipcv.org/nonnigitreco/)\n### \u4e09\u7ef4\u91cd\u6784 3D modeling\n[\u53c2\u8003](http://www.ipcv.org/3dmodeling/)\n[\u89c6\u89c9SLAM](http://www.ipcv.org/on-visual-slam/)\n\n[Self-augmented Convolutional Neural Networks](https://github.com/msraig/self-augmented-net)\n\n[\u8fd0\u52a8\u4f30\u8ba1 motion estimation](http://www.ipcv.org/on-motion-estimation/)\n\n[\u9762\u90e8\u53d8\u5f62\u3000face morphing\u3000](http://www.ipcv.org/about-face-morphing/)\n\n[\u4e09\u7ef4\u91cd\u5efa\u65b9\u9762\u7684\u89c6\u89c9\u4eba\u7269](http://www.ipcv.org/people-3d-modeling/)\n\n\n## 2  \u5339\u914d/\u8ddf\u8e2a Matching & Tracking\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/tracking/)\n\n### 2.a \u7279\u5f81\u63d0\u53d6 Feature extraction\n[\u53c2\u8003](http://www.ipcv.org/featureextraction/)\n\n### 2.b \u7279\u5f81\u5339\u914d Feature matching\n[\u53c2\u8003](http://www.ipcv.org/code-featmatching/)\n\n### 2.c \u65f6\u7a7a\u5339\u914d Space-time matching\n[\u53c2\u8003](http://www.ipcv.org/code-spacetimematching/)\n\n### 2.d \u533a\u57df\u5339\u914d Region matching\n[\u53c2\u8003](http://www.ipcv.org/code-regionmatching/)\n\n### 2.e \u8f6e\u5ed3\u5339\u914d Contour matching\n[\u53c2\u8003](http://www.ipcv.org/code-coutourmatching/)\n\n### 2.f \u7acb\u4f53\u5339\u914d Stereo matching \n[\u53c2\u8003](http://www.ipcv.org/code-stereomatching/)\n\n[\u53cc\u76ee\u89c6\u89c9\u81ea\u52a8\u9a7e \u573a\u666f\u7269\u4f53\u8ddf\u8e2apaper](http://www.cvlibs.net/publications/Menze2015CVPR.pdf)\n\n[kitti\u53cc\u76ee\u6570\u636e\u96c6\u89e3\u51b3\u65b9\u6848](http://www.cvlibs.net/datasets/kitti/eval_scene_flow.php?benchmark=stereo)\n\n[\u5c06\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7528\u4e8e\u5c062D\u7535\u5f71\u8f6c\u6362\u4e3a3D\u7535\u5f71\u7684\u8f6c\u6362](https://github.com/piiswrong/deep3d)\n\n[\u795e\u7ecf\u7f51\u7edc\u3000\u53cc\u76ee\u5339\u914d](https://github.com/jzbontar/mc-cnn)\n\n\n[\u4e2d\u5c71\u5927\u5b66\u5f20\u5f1b\u535a\u58eb](http://chizhang.me/)\n\n    MeshStereo: A Global Stereo Model with Mesh Alignment Regularization for View Interpolation\n    1\u3001\u8ba8\u8bba\u4e86\u7acb\u4f53\u89c6\u89c9\u5339\u914d\uff08Stereo Matching\uff09\u95ee\u9898\u7684\u5b9a\u4e49\u53ca\u5176\u4e0e\u4eba\u773c\u611f\u77e5\u6df1\u5ea6\u7684\u5173\u7cfb\uff1b\n    2\u3001\u5bf9Matching Cost Volume\u8fdb\u884c\u4e86\u53ef\u89c6\u5316\u5206\u6790\uff0c\u4ee5\u671f\u671b\u8fbe\u5230\u542c\u8005\u5bf9\u5176\u7684\u76f4\u89c2\u4e14\u672c\u8d28\u7684\u7406\u89e3\uff1b\n    3\u3001\u8ba8\u8bba\u4e86\u7acb\u4f53\u89c6\u89c9\u5339\u914d\u95ee\u9898\u4e2d\u7684\u56db\u4e2a\u7ecf\u5178\u65b9\u6cd5\uff08\n        Graph Cut\uff0cAdaptive Support Weight Aggregation, \n        Semi-Global Matching, \n        \u4ee5\u53ca PatchMatch Stereo\uff09\uff1b\n    4\u3001\u8ba8\u8bba\u4e86MeshStereo\u7684\u8bd5\u56fe\u7edf\u4e00disparity\u6c42\u89e3\u4ee5\u53ca\u7f51\u683c\u751f\u6210\u4e24\u4e2a\u6b65\u9aa4\u7684motivation\uff0c\n        \u4ee5\u53caformulate\u8fd9\u6837\u4e00\u4e2aunified model\u4f1a\u9047\u5230\u7684\u56f0\u96be\uff1b\n    5\u3001\u8ba8\u8bba\u4e86MeshStereo\u5f15\u5165splitting probability\u7684\u89e3\u51b3\u65b9\u6848\u53ca\u5176\u4f18\u5316\u8fc7\u7a0b\u3002\n    \n    Webinar\u6700\u540e\u5c55\u793a\u4e86MeshStereo\u5728\u6df1\u5ea6\u4f30\u8ba1\u4ee5\u53ca\u65b0\u89c6\u89d2\u6e32\u67d3\u4e24\u4e2a\u4efb\u52a1\u4e2d\u7684\u7ed3\u679c\u3002\n\n\n[Stereo Matching Using Tree Filtering non-local\u7b97\u6cd5\u5728\u53cc\u76ee\u7acb\u4f53\u5339\u914d\u4e0a\u7684\u5e94\u7528 ](https://blog.csdn.net/wsj998689aa/article/details/45584725)\n\n\n\n\n### 2.g \u6df1\u5ea6\u5339\u914d depth matching \n[\u6df1\u5ea6\u5339\u914d depth matching ](http://www.ipcv.org/on-depth-matching/)\n\n### 2.h \u59ff\u6001\u8ddf\u8e2a Pose tracking \n[\u53c2\u8003](http://www.ipcv.org/code-posetracking/)\n\n### 2.i \u7269\u4f53\u8ddf\u8e2a Object tracking\n[\u53c2\u8003](http://www.ipcv.org/code-objtracking/)\n\n### 2.j \u7fa4\u4f53\u5206\u6790 Crowd analysis\n[\u53c2\u8003](http://www.ipcv.org/code-crowdanalysis/)\n[\u7fa4\u4f53\u8fd0\u52a8\u5ea6\u91cf](https://github.com/metalbubble/collectiveness)\n\n### 2.k \u5149\u6d41\u573a\u8ddf\u8e2a Optical flow\n[\u53c2\u8003](http://www.ipcv.org/code-opticalflow/)\n\n\n## 3 \u8bed\u4e49/\u5b9e\u4f8b\u5206\u5272&\u89e3\u6790\u3000Segmentation & Parsing\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/parsing/)\n### 3.a \u89c6\u9891\u5206\u5272  Video  segmentation\n[\u53c2\u8003](http://www.ipcv.org/video-segmentation/)\n\n### 3.b \u4eba\u4f53\u89e3\u6790  Person parsing\n[\u53c2\u8003](http://www.ipcv.org/code-poseparsing/)\n\n[person parsing](http://www.ipcv.org/about-person-parsing/)\n\n### 3.c \u573a\u666f\u89e3\u6790  Scene  parsing\n[scene parsing](http://www.ipcv.org/about-scene-parsing/)\n[\u53c2\u8003](http://www.ipcv.org/code-sceneparsing/)\n\n### 3.d \u8fb9\u7f18\u68c0\u6d4b  Edge   detection\n[\u53c2\u8003](http://www.ipcv.org/code-edgedetection/)\n[\u8fb9\u7f18\u68c0\u6d4b](http://www.ipcv.org/on-edge-detection/)\n\n\n### 3.e \u56fe\u50cf\u7269\u4f53\u5206\u5272 Image object segmentation \n[\u53c2\u8003](http://www.ipcv.org/code-imobjseg/)\n \n### 3.f \u89c6\u9891\u7269\u4f53\u5206\u5272 Video object segmentation\n[\u53c2\u8003](http://www.ipcv.org/code-viobseg/)\n[object segmentation](http://www.ipcv.org/about-video-object-segmentation/)\n\n\n### 3.g \u4ea4\u4e92\u5f0f\u5206\u5272   Interactive segmentation\n[\u53c2\u8003](http://www.ipcv.org/code-intseg/)\n\n### 3.h \u5171\u5206\u5272      Co-segmentation\n[\u53c2\u8003](http://www.ipcv.org/code-cosegmentation/)\n\n### 3.i \u80cc\u666f\u5dee      Background subtraction \n[\u53c2\u8003](http://www.ipcv.org/code-backsub/)\n\n### 3.j \u56fe\u50cf\u5206\u5272\u65b9\u9762 Image segmentation\n[\u53c2\u8003](http://www.ipcv.org/code-imgseg/)\n \n\n## 4 \u8bc6\u522b/\u68c0\u6d4b\u3000Recognition & Detection\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/detect/)\n###  4.a \u5176\u4ed6\u8bc6\u522b Other recognition\n[\u53c2\u8003](http://www.ipcv.org/otherrecog/)\n\n### 4.b \u56fe\u50cf\u68c0\u7d22 Image retrieval\n[\u53c2\u8003](http://www.ipcv.org/%e5%9b%be%e5%83%8f%e6%a3%80%e7%b4%a2/)\n\n### 4.c \u663e\u8457\u68c0\u6d4b Saliency detection\n[\u53c2\u8003](http://www.ipcv.org/saldetection/)\n\n### 4.d \u901a\u7528\u7269\u4f53\u68c0\u6d4b Object proposal\n[\u53c2\u8003](http://www.ipcv.org/code-objproposal/)\n\n### 4.e \u884c\u4e3a\u8bc6\u522b Action recognition\n[\u53c2\u8003](http://www.ipcv.org/code-actionrecogntion/)\n\n### 4.f \u7269\u4f53\u8bc6\u522b Object recognition\n[\u53c2\u8003](http://www.ipcv.org/code-objrecogntion/)\n\n### 4.g \u884c\u4eba\u68c0\u6d4b Human detection\n[\u53c2\u8003](http://www.ipcv.org/code-humandetection/)\n\n### 4.h \u4eba\u8138\u89e3\u6790 Face Parsing\n[\u53c2\u8003](http://www.ipcv.org/code-facerecog/)\n\n### 4.i \u7eb9\u7406\u5206\u6790 Texture Analysis\n[\u7eb9\u7406\u5206\u6790 Texture Analysis](http://www.ipcv.org/on-texture-analysis/)\n[\u76f8\u5173\u4eba\u7269](http://www.ipcv.org/people-reidentity/)\n\n## 5 \u673a\u5668\u5b66\u4e60 Maching Learning\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/ml/)\n\n### 5.a \u751f\u6210\u5bf9\u6297\u7f51\u7edc GAN Generative Adversarial Networks\n[\u53c2\u8003](http://www.ipcv.org/adversarial-networks/)\n\n### 5.b \u6df1\u5ea6\u5b66\u4e60    Deep learning \n[\u53c2\u8003](http://www.ipcv.org/deeplearning/)\n[\u6df1\u5ea6\u5b66\u4e60\u65b9\u9762\u7684\u90e8\u5206\u8bfe\u7a0b\u8bb2\u4e49](http://www.ipcv.org/lecture-deeplearning/)\n\n[CNN Models \u5377\u79ef\u7f51\u7edc\u6a21\u578b](http://www.ipcv.org/on-object-detection/)\n\n[Deep Learning Libraries\u3000\u6df1\u5ea6\u5b66\u4e60\u8f6f\u4ef6\u5e93](http://www.ipcv.org/deep_learning_libraries/)\n\n[\u6df1\u5ea6\u5b66\u4e60\u65b9\u9762\u7684\u90e8\u5206\u89c6\u89c9\u4eba\u7269](http://www.ipcv.org/dl-researcher/)\n\n### 5.c \u80fd\u91cf\u4f18\u5316    Energy optimization \n[\u53c2\u8003](http://www.ipcv.org/energyopt/)\n\n### 5.d \u6a21\u578b\u8bbe\u8ba1    Model design\n[\u53c2\u8003](http://www.ipcv.org/modelbuilding/)\n\n### 5.e \u7a7a\u95f4\u964d\u7ef4    Dimention reduction \n[\u53c2\u8003](http://www.ipcv.org/dimention/)\n\n### 5.f \u805a\u7c7b       Clustering \n[\u53c2\u8003](http://www.ipcv.org/clustering/)\n\n### 5.g \u5206\u7c7b\u5668     Classifier\n[\u53c2\u8003](http://www.ipcv.org/classifier/)\n\n## 6 \u5f00\u6e90\u5e93\u3000Open library\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/lib/)\n###\n###\n\n\n## 7 \u6570\u636e\u96c6\u3000Public dataset\n[\u53c2\u8003](http://www.ipcv.org/category/code-data/dataset/)\n### 7.a \u5176\u4ed6\u65b9\u9762 Other datasets\n[\u53c2\u8003](http://www.ipcv.org/otherdb/)\n[\u4eba\u8138\u68c0\u6d4bFace tracking and recognition database ](http://seqam.rutgers.edu/site/index.php?option=com_content&view=article&id=65&Itemid=76)\n\n[\u4eba\u8138\u68c0\u6d4bCaltech 10,000 Web Faces](http://vision.caltech.edu/archive.html)\n\n[\u4eba\u8138\u68c0\u6d4bHelen dataset](http://www.ifp.illinois.edu/~vuongle2/helen/)\n\n[\u6df1\u5ea6\u56fe RGB-D dataset](http://mobilerobotics.cs.washington.edu/projects/kdes/)\n\n[\u89c6\u9891\u5206\u5272 2010 ECCV Efficient Hierarchical Graph Based Video Segmentation](http://www.cc.gatech.edu/cpl/projects/videosegmentation/)\n\n[\u624b\u52bf\u8ddf\u8e2a Hand dataset](https://engineering.purdue.edu/RVL/Database.html)\n\n[\u624b\u52bf\u8ddf\u8e2a2](http://www.robots.ox.ac.uk/~vgg/research/hands/index.html)\n\n[\u8f66\u8f86\u68c0\u6d4b 2002 ECCV Learning a sparse representation for object detection](http://cogcomp.cs.illinois.edu/Data/Car/)\n\n### 7.b \u4eba\u4f53\u68c0\u6d4b dataset on human annotation\n[\u53c2\u8003](http://www.ipcv.org/humandetection/)\n[Caltech Pedestrian Detection Benchmark](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/)\n\n[Ethz](http://www.vision.ee.ethz.ch/~aess/dataset/)\n[bleibe](http://www.vision.ee.ethz.ch/~bleibe/data/datasets.html)\n\n[RGB-D People Dataset](http://www.informatik.uni-freiburg.de/~spinello/RGBD-dataset.html)\n\n[TUD Campus](http://www.d2.mpi-inf.mpg.de/tud-brussels)\n[382](https://www.d2.mpi-inf.mpg.de/node/382)\n\n[PSU HUB Dataset](http://www.cse.psu.edu/~rcollins/software.html)\n\n[Pedestrian parsing](http://vision.ics.uci.edu/datasets/)\n\n[Human Eva](http://vision.cs.brown.edu/humaneva/)\n\n\n### 7.c \u7269\u4f53\u8bc6\u522b dataset on object recognition\n\n[\u53c2\u8003](http://www.ipcv.org/objectrecognition/)\n\n[ e-Lab Video Data Set](https://engineering.purdue.edu/elab/eVDS/)\n\n[Image Net](http://www.image-net.org/)\n\n[Places2 Database](http://places2.csail.mit.edu)\n\n[Microsoft CoCo: Common Objects in Context](http://mscoco.org/)\n\n[PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)\n[MIT\u2019s Place2]( http://places2.csail.mit.edu/)\n\n### 7.d \u663e\u8457\u68c0\u6d4b\u65b9\u9762 dataset on saliency detection\n[\u53c2\u8003](http://www.ipcv.org/saliencydetection/)\n\n[\u89c6\u89c9\u663e\u8457\u6027\u68c0\u6d4b\u6280\u672f\u53d1\u5c55\u60c5\u51b5](http://blog.csdn.net/anshan1984/article/details/8657176)\n\n[2012 ECCV Salient Objects Dataset (SOD)](http://elderlab.yorku.ca/SOD/)\n\n[2012 ECCV Neil D. B. Bruce Eye Tracking Data](http://cs.umanitoba.ca/~bruce/datacode.html)\n\n[2012 ECCV DOVES:A database of visual eye movements](http://live.ece.utexas.edu/research/doves/)\n\n[2012 ECCV MSRA:Salient Object Database](http://research.microsoft.com/en-us/um/people/jiansun/SalientObject/salient_object.htm)\n\n[2012 ECCV NUS: Predicting Saliency Beyond Pixels](http://www.ece.nus.edu.sg/stfpage/eleqiz/predicting.html)\n\n[2012 ECCV saliency benchmark](http://people.csail.mit.edu/tjudd/SaliencyBenchmark/index.html)\n\n[2010 ECCV The DUT-OMRON Image Dataset](http://ice.dlut.edu.cn/lu/DUT-OMRON/Homepage.htm)\n\n[2010 ECCV An eye fixation database for saliency detection in images](http://mmas.comp.nus.edu.sg/NUSEF.html)\n\n### 7.e \u884c\u4e3a\u8bc6\u522b dataset on action recognition\n[\u53c2\u8003](http://www.ipcv.org/actionrecognition/)\n\n[UCF](http://www.cs.ucf.edu/~liujg/YouTube_Action_dataset.html)\n[ChaoticInvariants](http://www.cs.ucf.edu/~sali/Projects/ChaoticInvariants/index.html)\n[datasetsActions](http://vision.eecs.ucf.edu/datasetsActions.html)\n\n[Hollywood Human Actions dataset](http://www.di.ens.fr/~laptev/download.html)\n[data](http://lear.inrialpes.fr/data)\n\n[Weizmann: Actionsas Space-Time Shapes](http://www.wisdom.weizmann.ac.il/~vision/SpaceTimeActions.html)\n\n[KTH](http://www.nada.kth.se/cvap/actions/)\n\n[UMD](http://www.umiacs.umd.edu/~zhuolin/Keckgesturedataset.html)\n\n[HMDB: A Large Video Database for Human Motion Recognition](http://serre-lab.clps.brown.edu/resources/HMDB/related_data/)\n\n[Collective Activity Dataset](http://www.eecs.umich.edu/vision/activity-dataset.html)\n\n[MSR Action Recognition Datasets and Codes](http://research.microsoft.com/en-us/um/people/zliu/ActionRecoRsrc/default.htm)\n\n[Visual Event Recognition in Videos](http://vc.sce.ntu.edu.sg/index_files/VisualEventRecognition/VisualEventRecognition.html)\n\n\n\n### 7.f \u7269\u4f53\u5206\u5272 dataset on object segmentation\n[\u53c2\u8003](http://www.ipcv.org/objectsegmentation/)\n[microsoft MSRC-V2](http://research.microsoft.com/en-us/projects/objectclassrecognition/)\n\n[2010 CVPR iCoseg: Interactive cosegmentation by touch](http://chenlab.ece.cornell.edu/projects/touch-coseg/)\n\n[2010 CVPR Caltech-UCSD Birds 200](http://www.vision.caltech.edu/visipedia/CUB-200.html)\n\n[2010 CVPR Flower Datasets](http://www.robots.ox.ac.uk/~vgg/data/flowers/)\n\n[2009 ICCV An efficient algorithm for co-segmentation](http://www.biostat.wisc.edu/~vsingh/)\n\n[2008 CVPR Unsupervised Learning of Probabilistic Object Models (POMs) for Object Classification, Segmentation and Recognition](http://people.csail.mit.edu/leozhu/)\n\n[2008 CVPR Caltech101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n\n[2004 ECCV The Weizmann Horse Database](http://www.msri.org/people/members/eranb/)\n\n\n### 7.g \u573a\u666f\u89e3\u6790 dataset on scene parsing\n[\u53c2\u8003](http://www.ipcv.org/sceneparsing/)\n\n[ImageNet](http://www.image-net.org/)\n\n[ADE 20k](http://sceneparsing.csail.mit.edu/)\n\n[Cityscapes](https://www.cityscapes-dataset.com/)\n\n[COCO](http://cocodataset.org/#home)\n\n[Lab, Koch](http://www.mis.tu-darmstadt.de/tudds)\n\n[uiuc, D hoiem](http://www.cs.illinois.edu/homes/dhoiem/)\n\n[mit, cbcl](http://cbcl.mit.edu/software-datasets/streetscenes/)\n\n[mit LabelMeVideo](http://labelme.csail.mit.edu/LabelMeVideo/)\n\n[2013 BMVC Hierarchical Scene Annotation](http://www.vision.caltech.edu/~mmaire/)\n\n[2010 ECCV SuperParsing: Scalable Nonparametric Image Parsing with Superpixels](http://www.cs.unc.edu/~jtighe/Papers/ECCV10/)\n\n[2009 CVPR Nonparametric Scene Parsing: Label Transfer via Dense Scene Alignment](ttp://people.csail.mit.edu/celiu/CVPR2009/)\n\n[2009 Scene Understanding Datasets](http://dags.stanford.edu/projects/scenedataset.html)\n\n[2008 IJCV 6D-Vision](http://www.6d-vision.com/scene-labeling)\n\n[2008 IJCV The Daimler Urban Segmentation Dataset](http://www.6d-vision.com/scene-labeling)\n\n[2008 ECCV Motion-based Segmentation and Recognition Dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec))/CamVid/\n\n[2008 York Urban Dataset](http://www.elderlab.yorku.ca/YorkUrbanDB/)\n\n[2008 IJCV LabelMe](http://labelme.csail.mit.edu/LabelMeToolbox/index.html)\n\n\n## 8 \u4f1a\u8bae\u3000\u671f\u520a\u3000\n### CVPR Computer vision  and  Pattern Reconition \u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u6a21\u5f0f\u8bc6\u522b\n### ECCV European Conference on Computer Vision   \u6b27\u6d32\u8ba1\u7b97\u673a\u89c6\u89c9\u56fd\u9645\u4f1a\u8bae \n### ICCV IEEE International Conference on Computer Vision  \u56fd\u9645\u8ba1\u7b97\u673a\u89c6\u89c9\u5927\u4f1a\n### \u5176\u4ed6\n[\u5176\u4ed6](http://www.ipcv.org/otherpaper/)\n###\n###\n###\n###\n\n\n## AR&VR\n[\u53c2\u8003](http://www.ipcv.org/category/top-dir/arvr/)\n\n\n## \n",
        "releases": []
    }
}