{
    "https://api.github.com/repos/facebookresearch/ImageBind": {
        "forks": 783,
        "watchers": 8485,
        "stars": 8485,
        "languages": {
            "Python": 66000
        },
        "commits": [
            "2024-07-10T17:36:35Z",
            "2024-07-10T17:34:15Z",
            "2024-07-10T17:30:27Z",
            "2024-07-10T13:36:08Z",
            "2024-07-10T13:34:02Z",
            "2024-07-05T13:07:02Z",
            "2024-06-10T09:51:07Z",
            "2024-06-10T09:50:29Z",
            "2024-04-03T00:20:47Z",
            "2024-03-20T15:31:18Z",
            "2023-11-29T04:44:51Z",
            "2023-10-16T06:18:59Z",
            "2023-07-14T22:16:21Z",
            "2023-07-14T15:01:48Z",
            "2023-07-12T23:16:58Z",
            "2023-07-12T22:41:05Z",
            "2023-07-12T22:37:48Z",
            "2023-07-12T22:34:14Z",
            "2023-05-31T14:40:45Z",
            "2023-05-31T08:40:56Z",
            "2023-05-31T08:38:01Z",
            "2023-05-20T17:25:27Z",
            "2023-05-16T17:49:37Z",
            "2023-05-16T17:48:28Z",
            "2023-05-13T15:01:33Z",
            "2023-05-13T14:59:58Z",
            "2023-05-12T22:56:41Z",
            "2023-05-12T10:31:58Z",
            "2023-05-10T15:16:01Z",
            "2023-05-10T13:29:58Z"
        ],
        "creation_date": "2023-03-23T15:52:47Z",
        "contributors": 17,
        "topics": [],
        "subscribers": 99,
        "readme": "# ImageBind: One Embedding Space To Bind Them All\n\n**[FAIR, Meta AI](https://ai.facebook.com/research/)** \n\nRohit Girdhar*,\nAlaaeldin El-Nouby*,\nZhuang Liu,\nMannat Singh,\nKalyan Vasudev Alwala,\nArmand Joulin,\nIshan Misra*\n\nTo appear at CVPR 2023 (*Highlighted paper*)\n\n[[`Paper`](https://facebookresearch.github.io/ImageBind/paper)] [[`Blog`](https://ai.facebook.com/blog/imagebind-six-modalities-binding-ai/)] [[`Demo`](https://imagebind.metademolab.com/)] [[`Supplementary Video`](https://dl.fbaipublicfiles.com/imagebind/imagebind_video.mp4)] [[`BibTex`](#citing-imagebind)]\n\nPyTorch implementation and pretrained models for ImageBind. For details, see the paper: **[ImageBind: One Embedding Space To Bind Them All](https://facebookresearch.github.io/ImageBind/paper)**.\n\nImageBind learns a joint embedding across six different modalities - images, text, audio, depth, thermal, and IMU data. It enables novel emergent applications \u2018out-of-the-box\u2019 including cross-modal retrieval, composing modalities with arithmetic, cross-modal detection and generation.\n\n\n\n![ImageBind](https://user-images.githubusercontent.com/8495451/236859695-ffa13364-3e39-4d99-a8da-fbfab17f9a6b.gif)\n\n## ImageBind model\n\nEmergent zero-shot classification performance.\n\n<table style=\"margin: auto\">\n  <tr>\n    <th>Model</th>\n    <th><span style=\"color:blue\">IN1k</span></th>\n    <th><span style=\"color:purple\">K400</span></th>\n    <th><span style=\"color:green\">NYU-D</span></th>\n    <th><span style=\"color:LightBlue\">ESC</span></th>\n    <th><span style=\"color:orange\">LLVIP</span></th>\n    <th><span style=\"color:purple\">Ego4D</span></th>\n    <th>download</th>\n  </tr>\n  <tr>\n    <td>imagebind_huge</td>\n    <td align=\"right\">77.7</td>\n    <td align=\"right\">50.0</td>\n    <td align=\"right\">54.0</td>\n    <td align=\"right\">66.9</td>\n    <td align=\"right\">63.4</td>\n    <td align=\"right\">25.0</td>\n    <td><a href=\"https://dl.fbaipublicfiles.com/imagebind/imagebind_huge.pth\">checkpoint</a></td>\n  </tr>\n  \n</table>\n\n## Usage\n\nInstall pytorch 1.13+ and other 3rd party dependencies.\n\n```shell\nconda create --name imagebind python=3.10 -y\nconda activate imagebind\n\npip install .\n```\n\nFor windows users, you might need to install `soundfile` for reading/writing audio files. (Thanks @congyue1977)\n\n```\npip install soundfile\n```\n\n\nExtract and compare features across modalities (e.g. Image, Text and Audio).\n\n```python\nfrom imagebind import data\nimport torch\nfrom imagebind.models import imagebind_model\nfrom imagebind.models.imagebind_model import ModalityType\n\ntext_list=[\"A dog.\", \"A car\", \"A bird\"]\nimage_paths=[\".assets/dog_image.jpg\", \".assets/car_image.jpg\", \".assets/bird_image.jpg\"]\naudio_paths=[\".assets/dog_audio.wav\", \".assets/car_audio.wav\", \".assets/bird_audio.wav\"]\n\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n\n# Instantiate model\nmodel = imagebind_model.imagebind_huge(pretrained=True)\nmodel.eval()\nmodel.to(device)\n\n# Load data\ninputs = {\n    ModalityType.TEXT: data.load_and_transform_text(text_list, device),\n    ModalityType.VISION: data.load_and_transform_vision_data(image_paths, device),\n    ModalityType.AUDIO: data.load_and_transform_audio_data(audio_paths, device),\n}\n\nwith torch.no_grad():\n    embeddings = model(inputs)\n\nprint(\n    \"Vision x Text: \",\n    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.TEXT].T, dim=-1),\n)\nprint(\n    \"Audio x Text: \",\n    torch.softmax(embeddings[ModalityType.AUDIO] @ embeddings[ModalityType.TEXT].T, dim=-1),\n)\nprint(\n    \"Vision x Audio: \",\n    torch.softmax(embeddings[ModalityType.VISION] @ embeddings[ModalityType.AUDIO].T, dim=-1),\n)\n\n# Expected output:\n#\n# Vision x Text:\n# tensor([[9.9761e-01, 2.3694e-03, 1.8612e-05],\n#         [3.3836e-05, 9.9994e-01, 2.4118e-05],\n#         [4.7997e-05, 1.3496e-02, 9.8646e-01]])\n#\n# Audio x Text:\n# tensor([[1., 0., 0.],\n#         [0., 1., 0.],\n#         [0., 0., 1.]])\n#\n# Vision x Audio:\n# tensor([[0.8070, 0.1088, 0.0842],\n#         [0.1036, 0.7884, 0.1079],\n#         [0.0018, 0.0022, 0.9960]])\n\n```\n\n## Model card\nPlease see the [model card](model_card.md) for details.\n\n## License\n\nImageBind code and model weights are released under the CC-BY-NC 4.0 license. See [LICENSE](LICENSE) for additional details.\n\n## Contributing\n\nSee [contributing](CONTRIBUTING.md) and the [code of conduct](CODE_OF_CONDUCT.md).\n\n## Citing ImageBind\n\nIf you find this repository useful, please consider giving a star :star: and citation\n\n```\n@inproceedings{girdhar2023imagebind,\n  title={ImageBind: One Embedding Space To Bind Them All},\n  author={Girdhar, Rohit and El-Nouby, Alaaeldin and Liu, Zhuang\nand Singh, Mannat and Alwala, Kalyan Vasudev and Joulin, Armand and Misra, Ishan},\n  booktitle={CVPR},\n  year={2023}\n}\n```\n",
        "releases": []
    }
}