{
    "https://api.github.com/repos/imartinez/privateGPT": {
        "forks": 7390,
        "watchers": 54947,
        "stars": 54947,
        "languages": {
            "Python": 239830,
            "MDX": 73879,
            "Makefile": 2800
        },
        "commits": [
            "2024-11-13T19:29:56Z",
            "2024-10-17T10:44:28Z",
            "2024-09-26T14:29:52Z",
            "2024-09-25T10:00:03Z",
            "2024-09-24T06:33:02Z",
            "2024-09-24T06:31:30Z",
            "2024-09-24T06:30:58Z",
            "2024-09-16T14:43:05Z",
            "2024-09-09T06:53:13Z",
            "2024-08-21T08:39:58Z",
            "2024-08-12T06:23:16Z",
            "2024-08-08T16:16:41Z",
            "2024-08-08T14:50:42Z",
            "2024-08-07T15:39:32Z",
            "2024-08-07T10:16:03Z",
            "2024-08-07T09:26:42Z",
            "2024-08-05T15:17:34Z",
            "2024-08-05T15:15:38Z",
            "2024-08-05T14:30:10Z",
            "2024-08-05T14:18:34Z",
            "2024-08-05T14:17:36Z",
            "2024-08-02T09:28:22Z",
            "2024-08-02T09:26:03Z",
            "2024-08-01T17:14:26Z",
            "2024-08-01T08:01:22Z",
            "2024-08-01T07:43:30Z",
            "2024-07-31T14:53:27Z",
            "2024-07-31T12:35:46Z",
            "2024-07-31T12:35:36Z",
            "2024-07-31T12:33:46Z"
        ],
        "creation_date": "2023-05-02T09:15:31Z",
        "contributors": 30,
        "topics": [],
        "subscribers": 461,
        "readme": "# PrivateGPT \n\n<a href=\"https://trendshift.io/repositories/2601\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2601\" alt=\"imartinez%2FprivateGPT | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n[![Tests](https://github.com/zylon-ai/private-gpt/actions/workflows/tests.yml/badge.svg)](https://github.com/zylon-ai/private-gpt/actions/workflows/tests.yml?query=branch%3Amain)\n[![Website](https://img.shields.io/website?up_message=check%20it&down_message=down&url=https%3A%2F%2Fdocs.privategpt.dev%2F&label=Documentation)](https://docs.privategpt.dev/)\n[![Discord](https://img.shields.io/discord/1164200432894234644?logo=discord&label=PrivateGPT)](https://discord.gg/bK6mRVpErU)\n[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/ZylonPrivateGPT)](https://twitter.com/ZylonPrivateGPT)\n\n![Gradio UI](/fern/docs/assets/ui.png?raw=true)\n\nPrivateGPT is a production-ready AI project that allows you to ask questions about your documents using the power\nof Large Language Models (LLMs), even in scenarios without an Internet connection. 100% private, no data leaves your\nexecution environment at any point.\n\n>[!TIP]\n> If you are looking for an **enterprise-ready, fully private AI workspace**\n> check out [Zylon's website](https://zylon.ai)  or [request a demo](https://cal.com/zylon/demo?source=pgpt-readme).\n> Crafted by the team behind PrivateGPT, Zylon is a best-in-class AI collaborative\n> workspace that can be easily deployed on-premise (data center, bare metal...) or in your private cloud (AWS, GCP, Azure...).\n\nThe project provides an API offering all the primitives required to build private, context-aware AI applications.\nIt follows and extends the [OpenAI API standard](https://openai.com/blog/openai-api),\nand supports both normal and streaming responses.\n\nThe API is divided into two logical blocks:\n\n**High-level API**, which abstracts all the complexity of a RAG (Retrieval Augmented Generation)\npipeline implementation:\n- Ingestion of documents: internally managing document parsing,\nsplitting, metadata extraction, embedding generation and storage.\n- Chat & Completions using context from ingested documents:\nabstracting the retrieval of context, the prompt engineering and the response generation.\n\n**Low-level API**, which allows advanced users to implement their own complex pipelines:\n- Embeddings generation: based on a piece of text.\n- Contextual chunks retrieval: given a query, returns the most relevant chunks of text from the ingested documents.\n\nIn addition to this, a working [Gradio UI](https://www.gradio.app/)\nclient is provided to test the API, together with a set of useful tools such as bulk model\ndownload script, ingestion script, documents folder watch, etc.\n\n## \ud83c\udf9e\ufe0f Overview\n>[!WARNING]\n>  This README is not updated as frequently as the [documentation](https://docs.privategpt.dev/).\n>  Please check it out for the latest updates!\n\n### Motivation behind PrivateGPT\nGenerative AI is a game changer for our society, but adoption in companies of all sizes and data-sensitive\ndomains like healthcare or legal is limited by a clear concern: **privacy**.\nNot being able to ensure that your data is fully under your control when using third-party AI tools\nis a risk those industries cannot take.\n\n### Primordial version\nThe first version of PrivateGPT was launched in May 2023 as a novel approach to address the privacy\nconcerns by using LLMs in a complete offline way.\n\nThat version, which rapidly became a go-to project for privacy-sensitive setups and served as the seed\nfor thousands of local-focused generative AI projects, was the foundation of what PrivateGPT is becoming nowadays;\nthus a simpler and more educational implementation to understand the basic concepts required\nto build a fully local -and therefore, private- chatGPT-like tool.\n\nIf you want to keep experimenting with it, we have saved it in the\n[primordial branch](https://github.com/zylon-ai/private-gpt/tree/primordial) of the project.\n\n> It is strongly recommended to do a clean clone and install of this new version of\nPrivateGPT if you come from the previous, primordial version.\n\n### Present and Future of PrivateGPT\nPrivateGPT is now evolving towards becoming a gateway to generative AI models and primitives, including\ncompletions, document ingestion, RAG pipelines and other low-level building blocks.\nWe want to make it easier for any developer to build AI applications and experiences, as well as provide\na suitable extensive architecture for the community to keep contributing.\n\nStay tuned to our [releases](https://github.com/zylon-ai/private-gpt/releases) to check out all the new features and changes included.\n\n## \ud83d\udcc4 Documentation\nFull documentation on installation, dependencies, configuration, running the server, deployment options,\ningesting local documents, API details and UI features can be found here: https://docs.privategpt.dev/\n\n## \ud83e\udde9 Architecture\nConceptually, PrivateGPT is an API that wraps a RAG pipeline and exposes its\nprimitives.\n* The API is built using [FastAPI](https://fastapi.tiangolo.com/) and follows\n  [OpenAI's API scheme](https://platform.openai.com/docs/api-reference).\n* The RAG pipeline is based on [LlamaIndex](https://www.llamaindex.ai/).\n\nThe design of PrivateGPT allows to easily extend and adapt both the API and the\nRAG implementation. Some key architectural decisions are:\n* Dependency Injection, decoupling the different components and layers.\n* Usage of LlamaIndex abstractions such as `LLM`, `BaseEmbedding` or `VectorStore`,\n  making it immediate to change the actual implementations of those abstractions.\n* Simplicity, adding as few layers and new abstractions as possible.\n* Ready to use, providing a full implementation of the API and RAG\n  pipeline.\n\nMain building blocks:\n* APIs are defined in `private_gpt:server:<api>`. Each package contains an\n  `<api>_router.py` (FastAPI layer) and an `<api>_service.py` (the\n  service implementation). Each *Service* uses LlamaIndex base abstractions instead\n  of specific implementations,\n  decoupling the actual implementation from its usage.\n* Components are placed in\n  `private_gpt:components:<component>`. Each *Component* is in charge of providing\n  actual implementations to the base abstractions used in the Services - for example\n  `LLMComponent` is in charge of providing an actual implementation of an `LLM`\n  (for example `LlamaCPP` or `OpenAI`).\n\n## \ud83d\udca1 Contributing\nContributions are welcomed! To ensure code quality we have enabled several format and\ntyping checks, just run `make check` before committing to make sure your code is ok.\nRemember to test your code! You'll find a tests folder with helpers, and you can run\ntests using `make test` command.\n\nDon't know what to contribute? Here is the public \n[Project Board](https://github.com/users/imartinez/projects/3) with several ideas. \n\nHead over to Discord \n#contributors channel and ask for write permissions on that GitHub project.\n\n## \ud83d\udcac Community\nJoin the conversation around PrivateGPT on our:\n- [Twitter (aka X)](https://twitter.com/PrivateGPT_AI)\n- [Discord](https://discord.gg/bK6mRVpErU)\n\n## \ud83d\udcd6 Citation\nIf you use PrivateGPT in a paper, check out the [Citation file](CITATION.cff) for the correct citation.  \nYou can also use the \"Cite this repository\" button in this repo to get the citation in different formats.\n\nHere are a couple of examples:\n\n#### BibTeX\n```bibtex\n@software{Zylon_PrivateGPT_2023,\nauthor = {Zylon by PrivateGPT},\nlicense = {Apache-2.0},\nmonth = may,\ntitle = {{PrivateGPT}},\nurl = {https://github.com/zylon-ai/private-gpt},\nyear = {2023}\n}\n```\n\n#### APA\n```\nZylon by PrivateGPT (2023). PrivateGPT [Computer software]. https://github.com/zylon-ai/private-gpt\n```\n\n## \ud83e\udd17 Partners & Supporters\nPrivateGPT is actively supported by the teams behind:\n* [Qdrant](https://qdrant.tech/), providing the default vector database\n* [Fern](https://buildwithfern.com/), providing Documentation and SDKs\n* [LlamaIndex](https://www.llamaindex.ai/), providing the base RAG framework and abstractions\n\nThis project has been strongly influenced and supported by other amazing projects like \n[LangChain](https://github.com/hwchase17/langchain),\n[GPT4All](https://github.com/nomic-ai/gpt4all),\n[LlamaCpp](https://github.com/ggerganov/llama.cpp),\n[Chroma](https://www.trychroma.com/)\nand [SentenceTransformers](https://www.sbert.net/).\n",
        "releases": [
            {
                "name": "v0.6.2",
                "date": "2024-08-08T16:16:58Z"
            },
            {
                "name": "v0.6.1",
                "date": "2024-08-05T15:17:52Z"
            },
            {
                "name": "v0.6.0",
                "date": "2024-08-02T09:28:42Z"
            },
            {
                "name": "v0.5.0",
                "date": "2024-04-02T15:45:35Z"
            },
            {
                "name": "v0.4.0",
                "date": "2024-03-06T16:53:59Z"
            },
            {
                "name": "v0.3.0",
                "date": "2024-02-16T16:42:59Z"
            },
            {
                "name": "v0.2.0",
                "date": "2023-12-10T19:08:37Z"
            },
            {
                "name": "v0.1.0",
                "date": "2023-12-01T13:46:16Z"
            },
            {
                "name": "v0.0.2",
                "date": "2023-10-20T16:29:40Z"
            },
            {
                "name": "v0.0.1",
                "date": "2023-10-20T11:09:09Z"
            }
        ]
    }
}