{
    "https://api.github.com/repos/bluenviron/mediamtx": {
        "forks": 1595,
        "watchers": 13123,
        "stars": 13123,
        "languages": {
            "Go": 1240234,
            "JavaScript": 25421,
            "HTML": 18628,
            "Makefile": 12135,
            "C": 2501,
            "Dockerfile": 1482,
            "Shell": 414
        },
        "commits": [
            "2025-01-22T06:15:45Z",
            "2025-01-20T19:06:33Z",
            "2025-01-19T17:40:18Z",
            "2025-01-19T14:43:58Z",
            "2025-01-19T14:36:40Z",
            "2025-01-19T13:20:06Z",
            "2025-01-19T09:23:03Z",
            "2025-01-18T17:57:56Z",
            "2025-01-17T12:21:24Z",
            "2025-01-17T12:19:03Z",
            "2025-01-17T12:12:53Z",
            "2025-01-17T10:49:35Z",
            "2025-01-15T18:11:51Z",
            "2025-01-15T18:00:21Z",
            "2025-01-13T22:23:26Z",
            "2025-01-13T22:19:29Z",
            "2025-01-13T17:45:47Z",
            "2025-01-11T19:40:25Z",
            "2025-01-11T16:29:48Z",
            "2025-01-11T09:25:29Z",
            "2025-01-10T18:10:26Z",
            "2025-01-10T17:52:57Z",
            "2025-01-10T17:52:47Z",
            "2025-01-10T16:36:03Z",
            "2025-01-10T16:16:47Z",
            "2025-01-10T15:53:28Z",
            "2025-01-10T15:20:45Z",
            "2025-01-10T15:20:25Z",
            "2025-01-10T06:23:51Z",
            "2025-01-09T18:05:01Z"
        ],
        "creation_date": "2019-12-28T20:08:43Z",
        "contributors": 30,
        "topics": [
            "go",
            "golang",
            "hls",
            "media-server",
            "obs-studio",
            "rtcp",
            "rtmp",
            "rtmp-proxy",
            "rtmp-server",
            "rtp",
            "rtsp",
            "rtsp-proxy",
            "rtsp-relay",
            "rtsp-server",
            "srt",
            "streaming",
            "webrtc",
            "webrtc-proxy"
        ],
        "subscribers": 150,
        "readme": "<h1 align=\"center\">\n  <img src=\"logo.png\" alt=\"MediaMTX / rtsp-simple-server\">\n\n  <br>\n  <br>\n\n  [![Test](https://github.com/bluenviron/mediamtx/workflows/test/badge.svg)](https://github.com/bluenviron/mediamtx/actions?query=workflow:test)\n  [![Lint](https://github.com/bluenviron/mediamtx/workflows/lint/badge.svg)](https://github.com/bluenviron/mediamtx/actions?query=workflow:lint)\n  [![CodeCov](https://codecov.io/gh/bluenviron/mediamtx/branch/main/graph/badge.svg)](https://app.codecov.io/gh/bluenviron/mediamtx/tree/main)\n  [![Release](https://img.shields.io/github/v/release/bluenviron/mediamtx)](https://github.com/bluenviron/mediamtx/releases)\n  [![Docker Hub](https://img.shields.io/badge/docker-bluenviron/mediamtx-blue)](https://hub.docker.com/r/bluenviron/mediamtx)\n  [![API Documentation](https://img.shields.io/badge/api-documentation-blue)](https://bluenviron.github.io/mediamtx)\n</h1>\n\n<br>\n\n_MediaMTX_ is a ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams. It has been conceived as a \"media router\" that routes media streams from one end to the other.\n\nLive streams can be published to the server with:\n\n|protocol|variants|video codecs|audio codecs|\n|--------|--------|------------|------------|\n|[SRT clients](#srt-clients)||H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|\n|[SRT cameras and servers](#srt-cameras-and-servers)||H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|\n|[WebRTC clients](#webrtc-clients)|WHIP|AV1, VP9, VP8, [H265](#supported-browsers), H264|Opus, G722, G711 (PCMA, PCMU)|\n|[WebRTC servers](#webrtc-servers)|WHEP|AV1, VP9, VP8, [H265](#supported-browsers), H264|Opus, G722, G711 (PCMA, PCMU)|\n|[RTSP clients](#rtsp-clients)|UDP, TCP, RTSPS|AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec|\n|[RTSP cameras and servers](#rtsp-cameras-and-servers)|UDP, UDP-Multicast, TCP, RTSPS|AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec|\n|[RTMP clients](#rtmp-clients)|RTMP, RTMPS, Enhanced RTMP|AV1, VP9, H265, H264|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM|\n|[RTMP cameras and servers](#rtmp-cameras-and-servers)|RTMP, RTMPS, Enhanced RTMP|AV1, VP9, H265, H264|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM|\n|[HLS cameras and servers](#hls-cameras-and-servers)|Low-Latency HLS, MP4-based HLS, legacy HLS|AV1, VP9, [H265](#supported-browsers-1), H264|Opus, MPEG-4 Audio (AAC)|\n|[UDP/MPEG-TS](#udpmpeg-ts)|Unicast, broadcast, multicast|H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|\n|[Raspberry Pi Cameras](#raspberry-pi-cameras)||H264||\n\nLive streams can be read from the server with:\n\n|protocol|variants|video codecs|audio codecs|\n|--------|--------|------------|------------|\n|[SRT](#srt)||H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|\n|[WebRTC](#webrtc)|WHEP|AV1, VP9, VP8, [H265](#supported-browsers), H264|Opus, G722, G711 (PCMA, PCMU)|\n|[RTSP](#rtsp)|UDP, UDP-Multicast, TCP, RTSPS|AV1, VP9, VP8, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG and any RTP-compatible codec|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G726, G722, G711 (PCMA, PCMU), LPCM and any RTP-compatible codec|\n|[RTMP](#rtmp)|RTMP, RTMPS, Enhanced RTMP|H264|MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3)|\n|[HLS](#hls)|Low-Latency HLS, MP4-based HLS, legacy HLS|AV1, VP9, [H265](#supported-browsers-1), H264|Opus, MPEG-4 Audio (AAC)|\n\nLive streams be recorded and played back with:\n\n|format|video codecs|audio codecs|\n|------|------------|------------|\n|[fMP4](#record-streams-to-disk)|AV1, VP9, H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video, M-JPEG|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3, G711 (PCMA, PCMU), LPCM|\n|[MPEG-TS](#record-streams-to-disk)|H265, H264, MPEG-4 Video (H263, Xvid), MPEG-1/2 Video|Opus, MPEG-4 Audio (AAC), MPEG-1/2 Audio (MP3), AC-3|\n\n**Features**\n\n* Publish live streams to the server\n* Read live streams from the server\n* Streams are automatically converted from a protocol to another\n* Serve multiple streams at once in separate paths\n* Record streams to disk\n* Playback recorded streams\n* Authenticate users\n* Redirect readers to other RTSP servers (load balancing)\n* Control the server through the Control API\n* Reload the configuration without disconnecting existing clients (hot reloading)\n* Read Prometheus-compatible metrics\n* Run hooks (external commands) when clients connect, disconnect, read or publish streams\n* Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it's a single executable\n\n**Note about rtsp-simple-server**\n\n_rtsp-simple-server_ has been rebranded as _MediaMTX_. The reason is pretty obvious: this project started as a RTSP server but has evolved into a much more versatile product that is not tied to the RTSP protocol anymore. Nothing will change regarding license, features and backward compatibility.\n\n## Table of contents\n\n* [Installation](#installation)\n  * [Standalone binary](#standalone-binary)\n  * [Docker image](#docker-image)\n  * [Arch Linux package](#arch-linux-package)\n  * [OpenWrt binary](#openwrt-binary)\n* [Basic usage](#basic-usage)\n* [Publish to the server](#publish-to-the-server)\n  * [By software](#by-software)\n    * [FFmpeg](#ffmpeg)\n    * [GStreamer](#gstreamer)\n    * [OBS Studio](#obs-studio)\n    * [OpenCV](#opencv)\n    * [Unity](#unity)\n    * [Web browsers](#web-browsers)\n  * [By device](#by-device)\n    * [Generic webcam](#generic-webcam)\n    * [Raspberry Pi Cameras](#raspberry-pi-cameras)\n  * [By protocol](#by-protocol)\n    * [SRT clients](#srt-clients)\n    * [SRT cameras and servers](#srt-cameras-and-servers)\n    * [WebRTC clients](#webrtc-clients)\n    * [WebRTC servers](#webrtc-servers)\n    * [RTSP clients](#rtsp-clients)\n    * [RTSP cameras and servers](#rtsp-cameras-and-servers)\n    * [RTMP clients](#rtmp-clients)\n    * [RTMP cameras and servers](#rtmp-cameras-and-servers)\n    * [HLS cameras and servers](#hls-cameras-and-servers)\n    * [UDP/MPEG-TS](#udpmpeg-ts)\n* [Read from the server](#read-from-the-server)\n  * [By software](#by-software-1)\n    * [FFmpeg](#ffmpeg-1)\n    * [GStreamer](#gstreamer-1)\n    * [VLC](#vlc)\n    * [Unity](#unity-1)\n    * [Web browsers](#web-browsers-1)\n  * [By protocol](#by-protocol-1)\n    * [SRT](#srt)\n    * [WebRTC](#webrtc)\n    * [RTSP](#rtsp)\n    * [RTMP](#rtmp)\n    * [HLS](#hls)\n* [Other features](#other-features)\n  * [Configuration](#configuration)\n  * [Authentication](#authentication)\n    * [Internal](#internal)\n    * [HTTP-based](#http-based)\n    * [JWT-based](#jwt-based)\n  * [Encrypt the configuration](#encrypt-the-configuration)\n  * [Remuxing, re-encoding, compression](#remuxing-re-encoding-compression)\n  * [Record streams to disk](#record-streams-to-disk)\n  * [Playback recorded streams](#playback-recorded-streams)\n  * [Forward streams to other servers](#forward-streams-to-other-servers)\n  * [Proxy requests to other servers](#proxy-requests-to-other-servers)\n  * [On-demand publishing](#on-demand-publishing)\n  * [Start on boot](#start-on-boot)\n    * [Linux](#linux)\n    * [OpenWrt](#openwrt)\n    * [Windows](#windows)\n  * [Hooks](#hooks)\n  * [Control API](#control-api)\n  * [Metrics](#metrics)\n  * [pprof](#pprof)\n  * [SRT-specific features](#srt-specific-features)\n    * [Standard stream ID syntax](#standard-stream-id-syntax)\n  * [WebRTC-specific features](#webrtc-specific-features)\n    * [Authenticating with WHIP/WHEP](#authenticating-with-whipwhep)\n    * [Solving WebRTC connectivity issues](#solving-webrtc-connectivity-issues)\n    * [Supported browsers](#supported-browsers)\n  * [HLS-specific features](#hls-specific-features)\n    * [Supported browsers](#supported-browsers-1)\n  * [RTSP-specific features](#rtsp-specific-features)\n    * [Transport protocols](#transport-protocols)\n    * [Encryption](#encryption)\n    * [Corrupted frames](#corrupted-frames)\n  * [RTMP-specific features](#rtmp-specific-features)\n    * [Encryption](#encryption-1)\n* [Compile from source](#compile-from-source)\n  * [Standard](#standard)\n  * [OpenWrt](#openwrt-1)\n  * [Custom libcamera](#custom-libcamera)\n  * [Cross compile](#cross-compile)\n  * [Compile for all supported platforms](#compile-for-all-supported-platforms)\n* [License](#license)\n* [Specifications](#specifications)\n* [Related projects](#related-projects)\n\n## Installation\n\nThere are several installation methods available: standalone binary, Docker image, Arch Linux package and OpenWrt binary.\n\n### Standalone binary\n\n1. Download and extract a standalone binary from the [release page](https://github.com/bluenviron/mediamtx/releases) that corresponds to your operating system and architecture.\n\n2. Start the server:\n\n   ```sh\n   ./mediamtx\n   ```\n\n### Docker image\n\nDownload and launch the image:\n\n```\ndocker run --rm -it --network=host bluenviron/mediamtx:latest\n```\n\nAvailable images:\n\n|name|FFmpeg included|RPI Camera support|\n|----|---------------|------------------|\n|bluenviron/mediamtx:latest|:x:|:x:|\n|bluenviron/mediamtx:latest-ffmpeg|:heavy_check_mark:|:x:|\n|bluenviron/mediamtx:latest-rpi|:x:|:heavy_check_mark:|\n|bluenviron/mediamtx:latest-ffmpeg-rpi|:heavy_check_mark:|:heavy_check_mark:|\n\nThe `--network=host` flag is mandatory for RTSP to work, since Docker can change the source port of UDP packets for routing reasons, and this doesn't allow the server to identify the senders of the packets. This issue can be avoided by disabling the RTSP UDP transport protocol:\n\n```\ndocker run --rm -it \\\n-e MTX_RTSPTRANSPORTS=tcp \\\n-e MTX_WEBRTCADDITIONALHOSTS=192.168.x.x \\\n-p 8554:8554 \\\n-p 1935:1935 \\\n-p 8888:8888 \\\n-p 8889:8889 \\\n-p 8890:8890/udp \\\n-p 8189:8189/udp \\\nbluenviron/mediamtx\n```\n\nset `MTX_WEBRTCADDITIONALHOSTS` to your local IP address.\n\n### Arch Linux package\n\nIf you are running the Arch Linux distribution, run:\n\n```sh\ngit clone https://aur.archlinux.org/mediamtx.git\ncd mediamtx\nmakepkg -si\n```\n\n### OpenWrt binary\n\nIf the architecture of the OpenWrt device is amd64, armv6, armv7 or arm64, use the [standalone binary method](#standalone-binary) and download a Linux binary that corresponds to your architecture.\n\nOtherwise, [compile the server from source](#openwrt-1).\n\n## Basic usage\n\n1. Publish a stream. For instance, you can publish a video/audio file with _FFmpeg_:\n\n   ```sh\n   ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream\n   ```\n\n   or _GStreamer_:\n\n   ```sh\n   gst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream filesrc location=file.mp4 \\\n   ! qtdemux name=d d.video_0 ! queue ! s.sink_0 d.audio_0 ! queue ! s.sink_1\n   ```\n\n2. Open the stream. For instance, you can open the stream with _VLC_:\n\n   ```sh\n   vlc --network-caching=50 rtsp://localhost:8554/mystream\n   ```\n\n   or _GStreamer_:\n\n   ```sh\n   gst-play-1.0 rtsp://localhost:8554/mystream\n   ```\n\n   or _FFmpeg_:\n\n   ```sh\n   ffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4\n   ```\n\n## Publish to the server\n\n### By software\n\n#### FFmpeg\n\nFFmpeg can publish a stream to the server in multiple ways (SRT client, SRT server, RTSP client, RTMP client, UDP/MPEG-TS, WebRTC with WHIP). The recommended one consists in publishing as a [RTSP client](#rtsp-clients):\n\n```\nffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream\n```\n\nThe RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)). You can set the transport protocol by using the `rtsp_transport` flag, for instance, in order to use TCP:\n\n```sh\nffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp -rtsp_transport tcp rtsp://localhost:8554/mystream\n```\n\nThe resulting stream will be available in path `/mystream`.\n\n#### GStreamer\n\nGStreamer can publish a stream to the server in multiple ways (SRT client, SRT server, RTSP client, RTMP client, UDP/MPEG-TS, WebRTC with WHIP). The recommended one consists in publishing as a [RTSP client](#rtsp-clients):\n\n```sh\ngst-launch-1.0 rtspclientsink name=s location=rtsp://localhost:8554/mystream \\\nfilesrc location=file.mp4 ! qtdemux name=d \\\nd.video_0 ! queue ! s.sink_0 \\\nd.audio_0 ! queue ! s.sink_1\n```\n\nIf the stream is video only:\n\n```sh\ngst-launch-1.0 filesrc location=file.mp4 ! qtdemux name=d \\\nd.video_0 ! rtspclientsink location=rtsp://localhost:8554/mystream\n```\n\nThe RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)). You can set the transport protocol by using the `protocols` flag:\n\n```sh\ngst-launch-1.0 filesrc location=file.mp4 ! qtdemux name=d \\\nd.video_0 ! rtspclientsink protocols=tcp name=s location=rtsp://localhost:8554/mystream\n```\n\nThe resulting stream will be available in path `/mystream`.\n\nGStreamer can also publish a stream by using the [WebRTC / WHIP protocol](#webrtc). Make sure that GStreamer version is at least 1.22, and that if the codec is H264, the profile is baseline. Use the `whipclientsink` element:\n\n```\ngst-launch-1.0 videotestsrc \\\n! video/x-raw,width=1920,height=1080,format=I420 \\\n! x264enc speed-preset=ultrafast bitrate=2000 \\\n! video/x-h264,profile=baseline \\\n! whipclientsink signaller::whip-endpoint=http://localhost:8889/mystream/whip\n```\n\n#### OBS Studio\n\nOBS Studio can publish to the server in multiple ways (SRT client, RTMP client, WebRTC client). The recommended one consists in publishing as a [RTMP client](#rtmp-clients). In `Settings -> Stream` (or in the Auto-configuration Wizard), use the following parameters:\n\n* Service: `Custom...`\n* Server: `rtmp://localhost`\n* Stream key: `mystream`\n\nIf credentials are in use, use the following parameters:\n\n* Service: `Custom...`\n* Server: `rtmp://localhost`\n* Stream key: `mystream?user=myuser&pass=mypass`\n\nSave the configuration and click `Start streaming`.\n\nIf you want to generate a stream that can be read with WebRTC, open `Settings -> Output -> Recording` and use the following parameters:\n\n* FFmpeg output type: `Output to URL`\n* File path or URL: `rtsp://localhost:8554/mystream`\n* Container format: `rtsp`\n* Check `show all codecs (even if potentically incompatible)`\n* Video encoder: `h264_nvenc (libx264)`\n* Video encoder settings (if any): `bf=0`\n* Audio track: `1`\n* Audio encoder: `libopus`\n\nThen use the button `Start Recording` (instead of `Start Streaming`) to start streaming.\n\nLatest versions of OBS Studio can publish to the server with the [WebRTC / WHIP protocol](#webrtc). Use the following parameters:\n\n* Service: `WHIP`\n* Server: `http://localhost:8889/mystream/whip`\n* Bearer Token: `myuser:mypass` (if internal authentication is enabled) or JWT (if JWT-based authentication is enabled)\n\nSave the configuration and click `Start streaming`.\n\nThe resulting stream will be available in path `/mystream`.\n\n#### OpenCV\n\nSoftware which uses the OpenCV library can publish to the server through its GStreamer plugin, as a [RTSP client](#rtsp-clients). It must be compiled with GStreamer support, by following this procedure:\n\n```sh\nsudo apt install -y libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev gstreamer1.0-plugins-ugly gstreamer1.0-rtsp python3-dev python3-numpy\ngit clone --depth=1 -b 4.5.4 https://github.com/opencv/opencv\ncd opencv\nmkdir build && cd build\ncmake -D CMAKE_INSTALL_PREFIX=/usr -D WITH_GSTREAMER=ON ..\nmake -j$(nproc)\nsudo make install\n```\n\nYou can check that OpenCV has been installed correctly by running:\n\n```sh\npython3 -c 'import cv2; print(cv2.getBuildInformation())'\n```\n\nCheck that the output contains `GStreamer: YES`.\n\nVideos can be published with `cv2.VideoWriter`:\n\n```python\nfrom datetime import datetime\nfrom time import sleep, time\n\nimport cv2\nimport numpy as np\n\nfps = 15\nwidth = 800\nheight = 600\ncolors = [\n    (0, 0, 255),\n    (255, 0, 0),\n    (0, 255, 0),\n]\n\nout = cv2.VideoWriter('appsrc ! videoconvert' + \\\n    ' ! video/x-raw,format=I420' + \\\n    ' ! x264enc speed-preset=ultrafast bitrate=600 key-int-max=' + str(fps * 2) + \\\n    ' ! video/x-h264,profile=baseline' + \\\n    ' ! rtspclientsink location=rtsp://localhost:8554/mystream',\n    cv2.CAP_GSTREAMER, 0, fps, (width, height), True)\nif not out.isOpened():\n    raise Exception(\"can't open video writer\")\n\ncurcolor = 0\nstart = time()\n\nwhile True:\n    frame = np.zeros((height, width, 3), np.uint8)\n\n    # create a rectangle\n    color = colors[curcolor]\n    curcolor += 1\n    curcolor %= len(colors)\n    for y in range(0, int(frame.shape[0] / 2)):\n        for x in range(0, int(frame.shape[1] / 2)):\n            frame[y][x] = color\n\n    out.write(frame)\n    print(\"%s frame written to the server\" % datetime.now())\n\n    now = time()\n    diff = (1 / fps) - now - start\n    if diff > 0:\n        sleep(diff)\n    start = now\n```\n\nThe resulting stream will be available in path `/mystream`.\n\n#### Unity\n\nSoftware written with the Unity Engine can publish a stream to the server by using the [WebRTC protocol](#webrtc).\n\nCreate a new Unity project or open an existing open.\n\nOpen _Window -> Package Manager_, click on the plus sign, _Add Package by name..._ and insert `com.unity.webrtc`. Wait for the package to be installed.\n\nIn the _Project_ window, under `Assets`, create a new C# Script called `WebRTCPublisher.cs` with this content:\n\n```cs\nusing System.Collections;\nusing UnityEngine;\nusing Unity.WebRTC;\nusing UnityEngine.Networking;\n\npublic class WebRTCPublisher : MonoBehaviour\n{\n    public string url = \"http://localhost:8889/unity/whip\";\n    public int videoWidth = 1280;\n    public int videoHeight = 720;\n\n    private RTCPeerConnection pc;\n    private MediaStream videoStream;\n\n    void Start()\n    {\n        pc = new RTCPeerConnection();\n        Camera sourceCamera = gameObject.GetComponent<Camera>();\n        videoStream = sourceCamera.CaptureStream(videoWidth, videoHeight);\n        foreach (var track in videoStream.GetTracks())\n        {\n            pc.AddTrack(track);\n        }\n\n        StartCoroutine(WebRTC.Update());\n        StartCoroutine(createOffer());\n    }\n\n    private IEnumerator createOffer()\n    {\n        var op = pc.CreateOffer();\n        yield return op;\n        if (op.IsError) {\n            Debug.LogError(\"CreateOffer() failed\");\n            yield break;\n        }\n\n        yield return setLocalDescription(op.Desc);\n    }\n\n    private IEnumerator setLocalDescription(RTCSessionDescription offer)\n    {\n        var op = pc.SetLocalDescription(ref offer);\n        yield return op;\n        if (op.IsError) {\n            Debug.LogError(\"SetLocalDescription() failed\");\n            yield break;\n        }\n\n        yield return postOffer(offer);\n    }\n\n    private IEnumerator postOffer(RTCSessionDescription offer)\n    {\n        var content = new System.Net.Http.StringContent(offer.sdp);\n        content.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue(\"application/sdp\");\n        var client = new System.Net.Http.HttpClient();\n\n        var task = System.Threading.Tasks.Task.Run(async () => {\n            var res = await client.PostAsync(new System.UriBuilder(url).Uri, content);\n            res.EnsureSuccessStatusCode();\n            return await res.Content.ReadAsStringAsync();\n        });\n        yield return new WaitUntil(() => task.IsCompleted);\n        if (task.Exception != null) {\n            Debug.LogError(task.Exception);\n            yield break;\n        }\n\n        yield return setRemoteDescription(task.Result);\n    }\n\n    private IEnumerator setRemoteDescription(string answer)\n    {\n        RTCSessionDescription desc = new RTCSessionDescription();\n        desc.type = RTCSdpType.Answer;\n        desc.sdp = answer;\n        var op = pc.SetRemoteDescription(ref desc);\n        yield return op;\n        if (op.IsError) {\n            Debug.LogError(\"SetRemoteDescription() failed\");\n            yield break;\n        }\n\n        yield break;\n    }\n\n    void OnDestroy()\n    {\n        pc?.Close();\n        pc?.Dispose();\n        videoStream?.Dispose();\n    }\n}\n```\n\nIn the _Hierarchy_ window, find or create a scene and a camera, then add the `WebRTCPublisher.cs` script as component of the camera, by dragging it inside the _Inspector_ window. then Press the _Play_ button at the top of the page.\n\nThe resulting stream will be available in path `/unity`.\n\n#### Web browsers\n\nWeb browsers can publish a stream to the server by using the [WebRTC protocol](#webrtc). Start the server and open the web page:\n\n```\nhttp://localhost:8889/mystream/publish\n```\n\nThe resulting stream will be available in path `/mystream`.\n\nThis web page can be embedded into another web page by using an iframe:\n\n```html\n<iframe src=\"http://mediamtx-ip:8889/mystream/publish\" scrolling=\"no\"></iframe>\n```\n\nFor more advanced setups, you can create and serve a custom web page by starting from the [source code of the WebRTC publish page](internal/servers/webrtc/publish_index.html).\n\n### By device\n\n#### Generic webcam\n\nIf the operating system is Linux-based, edit `mediamtx.yml` and replace everything inside section `paths` with the following content:\n\n```yml\npaths:\n  cam:\n    runOnInit: ffmpeg -f v4l2 -i /dev/video0 -c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH\n    runOnInitRestart: yes\n```\n\nIf the operating system is Windows:\n\n```yml\npaths:\n  cam:\n    runOnInit: ffmpeg -f dshow -i video=\"USB2.0 HD UVC WebCam\" -c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH\n    runOnInitRestart: yes\n```\n\nWhere `USB2.0 HD UVC WebCam` is the name of a webcam, that can be obtained with:\n\n```sh\nffmpeg -list_devices true -f dshow -i dummy\n```\n\nThe resulting stream will be available in path `/cam`.\n\n#### Raspberry Pi Cameras\n\n_MediaMTX_ natively supports most of the Raspberry Pi Camera models, enabling high-quality and low-latency video streaming from the camera to any user, for any purpose. There are a couple of requirements:\n\n1. The server must run on a Raspberry Pi, with one of the following operating systems:\n\n   * Raspberry Pi OS Bookworm\n   * Raspberry Pi OS Bullseye\n\n   Both 32 bit and 64 bit architectures are supported.\n\n2. If you are using Raspberry Pi OS Bullseye, make sure that the legacy camera stack is disabled. Type `sudo raspi-config`, then go to `Interfacing options`, `enable/disable legacy camera support`, choose `no`. Reboot the system.\n\nIf you want to run the standard (non-Docker) version of the server:\n\n1. Download the server executable. If you're using 64-bit version of the operative system, make sure to pick the `arm64` variant.\n\n2. Edit `mediamtx.yml` and replace everything inside section `paths` with the following content:\n\n   ```yml\n   paths:\n     cam:\n       source: rpiCamera\n   ```\n\nThe resulting stream will be available in path `/cam`.\n\nIf you want to run the server inside Docker, you need to use the `latest-rpi` image and launch the container with some additional flags:\n\n```sh\ndocker run --rm -it \\\n--network=host \\\n--privileged \\\n--tmpfs /dev/shm:exec \\\n-v /run/udev:/run/udev:ro \\\n-e MTX_PATHS_CAM_SOURCE=rpiCamera \\\nbluenviron/mediamtx:latest-rpi\n```\n\nBe aware that the server is not compatible with cameras that requires a custom `libcamera` (like some ArduCam products), since it comes with a bundled `libcamera`. If you want to use a custom one, you can [compile from source](#custom-libcamera).\n\nCamera settings can be changed by using the `rpiCamera*` parameters:\n\n```yml\npaths:\n  cam:\n    source: rpiCamera\n    rpiCameraWidth: 1920\n    rpiCameraHeight: 1080\n```\n\nAll available parameters are listed in the [sample configuration file](/mediamtx.yml).\n\nIn order to add audio from a USB microfone, install GStreamer and alsa-utils:\n\n```sh\nsudo apt install -y gstreamer1.0-tools gstreamer1.0-rtsp gstreamer1.0-alsa alsa-utils\n```\n\nlist available audio cards with:\n\n```sh\narecord -L\n```\n\nSample output:\n\n```\nsurround51:CARD=ICH5,DEV=0\n    Intel ICH5, Intel ICH5\n    5.1 Surround output to Front, Center, Rear and Subwoofer speakers\ndefault:CARD=U0x46d0x809\n    USB Device 0x46d:0x809, USB Audio\n    Default Audio Device\n```\n\nFind the audio card of the microfone and take note of its name, for instance `default:CARD=U0x46d0x809`. Then create a new path that takes the video stream from the camera and audio from the microphone:\n\n```yml\npaths:\n  cam:\n    source: rpiCamera\n\n  cam_with_audio:\n    runOnInit: >\n      gst-launch-1.0\n      rtspclientsink name=s location=rtsp://localhost:$RTSP_PORT/cam_with_audio\n      rtspsrc location=rtsp://127.0.0.1:$RTSP_PORT/cam latency=0 ! rtph264depay ! s.\n      alsasrc device=default:CARD=U0x46d0x809 ! opusenc bitrate=16000 ! s.\n    runOnInitRestart: yes\n```\n\nThe resulting stream will be available in path `/cam_with_audio`.\n\n### By protocol\n\n#### SRT clients\n\nSRT is a protocol that allows to publish and read live data stream, providing encryption, integrity and a retransmission mechanism. It is usually used to transfer media streams encoded with MPEG-TS. In order to publish a stream to the server with the SRT protocol, use this URL:\n\n```\nsrt://localhost:8890?streamid=publish:mystream&pkt_size=1316\n```\n\nReplace `mystream` with any name you want. The resulting stream will be available in path `/mystream`.\n\nIf credentials are enabled, append username and password to `streamid`:\n\n```\nsrt://localhost:8890?streamid=publish:mystream:user:pass&pkt_size=1316\n```\n\nIf you need to use the standard stream ID syntax instead of the custom one in use by this server, see [Standard stream ID syntax](#standard-stream-id-syntax).\n\nIf you want to publish a stream by using a client in listening mode (i.e. with `mode=listener` appended to the URL), read the next section.\n\nKnown clients that can publish with SRT are [FFmpeg](#ffmpeg), [GStreamer](#gstreamer), [OBS Studio](#obs-studio).\n\n#### SRT cameras and servers\n\nIn order to ingest into the server a SRT stream from an existing server, camera or client in listening mode (i.e. with `mode=listener` appended to the URL), add the corresponding URL into the `source` parameter of a path:\n\n```yml\npaths:\n  proxied:\n    # url of the source stream, in the format srt://host:port?streamid=streamid&other_parameters\n    source: srt://original-url\n```\n\n#### WebRTC clients\n\nWebRTC is an API that makes use of a set of protocols and methods to connect two clients together and allow them to exchange real-time media or data streams. You can publish a stream with WebRTC and a web browser by visiting:\n\n```\nhttp://localhost:8889/mystream/publish\n```\n\nThe resulting stream will be available in path `/mystream`.\n\nWHIP is a WebRTC extensions that allows to publish streams by using a URL, without passing through a web page. This allows to use WebRTC as a general purpose streaming protocol. If you are using a software that supports WHIP (for instance, latest versions of OBS Studio), you can publish a stream to the server by using this URL:\n\n```\nhttp://localhost:8889/mystream/whip\n```\n\nRegarding authentication, read [Authenticating with WHIP/WHEP](#authenticating-with-whipwhep).\n\nDepending on the network it may be difficult to establish a connection between server and clients, read [Solving WebRTC connectivity issues](#solving-webrtc-connectivity-issues).\n\nKnown clients that can publish with WebRTC and WHIP are [FFmpeg](#ffmpeg), [GStreamer](#gstreamer), [OBS Studio](#obs-studio), [Unity](#unity) and [Web browsers](#web-browsers).\n\n#### WebRTC servers\n\nIn order to ingest into the server a WebRTC stream from an existing server, add the corresponding WHEP URL into the `source` parameter of a path:\n\n```yml\npaths:\n  proxied:\n    # url of the source stream, in the format whep://host:port/path (HTTP) or wheps:// (HTTPS)\n    source: wheps://host:port/path\n```\n\n#### RTSP clients\n\nRTSP is a protocol that allows to publish and read streams. It supports different underlying transport protocols and allows to encrypt streams in transit (see [RTSP-specific features](#rtsp-specific-features)). In order to publish a stream to the server with the RTSP protocol, use this URL:\n\n```\nrtsp://localhost:8554/mystream\n```\n\nThe resulting stream will be available in path `/mystream`.\n\nKnown clients that can publish with RTSP are [FFmpeg](#ffmpeg), [GStreamer](#gstreamer), [OBS Studio](#obs-studio).\n\n#### RTSP cameras and servers\n\nMost IP cameras expose their video stream by using a RTSP server that is embedded into the camera itself. In particular, cameras that are compliant with ONVIF profile S or T meet this requirement. You can use _MediaMTX_ to connect to one or multiple existing RTSP servers and read their video streams:\n\n```yml\npaths:\n  proxied:\n    # url of the source stream, in the format rtsp://user:pass@host:port/path\n    source: rtsp://original-url\n```\n\nThe resulting stream will be available in path `/proxied`.\n\nThe server supports any number of source streams (count is just limited by available hardware resources) it's enough to add additional entries to the paths section:\n\n```yml\npaths:\n  proxied1:\n    source: rtsp://url1\n\n  proxied2:\n    source: rtsp://url1\n```\n\n#### RTMP clients\n\nRTMP is a protocol that allows to read and publish streams, but is less versatile and less efficient than RTSP and WebRTC (doesn't support UDP, doesn't support most RTSP codecs, doesn't support feedback mechanism). Streams can be published to the server by using the URL:\n\n```\nrtmp://localhost/mystream\n```\n\nThe resulting stream will be available in path `/mystream`.\n\nIn case authentication is enabled, credentials can be passed to the server by using the `user` and `pass` query parameters:\n\n```\nrtmp://localhost/mystream?user=myuser&pass=mypass\n```\n\nKnown clients that can publish with RTMP are [FFmpeg](#ffmpeg), [GStreamer](#gstreamer), [OBS Studio](#obs-studio).\n\n#### RTMP cameras and servers\n\nYou can use _MediaMTX_ to connect to one or multiple existing RTMP servers and read their video streams:\n\n```yml\npaths:\n  proxied:\n    # url of the source stream, in the format rtmp://user:pass@host:port/path\n    source: rtmp://original-url\n```\n\nThe resulting stream will be available in path `/proxied`.\n\n#### HLS cameras and servers\n\nHLS is a streaming protocol that works by splitting streams into segments, and by serving these segments and a playlist with the HTTP protocol. You can use _MediaMTX_ to connect to one or multiple existing HLS servers and read their video streams:\n\n```yml\npaths:\n  proxied:\n    # url of the playlist of the stream, in the format http://user:pass@host:port/path\n    source: http://original-url/stream/index.m3u8\n```\n\nThe resulting stream will be available in path `/proxied`.\n\n#### UDP/MPEG-TS\n\nThe server supports ingesting UDP/MPEG-TS packets (i.e. MPEG-TS packets sent with UDP). Packets can be unicast, broadcast or multicast. For instance, you can generate a multicast UDP/MPEG-TS stream with GStreamer:\n\n```sh\ngst-launch-1.0 -v mpegtsmux name=mux alignment=1 ! udpsink host=238.0.0.1 port=1234 \\\nvideotestsrc ! video/x-raw,width=1280,height=720,format=I420 ! x264enc speed-preset=ultrafast bitrate=3000 key-int-max=60 ! video/x-h264,profile=high ! mux. \\\naudiotestsrc ! audioconvert ! avenc_aac ! mux.\n```\n\nor FFmpeg:\n\n```sh\nffmpeg -re -f lavfi -i testsrc=size=1280x720:rate=30 \\\n-c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k \\\n-f mpegts udp://238.0.0.1:1234?pkt_size=1316\n```\n\nEdit `mediamtx.yml` and replace everything inside section `paths` with the following content:\n\n```yml\npaths:\n  mypath:\n    source: udp://238.0.0.1:1234\n```\n\nThe resulting stream will be available in path `/mypath`.\n\nKnown clients that can publish with WebRTC and WHIP are [FFmpeg](#ffmpeg) and [GStreamer](#gstreamer).\n\n## Read from the server\n\n### By software\n\n#### FFmpeg\n\nFFmpeg can read a stream from the server in multiple ways (RTSP, RTMP, HLS, WebRTC with WHEP, SRT). The recommended one consists in reading with [RTSP](#rtsp):\n\n```sh\nffmpeg -i rtsp://localhost:8554/mystream -c copy output.mp4\n```\n\nThe RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)). You can set the transport protocol by using the `rtsp_transport` flag:\n\n```sh\nffmpeg -rtsp_transport tcp -i rtsp://localhost:8554/mystream -c copy output.mp4\n```\n\n#### GStreamer\n\nGStreamer can read a stream from the server in multiple ways (RTSP, RTMP, HLS, WebRTC with WHEP, SRT). The recommended one consists in reading with [RTSP](#rtsp):\n\n```sh\ngst-launch-1.0 rtspsrc location=rtsp://127.0.0.1:8554/mystream latency=0 ! decodebin ! autovideosink\n```\n\nThe RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)). You can change the transport protocol by using the `protocols` flag:\n\n```sh\ngst-launch-1.0 rtspsrc protocols=tcp location=rtsp://127.0.0.1:8554/mystream latency=0 ! decodebin ! autovideosink\n```\n\nIf encryption is enabled, set `tls-validation-flags` to `0`:\n\n```sh\ngst-launch-1.0 rtspsrc tls-validation-flags=0 location=rtsps://ip:8322/...\n```\n\nGStreamer also supports reading streams with WebRTC/WHEP, although track codecs must be specified in advance through the `video-caps` and `audio-caps` parameters. Furthermore, if audio is not present, `audio-caps` must be set anyway and must point to a PCMU codec. For instance, the command for reading a video-only H264 stream is:\n\n```sh\ngst-launch-1.0 whepsrc whep-endpoint=http://127.0.0.1:8889/stream/whep use-link-headers=true \\\nvideo-caps=\"application/x-rtp,media=video,encoding-name=H264,payload=127,clock-rate=90000\" \\\naudio-caps=\"application/x-rtp,media=audio,encoding-name=PCMU,payload=0,clock-rate=8000\" \\\n! rtph264depay ! decodebin ! autovideosink\n```\n\nWhile the command for reading an audio-only Opus stream is:\n\n```sh\ngst-launch-1.0 whepsrc whep-endpoint=\"http://127.0.0.1:8889/stream/whep\" use-link-headers=true \\\naudio-caps=\"application/x-rtp,media=audio,encoding-name=OPUS,payload=111,clock-rate=48000,encoding-params=(string)2\" \\\n! rtpopusdepay ! decodebin ! autoaudiosink\n```\n\nWhile the command for reading a H264 and Opus stream is:\n\n```sh\ngst-launch-1.0 whepsrc whep-endpoint=http://127.0.0.1:8889/stream/whep use-link-headers=true \\\nvideo-caps=\"application/x-rtp,media=video,encoding-name=H264,payload=127,clock-rate=90000\" \\\naudio-caps=\"application/x-rtp,media=audio,encoding-name=OPUS,payload=111,clock-rate=48000,encoding-params=(string)2\" \\\n! decodebin ! autovideosink\n```\n\n#### VLC\n\nVLC can read a stream from the server in multiple ways (RTSP, RTMP, HLS, SRT). The recommended one consists in reading with [RTSP](#rtsp):\n\n```sh\nvlc --network-caching=50 rtsp://localhost:8554/mystream\n```\n\nThe RTSP protocol supports multiple underlying transport protocols, each with its own characteristics (see [RTSP-specific features](#rtsp-specific-features)).\n\nIn order to use the TCP transport protocol, use the `--rtsp_tcp` flag:\n\n```sh\nvlc --network-caching=50 --rtsp-tcp rtsp://localhost:8554/mystream\n```\n\nIn order to use the UDP-multicast transport protocol, append `?vlcmulticast` to the URL:\n\n```sh\nvlc --network-caching=50 rtsp://localhost:8554/mystream?vlcmulticast\n```\n\n##### Ubuntu bug\n\nThe VLC shipped with Ubuntu 21.10 doesn't support playing RTSP due to a license issue (see [here](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=982299) and [here](https://stackoverflow.com/questions/69766748/cvlc-cannot-play-rtsp-omxplayer-instead-can)). To fix the issue, remove the default VLC instance and install the snap version:\n\n```\nsudo apt purge -y vlc\nsnap install vlc\n```\n\n##### Encrypted streams\n\nAt the moment VLC doesn't support reading encrypted RTSP streams. However, you can use a proxy like [stunnel](https://www.stunnel.org) or [nginx](https://nginx.org/) or a local _MediaMTX_ instance to decrypt streams before reading them.\n\n#### Unity\n\nSoftware written with the Unity Engine can read a stream from the server by using the [WebRTC protocol](#webrtc).\n\nCreate a new Unity project or open an existing open.\n\nOpen _Window -> Package Manager_, click on the plus sign, _Add Package by name..._ and insert `com.unity.webrtc`. Wait for the package to be installed.\n\nIn the _Project_ window, under `Assets`, create a new C# Script called `WebRTCReader.cs` with this content:\n\n```cs\nusing System.Collections;\nusing UnityEngine;\nusing Unity.WebRTC;\n\npublic class WebRTCReader : MonoBehaviour\n{\n    public string url = \"http://localhost:8889/stream/whep\";\n\n    private RTCPeerConnection pc;\n    private MediaStream receiveStream;\n\n    void Start()\n    {\n        UnityEngine.UI.RawImage rawImage = gameObject.GetComponentInChildren<UnityEngine.UI.RawImage>();\n        AudioSource audioSource = gameObject.GetComponentInChildren<AudioSource>();\n        pc = new RTCPeerConnection();\n        receiveStream = new MediaStream();\n\n        pc.OnTrack = e =>\n        {\n            receiveStream.AddTrack(e.Track);\n        };\n\n        receiveStream.OnAddTrack = e =>\n        {\n            if (e.Track is VideoStreamTrack videoTrack)\n            {\n                videoTrack.OnVideoReceived += (tex) =>\n                {\n                    rawImage.texture = tex;\n                };\n            }\n            else if (e.Track is AudioStreamTrack audioTrack)\n            {\n                audioSource.SetTrack(audioTrack);\n                audioSource.loop = true;\n                audioSource.Play();\n            }\n        };\n\n        RTCRtpTransceiverInit init = new RTCRtpTransceiverInit();\n        init.direction = RTCRtpTransceiverDirection.RecvOnly;\n        pc.AddTransceiver(TrackKind.Audio, init);\n        pc.AddTransceiver(TrackKind.Video, init);\n\n        StartCoroutine(WebRTC.Update());\n        StartCoroutine(createOffer());\n    }\n\n    private IEnumerator createOffer()\n    {\n        var op = pc.CreateOffer();\n        yield return op;\n        if (op.IsError) {\n            Debug.LogError(\"CreateOffer() failed\");\n            yield break;\n        }\n\n        yield return setLocalDescription(op.Desc);\n    }\n\n    private IEnumerator setLocalDescription(RTCSessionDescription offer)\n    {\n        var op = pc.SetLocalDescription(ref offer);\n        yield return op;\n        if (op.IsError) {\n            Debug.LogError(\"SetLocalDescription() failed\");\n            yield break;\n        }\n\n        yield return postOffer(offer);\n    }\n\n    private IEnumerator postOffer(RTCSessionDescription offer)\n    {\n        var content = new System.Net.Http.StringContent(offer.sdp);\n        content.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue(\"application/sdp\");\n        var client = new System.Net.Http.HttpClient();\n\n        var task = System.Threading.Tasks.Task.Run(async () => {\n            var res = await client.PostAsync(new System.UriBuilder(url).Uri, content);\n            res.EnsureSuccessStatusCode();\n            return await res.Content.ReadAsStringAsync();\n        });\n        yield return new WaitUntil(() => task.IsCompleted);\n        if (task.Exception != null) {\n            Debug.LogError(task.Exception);\n            yield break;\n        }\n\n        yield return setRemoteDescription(task.Result);\n    }\n\n    private IEnumerator setRemoteDescription(string answer)\n    {\n        RTCSessionDescription desc = new RTCSessionDescription();\n        desc.type = RTCSdpType.Answer;\n        desc.sdp = answer;\n        var op = pc.SetRemoteDescription(ref desc);\n        yield return op;\n        if (op.IsError) {\n            Debug.LogError(\"SetRemoteDescription() failed\");\n            yield break;\n        }\n\n        yield break;\n    }\n\n    void OnDestroy()\n    {\n        pc?.Close();\n        pc?.Dispose();\n        receiveStream?.Dispose();\n    }\n}\n```\n\nEdit the `url` variable according to your needs.\n\nIn the _Hierarchy_ window, find or create a scene. Inside the scene, add a _Canvas_. Inside the Canvas, add a _Raw Image_ and an _Audio Source_. Then add the `WebRTCReader.cs` script as component of the canvas, by dragging it inside the _Inspector_ window. then Press the _Play_ button at the top of the page.\n\n#### Web browsers\n\nWeb browsers can read a stream from the server in multiple ways (WebRTC or HLS).\n\nYou can read a stream by using the [WebRTC protocol](#webrtc-1) by visiting the web page:\n\n```\nhttp://localhost:8889/mystream\n```\n\nThis web page can be embedded into another web page by using an iframe:\n\n```html\n<iframe src=\"http://mediamtx-ip:8889/mystream\" scrolling=\"no\"></iframe>\n```\n\nFor more advanced setups, you can create and serve a custom web page by starting from the [source code of the WebRTC read page](internal/servers/webrtc/read_index.html).\n\nWeb browsers can also read a stream with the [HLS protocol](#hls). Latency is higher but there are less problems related to connectivity between server and clients, furthermore the server load can be balanced by using a common HTTP CDN (like CloudFront or Cloudflare), and this allows to handle readers in the order of millions. Visit the web page:\n\n```\nhttp://localhost:8888/mystream\n```\n\nThis web page can be embedded into another web page by using an iframe:\n\n```html\n<iframe src=\"http://mediamtx-ip:8888/mystream\" scrolling=\"no\"></iframe>\n```\n\nFor more advanced setups, you can create and serve a custom web page by starting from the [source code of the HLS read page](internal/servers/hls/index.html).\n\n### By protocol\n\n#### SRT\n\nSRT is a protocol that allows to publish and read live data stream, providing encryption, integrity and a retransmission mechanism. It is usually used to transfer media streams encoded with MPEG-TS. In order to read a stream from the server with the SRT protocol, use this URL:\n\n```\nsrt://localhost:8890?streamid=read:mystream\n```\n\nReplace `mystream` with the path name.\n\nIf credentials are enabled, append username and password to `streamid`:\n\n```\nsrt://localhost:8890?streamid=read:mystream:user:pass\n```\n\nIf you need to use the standard stream ID syntax instead of the custom one in use by this server, see [Standard stream ID syntax](#standard-stream-id-syntax).\n\nKnown clients that can read with SRT are [FFmpeg](#ffmpeg-1), [GStreamer](#gstreamer-1) and [VLC](#vlc).\n\n#### WebRTC\n\nWebRTC is an API that makes use of a set of protocols and methods to connect two clients together and allow them to exchange real-time media or data streams. You can read a stream with WebRTC and a web browser by visiting:\n\n```\nhttp://localhost:8889/mystream\n```\n\nWHEP is a WebRTC extensions that allows to read streams by using a URL, without passing through a web page. This allows to use WebRTC as a general purpose streaming protocol. If you are using a software that supports WHEP, you can read a stream from the server by using this URL:\n\n```\nhttp://localhost:8889/mystream/whep\n```\n\nRegarding authentication, read [Authenticating with WHIP/WHEP](#authenticating-with-whipwhep).\n\nDepending on the network it may be difficult to establish a connection between server and clients, read [Solving WebRTC connectivity issues](#solving-webrtc-connectivity-issues).\n\nKnown clients that can read with WebRTC and WHEP are [FFmpeg](#ffmpeg-1), [GStreamer](#gstreamer-1), [Unity](#unity-1) and [web browsers](#web-browsers-1).\n\n#### RTSP\n\nRTSP is a protocol that allows to publish and read streams. It supports different underlying transport protocols and allows to encrypt streams in transit (see [RTSP-specific features](#rtsp-specific-features)). In order to read a stream with the RTSP protocol, use this URL:\n\n```\nrtsp://localhost:8554/mystream\n```\n\nKnown clients that can read with RTSP are [FFmpeg](#ffmpeg-1), [GStreamer](#gstreamer-1) and [VLC](#vlc).\n\n##### Latency\n\nThe RTSP protocol doesn't introduce any latency by itself. Latency is usually introduced by clients, that put frames in a buffer to compensate network fluctuations. In order to decrease latency, the best way consists in tuning the client. For instance, in VLC, latency can be decreased by decreasing the _Network caching_ parameter, that is available in the _Open network stream_ dialog or alternatively can be set with the command line:\n\n```\nvlc --network-caching=50 rtsp://...\n```\n\n#### RTMP\n\nRTMP is a protocol that allows to read and publish streams, but is less versatile and less efficient than RTSP and WebRTC (doesn't support UDP, doesn't support most RTSP codecs, doesn't support feedback mechanism). Streams can be read from the server by using the URL:\n\n```\nrtmp://localhost/mystream\n```\n\nIn case authentication is enabled, credentials can be passed to the server by using the `user` and `pass` query parameters:\n\n```\nrtmp://localhost/mystream?user=myuser&pass=mypass\n```\n\nKnown clients that can read with RTMP are [FFmpeg](#ffmpeg-1), [GStreamer](#gstreamer-1) and [VLC](#vlc).\n\n#### HLS\n\nHLS is a protocol that works by splitting streams into segments, and by serving these segments and a playlist with the HTTP protocol. You can use _MediaMTX_ to generate a HLS stream, that is accessible through a web page:\n\n```\nhttp://localhost:8888/mystream\n```\n\nand can also be accessed without using the browsers, by software that supports the HLS protocol (for instance VLC or _MediaMTX_ itself) by using this URL:\n\n```\nhttp://localhost:8888/mystream/index.m3u8\n```\n\nKnown clients that can read with HLS are [FFmpeg](#ffmpeg-1), [GStreamer](#gstreamer-1), [VLC](#vlc) and [web browsers](#web-browsers-1).\n\n##### LL-HLS\n\nLow-Latency HLS is a recently standardized variant of the protocol that allows to greatly reduce playback latency. It works by splitting segments into parts, that are served before the segment is complete. LL-HLS is enabled by default. If the stream is not shown correctly, try tuning the hlsPartDuration parameter, for instance:\n\n```yml\nhlsPartDuration: 500ms\n```\n\n##### Compatibility with Apple devices\n\nIn order to correctly display Low-Latency HLS streams in Safari running on Apple devices (iOS or macOS), a TLS certificate is needed and can be generated with OpenSSL:\n\n```sh\nopenssl genrsa -out server.key 2048\nopenssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650\n```\n\nSet the `hlsEncryption`, `hlsServerKey` and `hlsServerCert` parameters in the configuration file:\n\n```yml\nhlsEncryption: yes\nhlsServerKey: server.key\nhlsServerCert: server.crt\n```\n\nKeep also in mind that not all H264 video streams can be played on Apple Devices due to some intrinsic properties (distance between I-Frames, profile). If the video can't be played correctly, you can either:\n\n* re-encode it by following instructions in this README\n* disable the Low-latency variant of HLS and go back to the legacy variant:\n\n  ```yml\n    hlsVariant: mpegts\n  ```\n\n##### Latency\n\nin HLS, latency is introduced since a client must wait for the server to generate segments before downloading them. This latency amounts to 500ms-3s when the low-latency HLS variant is enabled (and it is by default), otherwise amounts to 1-15secs.\n\nTo decrease the latency, you can:\n\n* try decreasing the hlsPartDuration parameter\n* try decreasing the hlsSegmentDuration parameter\n* The segment duration is influenced by the interval between the IDR frames of the video track. An IDR frame is a frame that can be decoded independently from the others. The server changes the segment duration in order to include at least one IDR frame into each segment. Therefore, you need to decrease the interval between the IDR frames. This can be done in two ways:\n\n  * if the stream is being hardware-generated (i.e. by a camera), there's usually a setting called Key-Frame Interval in the camera configuration page\n  * otherwise, the stream must be re-encoded. It's possible to tune the IDR frame interval by using ffmpeg's -g option:\n\n    ```sh\n    ffmpeg -i rtsp://original-stream -c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k -max_muxing_queue_size 1024 -g 30 -f rtsp rtsp://localhost:$RTSP_PORT/compressed\n    ```\n\n## Other features\n\n### Configuration\n\nAll the configuration parameters are listed and commented in the [configuration file](mediamtx.yml).\n\nThere are 3 ways to change the configuration:\n\n1. By editing the `mediamtx.yml` file, that is\n\n   * included into the release bundle\n   * available in the root folder of the Docker image (`/mediamtx.yml`); it can be overridden in this way:\n\n     ```\n     docker run --rm -it --network=host -v \"$PWD/mediamtx.yml:/mediamtx.yml:ro\" bluenviron/mediamtx\n     ```\n\n   The configuration can be changed dynamically when the server is running (hot reloading) by writing to the configuration file. Changes are detected and applied without disconnecting existing clients, whenever it's possible.\n\n2. By overriding configuration parameters with environment variables, in the format `MTX_PARAMNAME`, where `PARAMNAME` is the uppercase name of a parameter. For instance, the `rtspAddress` parameter can be overridden in the following way:\n\n   ```\n   MTX_RTSPADDRESS=\"127.0.0.1:8554\" ./mediamtx\n   ```\n\n   Parameters that have array as value can be overridden by setting a comma-separated list. For example:\n\n   ```\n   MTX_RTSPTRANSPORTS=\"tcp,udp\"\n   ```\n\n   Parameters in maps can be overridden by using underscores, in the following way:\n\n   ```\n   MTX_PATHS_TEST_SOURCE=rtsp://myurl ./mediamtx\n   ```\n\n   This method is particularly useful when using Docker; any configuration parameter can be changed by passing environment variables with the `-e` flag:\n\n   ```\n   docker run --rm -it --network=host -e MTX_PATHS_TEST_SOURCE=rtsp://myurl bluenviron/mediamtx\n   ```\n\n3. By using the [Control API](#control-api).\n\n### Authentication\n\n#### Internal\n\nThe server provides three way to authenticate users:\n* Internal: users are stored in the configuration file\n* HTTP-based: an external HTTP URL is contacted to perform authentication\n* JWT: an external identity server provides authentication through JWTs\n\nThe internal authentication method is the default one. Users are stored inside the configuration file, in this format:\n\n```yml\nauthInternalUsers:\n  # Username. 'any' means any user, including anonymous ones.\n- user: any\n  # Password. Not used in case of 'any' user.\n  pass:\n  # IPs or networks allowed to use this user. An empty list means any IP.\n  ips: []\n  # List of permissions.\n  permissions:\n    # Available actions are: publish, read, playback, api, metrics, pprof.\n  - action: publish\n    # Paths can be set to further restrict access to a specific path.\n    # An empty path means any path.\n    # Regular expressions can be used by using a tilde as prefix.\n    path:\n  - action: read\n    path:\n  - action: playback\n    path:\n```\n\nOnly clients that provide username and passwords will be able to perform a certain action:\n\n```\nffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://myuser:mypass@localhost:8554/mystream\n```\n\nIf storing plain credentials in the configuration file is a security problem, username and passwords can be stored as hashed strings. The Argon2 and SHA256 hashing algorithms are supported. To use Argon2, the string must be hashed using Argon2id (recommended) or Argon2i:\n\n```\necho -n \"mypass\" | argon2 saltItWithSalt -id -l 32 -e\n```\n\nThen stored with the `argon2:` prefix:\n\n```yml\nauthInternalUsers:\n- user: argon2:$argon2id$v=19$m=4096,t=3,p=1$MTIzNDU2Nzg$OGGO0eCMN0ievb4YGSzvS/H+Vajx1pcbUmtLp2tRqRU\n  pass: argon2:$argon2i$v=19$m=4096,t=3,p=1$MTIzNDU2Nzg$oct3kOiFywTdDdt19kT07hdvmsPTvt9zxAUho2DLqZw\n  permissions:\n  - action: publish\n```\n\nTo use SHA256, the string must be hashed with SHA256 and encoded with base64:\n\n```\necho -n \"mypass\" | openssl dgst -binary -sha256 | openssl base64\n```\n\nThen stored with the `sha256:` prefix:\n\n```yml\nauthInternalUsers:\n- user: sha256:j1tsRqDEw9xvq/D7/9tMx6Jh/jMhk3UfjwIB2f1zgMo=\n  pass: sha256:BdSWkrdV+ZxFBLUQQY7+7uv9RmiSVA8nrPmjGjJtZQQ=\n  permissions:\n  - action: publish\n```\n\n**WARNING**: enable encryption or use a VPN to ensure that no one is intercepting the credentials in transit.\n\n#### HTTP-based\n\nAuthentication can be delegated to an external HTTP server:\n\n```yml\nauthMethod: http\nauthHTTPAddress: http://myauthserver/auth\n```\n\nEach time a user needs to be authenticated, the specified URL will be requested with the POST method and this payload:\n\n```json\n{\n  \"user\": \"user\",\n  \"password\": \"password\",\n  \"ip\": \"ip\",\n  \"action\": \"publish|read|playback|api|metrics|pprof\",\n  \"path\": \"path\",\n  \"protocol\": \"rtsp|rtmp|hls|webrtc|srt\",\n  \"id\": \"id\",\n  \"query\": \"query\"\n}\n```\n\nIf the URL returns a status code that begins with `20` (i.e. `200`), authentication is successful, otherwise it fails. Be aware that it's perfectly normal for the authentication server to receive requests with empty users and passwords, i.e.:\n\n```json\n{\n  \"user\": \"\",\n  \"password\": \"\"\n}\n```\n\nThis happens because RTSP clients don't provide credentials until they are asked to. In order to receive the credentials, the authentication server must reply with status code `401`, then the client will send credentials.\n\nSome actions can be excluded from the process:\n\n```yml\n# Actions to exclude from HTTP-based authentication.\n# Format is the same as the one of user permissions.\nauthHTTPExclude:\n- action: api\n- action: metrics\n- action: pprof\n```\n\n#### JWT-based\n\nAuthentication can be delegated to an external identity server, that is capable of generating JWTs and provides a JWKS endpoint. With respect to the HTTP-based method, this has the advantage that the external server is contacted just once, and not for every request, greatly improving performance. In order to use the JWT-based authentication method, set `authMethod` and `authJWTJWKS`:\n\n```yml\nauthMethod: jwt\nauthJWTJWKS: http://my_identity_server/jwks_endpoint\nauthJWTClaimKey: mediamtx_permissions\n```\n\nThe JWT is expected to contain a claim, with a list of permissions in the same format as the one of user permissions:\n\n```json\n{\n \"mediamtx_permissions\": [\n    {\n      \"action\": \"publish\",\n      \"path\": \"\"\n    }\n  ]\n}\n```\n\nClients are expected to pass the JWT in the Authorization header (in case of HLS, WebRTC and all web-based features) or in query parameters (in case of all other protocols), for instance:\n\n```\nffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:8554/mystream?jwt=MY_JWT\n```\n\nFor instance (HLS):\n\n```\nGET /mypath/index.m3u8 HTTP/1.1\nHost: example.com\nAuthorization: Bearer MY_JWT\n```\n\nHere's a tutorial on how to setup the [Keycloak identity server](https://www.keycloak.org/) in order to provide such JWTs:\n\n1. Start Keycloak:\n\n   ```\n   docker run --name=keycloak -p 8080:8080 -e KEYCLOAK_ADMIN=admin -e KEYCLOAK_ADMIN_PASSWORD=admin quay.io/keycloak/keycloak:23.0.7 start-dev\n   ```\n\n2. Open the Keycloak administration console on http://localhost:8080, click on _master_ in the top left corner, _create realm_, set realm name to `mediamtx`, Save\n\n3. Open page _Client scopes_, _create client scope_, set name to `mediamtx`, Save\n\n4. Open tab _Mappers_, _Configure a new Mapper_, _User Attribute_\n\n   * Name: `mediamtx_permissions`\n   * User Attribute: `mediamtx_permissions`\n   * Token Claim Name: `mediamtx_permissions`\n   * Claim JSON Type: `JSON`\n   * Multivalued: `On`\n\n   Save\n\n5. Open page _Clients_, _Create client_, set Client ID to `mediamtx`, Next, Client authentication `On`, Next, Save\n\n6. Open tab _Credentials_, copy client secret somewhere\n\n7. Open tab _Client scopes_, _Add client scope_, Select `mediamtx`, Add, Default\n\n8. Open page _Users_, _Add user_, Username `testuser`, Tab credentials, _Set password_, pick a password, Save\n\n9. Open tab _Attributes_, _Add an attribute_\n\n   * Key: `mediamtx_permissions`\n   * Value: `{\"action\":\"publish\", \"path\": \"\"}`\n\n   You can add as many attributes with key `mediamtx_permissions` as you want, each with a single permission in it\n\n10. In MediaMTX, use the following URL:\n\n    ```yml\n    authJWTJWKS: http://localhost:8080/realms/mediamtx/protocol/openid-connect/certs\n    ```\n\n11. Perform authentication on Keycloak:\n\n    ```\n    curl \\\n    -d \"client_id=mediamtx\" \\\n    -d \"client_secret=$CLIENT_SECRET\" \\\n    -d \"username=$USER\" \\\n    -d \"password=$PASS\" \\\n    -d \"grant_type=password\" \\\n    http://localhost:8080/realms/mediamtx/protocol/openid-connect/token\n    ```\n\n    The JWT is inside the `access_token` key of the response:\n\n    ```json\n    {\"access_token\":\"eyJhbGciOiJSUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICIyNzVjX3ptOVlOdHQ0TkhwWVk4Und6ZndUclVGSzRBRmQwY3lsM2wtY3pzIn0.eyJleHAiOjE3MDk1NTUwOTIsImlhdCI6MTcwOTU1NDc5MiwianRpIjoiMzE3ZTQ1NGUtNzczMi00OTM1LWExNzAtOTNhYzQ2ODhhYWIxIiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MDgwL3JlYWxtcy9tZWRpYW10eCIsImF1ZCI6ImFjY291bnQiLCJzdWIiOiI2NTBhZDA5Zi03MDgxLTQyNGItODI4Ni0xM2I3YTA3ZDI0MWEiLCJ0eXAiOiJCZWFyZXIiLCJhenAiOiJtZWRpYW10eCIsInNlc3Npb25fc3RhdGUiOiJjYzJkNDhjYy1kMmU5LTQ0YjAtODkzZS0wYTdhNjJiZDI1YmQiLCJhY3IiOiIxIiwiYWxsb3dlZC1vcmlnaW5zIjpbIi8qIl0sInJlYWxtX2FjY2VzcyI6eyJyb2xlcyI6WyJvZmZsaW5lX2FjY2VzcyIsInVtYV9hdXRob3JpemF0aW9uIiwiZGVmYXVsdC1yb2xlcy1tZWRpYW10eCJdfSwicmVzb3VyY2VfYWNjZXNzIjp7ImFjY291bnQiOnsicm9sZXMiOlsibWFuYWdlLWFjY291bnQiLCJtYW5hZ2UtYWNjb3VudC1saW5rcyIsInZpZXctcHJvZmlsZSJdfX0sInNjb3BlIjoibWVkaWFtdHggcHJvZmlsZSBlbWFpbCIsInNpZCI6ImNjMmQ0OGNjLWQyZTktNDRiMC04OTNlLTBhN2E2MmJkMjViZCIsImVtYWlsX3ZlcmlmaWVkIjpmYWxzZSwibWVkaWFtdHhfcGVybWlzc2lvbnMiOlt7ImFjdGlvbiI6InB1Ymxpc2giLCJwYXRocyI6ImFsbCJ9XSwicHJlZmVycmVkX3VzZXJuYW1lIjoidGVzdHVzZXIifQ.Gevz7rf1qHqFg7cqtSfSP31v_NS0VH7MYfwAdra1t6Yt5rTr9vJzqUeGfjYLQWR3fr4XC58DrPOhNnILCpo7jWRdimCnbPmuuCJ0AYM-Aoi3PAsWZNxgmtopq24_JokbFArY9Y1wSGFvF8puU64lt1jyOOyxf2M4cBHCs_EarCKOwuQmEZxSf8Z-QV9nlfkoTUszDCQTiKyeIkLRHL2Iy7Fw7_T3UI7sxJjVIt0c6HCNJhBBazGsYzmcSQ_GrmhbUteMTg00o6FicqkMBe99uZFnx9wIBm_QbO9hbAkkzF923I-DTAQrFLxT08ESMepDwmzFrmnwWYBLE3u8zuUlCA\",\"expires_in\":300,\"refresh_expires_in\":1800,\"refresh_token\":\"eyJhbGciOiJIUzI1NiIsInR5cCIgOiAiSldUIiwia2lkIiA6ICI3OTI3Zjg4Zi05YWM4LTRlNmEtYWE1OC1kZmY0MDQzZDRhNGUifQ.eyJleHAiOjE3MDk1NTY1OTIsImlhdCI6MTcwOTU1NDc5MiwianRpIjoiMGVhZWFhMWItYzNhMC00M2YxLWJkZjAtZjI2NTRiODlkOTE3IiwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo4MDgwL3JlYWxtcy9tZWRpYW10eCIsImF1ZCI6Imh0dHA6Ly9sb2NhbGhvc3Q6ODA4MC9yZWFsbXMvbWVkaWFtdHgiLCJzdWIiOiI2NTBhZDA5Zi03MDgxLTQyNGItODI4Ni0xM2I3YTA3ZDI0MWEiLCJ0eXAiOiJSZWZyZXNoIiwiYXpwIjoibWVkaWFtdHgiLCJzZXNzaW9uX3N0YXRlIjoiY2MyZDQ4Y2MtZDJlOS00NGIwLTg5M2UtMGE3YTYyYmQyNWJkIiwic2NvcGUiOiJtZWRpYW10eCBwcm9maWxlIGVtYWlsIiwic2lkIjoiY2MyZDQ4Y2MtZDJlOS00NGIwLTg5M2UtMGE3YTYyYmQyNWJkIn0.yuXV8_JU0TQLuosNdp5xlYMjn7eO5Xq-PusdHzE7bsQ\",\"token_type\":\"Bearer\",\"not-before-policy\":0,\"session_state\":\"cc2d48cc-d2e9-44b0-893e-0a7a62bd25bd\",\"scope\":\"mediamtx profile email\"}\n    ```\n\n### Encrypt the configuration\n\nThe configuration file can be entirely encrypted for security purposes by using the `crypto_secretbox` function of the NaCL function. An online tool for performing this operation is [available here](https://play.golang.org/p/rX29jwObNe4).\n\nAfter performing the encryption, put the base64-encoded result into the configuration file, and launch the server with the `MTX_CONFKEY` variable:\n\n```\nMTX_CONFKEY=mykey ./mediamtx\n```\n\n### Remuxing, re-encoding, compression\n\nTo change the format, codec or compression of a stream, use _FFmpeg_ or _GStreamer_ together with _MediaMTX_. For instance, to re-encode an existing stream, that is available in the `/original` path, and publish the resulting stream in the `/compressed` path, edit `mediamtx.yml` and replace everything inside section `paths` with the following content:\n\n```yml\npaths:\n  compressed:\n  original:\n    runOnReady: >\n      ffmpeg -i rtsp://localhost:$RTSP_PORT/$MTX_PATH\n        -c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k\n        -max_muxing_queue_size 1024 -f rtsp rtsp://localhost:$RTSP_PORT/compressed\n    runOnReadyRestart: yes\n```\n\n### Record streams to disk\n\nTo save available streams to disk, set the `record` and the `recordPath` parameter in the configuration file:\n\n```yml\npathDefaults:\n  # Record streams to disk.\n  record: yes\n  # Path of recording segments.\n  # Extension is added automatically.\n  # Available variables are %path (path name), %Y %m %d %H %M %S %f %s (time in strftime format)\n  recordPath: ./recordings/%path/%Y-%m-%d_%H-%M-%S-%f\n```\n\nAll available recording parameters are listed in the [sample configuration file](/mediamtx.yml).\n\nBe aware that not all codecs can be saved with all formats, as described in the compatibility matrix at the beginning of the README.\n\nTo upload recordings to a remote location, you can use _MediaMTX_ together with [rclone](https://github.com/rclone/rclone), a command line tool that provides file synchronization capabilities with a huge variety of services (including S3, FTP, SMB, Google Drive):\n\n1. Download and install [rclone](https://github.com/rclone/rclone).\n\n2. Configure _rclone_:\n\n   ```\n   rclone config\n   ```\n\n3. Place `rclone` into the `runOnInit` and `runOnRecordSegmentComplete` hooks:\n\n   ```yml\n   pathDefaults:\n     # this is needed to sync segments after a crash.\n     # replace myconfig with the name of the rclone config.\n     runOnInit: rclone sync -v ./recordings myconfig:/my-path/recordings\n\n     # this is called when a segment has been finalized.\n     # replace myconfig with the name of the rclone config.\n     runOnRecordSegmentComplete: rclone sync -v --min-age=1ms ./recordings myconfig:/my-path/recordings\n   ```\n\n   If you want to delete local segments after they are uploaded, replace `rclone sync` with `rclone move`.\n\n### Playback recorded streams\n\nExisting recordings can be served to users through a dedicated HTTP server, that can be enabled inside the configuration:\n\n```yml\nplayback: yes\nplaybackAddress: :9996\n```\n\nThe server provides an endpoint to list recorded timespans:\n\n```\nhttp://localhost:9996/list?path=[mypath]&start=[start]&end=[end]\n```\n\nWhere:\n\n* [mypath] is the name of a path\n* [start] (optional) is the start date in [RFC3339 format](https://www.utctime.net/)\n* [end] (optional) is the end date in [RFC3339 format](https://www.utctime.net/)\n\nThe server will return a list of timespans in JSON format:\n\n```json\n[\n  {\n    \"start\": \"2006-01-02T15:04:05Z07:00\",\n    \"duration\": \"60.0\",\n    \"url\": \"http://localhost:9996/get?path=[mypath]&start=2006-01-02T15%3A04%3A05Z07%3A00&duration=60.0\"\n  },\n  {\n    \"start\": \"2006-01-02T15:07:05Z07:00\",\n    \"duration\": \"32.33\",\n    \"url\": \"http://localhost:9996/get?path=[mypath]&start=2006-01-02T15%3A07%3A05Z07%3A00&duration=32.33\"\n  }\n]\n```\n\nThe server provides an endpoint to download recordings:\n\n```\nhttp://localhost:9996/get?path=[mypath]&start=[start]&duration=[duration]&format=[format]\n```\n\nWhere:\n\n* [mypath] is the path name\n* [start] is the start date in [RFC3339 format](https://www.utctime.net/)\n* [duration] is the maximum duration of the recording in seconds\n* [format] (optional) is the output format of the stream. Available values are \"fmp4\" (default) and \"mp4\"\n\nAll parameters must be [url-encoded](https://www.urlencoder.org/). For instance:\n\n```\nhttp://localhost:9996/get?path=mypath&start=2024-01-14T16%3A33%3A17%2B00%3A00&duration=200.5\n```\n\nThe resulting stream uses the fMP4 format, that is natively compatible with any browser, therefore its URL can be directly inserted into a \\<video> tag:\n\n```html\n<video controls>\n  <source src=\"http://localhost:9996/get?path=[mypath]&start=[start_date]&duration=[duration]\" type=\"video/mp4\" />\n</video>\n```\n\nThe fMP4 format may offer limited compatibility with some players. To fix the issue, it's possible to use the standard MP4 format, by adding `format=mp4` to a `/get` request:\n\n```\nhttp://localhost:9996/get?path=[mypath]&start=[start_date]&duration=[duration]&format=mp4\n```\n\n### Forward streams to other servers\n\nTo forward incoming streams to another server, use _FFmpeg_ inside the `runOnReady` parameter:\n\n```yml\npathDefaults:\n  runOnReady: >\n    ffmpeg -i rtsp://localhost:$RTSP_PORT/$MTX_PATH\n    -c copy\n    -f rtsp rtsp://other-server:8554/another-path\n  runOnReadyRestart: yes\n```\n\n### Proxy requests to other servers\n\nThe server allows to proxy incoming requests to other servers or cameras. This is useful to expose servers or cameras behind a NAT. Edit `mediamtx.yml` and replace everything inside section `paths` with the following content:\n\n```yml\npaths:\n  \"~^proxy_(.+)$\":\n    # If path name is a regular expression, $G1, G2, etc will be replaced\n    # with regular expression groups.\n    source: rtsp://other-server:8554/$G1\n    sourceOnDemand: yes\n```\n\nAll requests addressed to `rtsp://server:8854/proxy_a` will be forwarded to `rtsp://other-server:8854/a` and so on.\n\n### On-demand publishing\n\nEdit `mediamtx.yml` and replace everything inside section `paths` with the following content:\n\n```yml\npaths:\n  ondemand:\n    runOnDemand: ffmpeg -re -stream_loop -1 -i file.ts -c copy -f rtsp rtsp://localhost:$RTSP_PORT/$MTX_PATH\n    runOnDemandRestart: yes\n```\n\nThe command inserted into `runOnDemand` will start only when a client requests the path `ondemand`, therefore the file will start streaming only when requested.\n\n### Start on boot\n\n#### Linux\n\nOn most Linux distributions (including Ubuntu and Debian, but not OpenWrt), _systemd_ is in charge of managing services and starting them on boot.\n\nMove the server executable and configuration in global folders:\n\n```sh\nsudo mv mediamtx /usr/local/bin/\nsudo mv mediamtx.yml /usr/local/etc/\n```\n\nCreate a _systemd_ service:\n\n```sh\nsudo tee /etc/systemd/system/mediamtx.service >/dev/null << EOF\n[Unit]\nWants=network.target\n[Service]\nExecStart=/usr/local/bin/mediamtx /usr/local/etc/mediamtx.yml\n[Install]\nWantedBy=multi-user.target\nEOF\n```\n\nIf SELinux is enabled (for instance in case of RedHat, Rocky, CentOS++), add correct security context:\n\n```sh\nsemanage fcontext -a -t bin_t /usr/local/bin/mediamtx\nrestorecon -Fv /usr/local/bin/mediamtx\n```\n\nEnable and start the service:\n\n```sh\nsudo systemctl daemon-reload\nsudo systemctl enable mediamtx\nsudo systemctl start mediamtx\n```\n\n#### OpenWrt\n\nMove the server executable and configuration in global folders:\n\n```sh\nmv mediamtx /usr/bin/\nmkdir -p /usr/etc && mv mediamtx.yml /usr/etc/\n```\n\nCreate a procd service:\n\n```sh\ntee /etc/init.d/mediamtx >/dev/null << EOF\n#!/bin/sh /etc/rc.common\nUSE_PROCD=1\nSTART=95\nSTOP=01\nstart_service() {\n    procd_open_instance\n    procd_set_param command /usr/bin/mediamtx\n    procd_set_param stdout 1\n    procd_set_param stderr 1\n    procd_close_instance\n}\nEOF\n```\n\nEnable and start the service:\n\n```sh\nchmod +x /etc/init.d/mediamtx\n/etc/init.d/mediamtx enable\n/etc/init.d/mediamtx start\n```\n\nRead the server logs:\n\n```sh\nlogread\n```\n\n#### Windows\n\nDownload the [WinSW v2 executable](https://github.com/winsw/winsw/releases/download/v2.11.0/WinSW-x64.exe) and place it into the same folder of `mediamtx.exe`.\n\nIn the same folder, create a file named `WinSW-x64.xml` with this content:\n\n```xml\n<service>\n  <id>mediamtx</id>\n  <name>mediamtx</name>\n  <description></description>\n  <executable>%BASE%/mediamtx.exe</executable>\n</service>\n```\n\nOpen a terminal, navigate to the folder and run:\n\n```\nWinSW-x64 install\n```\n\nThe server is now installed as a system service and will start at boot time.\n\n### Hooks\n\nThe server allows to specify commands that are executed when a certain event happens, allowing the propagation of events to external software.\n\n`runOnConnect` allows to run a command when a client connects to the server:\n\n```yml\n# Command to run when a client connects to the server.\n# This is terminated with SIGINT when a client disconnects from the server.\n# The following environment variables are available:\n# * MTX_CONN_TYPE: connection type\n# * MTX_CONN_ID: connection ID\n# * RTSP_PORT: RTSP server port\nrunOnConnect: curl http://my-custom-server/webhook?conn_type=$MTX_CONN_TYPE&conn_id=$MTX_CONN_ID\n# Restart the command if it exits.\nrunOnConnectRestart: no\n```\n\n`runOnDisconnect` allows to run a command when a client disconnects from the server:\n\n```yml\n# Command to run when a client disconnects from the server.\n# Environment variables are the same of runOnConnect.\nrunOnDisconnect: curl http://my-custom-server/webhook?conn_type=$MTX_CONN_TYPE&conn_id=$MTX_CONN_ID\n```\n\n`runOnInit` allows to run a command when a path is initialized. This can be used to publish a stream when the server is launched:\n\n```yml\npaths:\n  mypath:\n    # Command to run when this path is initialized.\n    # This can be used to publish a stream when the server is launched.\n    # The following environment variables are available:\n    # * MTX_PATH: path name\n    # * RTSP_PORT: RTSP server port\n    # * G1, G2, ...: regular expression groups, if path name is\n    #   a regular expression.\n    runOnInit: ffmpeg -i my_file.mp4 -c copy -f rtsp rtsp://localhost:8554/mypath\n    # Restart the command if it exits.\n    runOnInitRestart: no\n```\n\n`runOnDemand` allows to run a command when a path is requested by a reader. This can be used to publish a stream on demand:\n\n```yml\npathDefaults:\n  # Command to run when this path is requested by a reader\n  # and no one is publishing to this path yet.\n  # This is terminated with SIGINT when there are no readers anymore.\n  # The following environment variables are available:\n  # * MTX_PATH: path name\n  # * MTX_QUERY: query parameters (passed by first reader)\n  # * RTSP_PORT: RTSP server port\n  # * G1, G2, ...: regular expression groups, if path name is\n  #   a regular expression.\n  runOnDemand: ffmpeg -i my_file.mp4 -c copy -f rtsp rtsp://localhost:8554/mypath\n  # Restart the command if it exits.\n  runOnDemandRestart: no\n```\n\n`runOnUnDemand` allows to run a command when there are no readers anymore:\n\n```yml\npathDefaults:\n  # Command to run when there are no readers anymore.\n  # Environment variables are the same of runOnDemand.\n  runOnUnDemand:\n```\n\n`runOnReady` allows to run a command when a stream is ready to be read:\n\n```yml\npathDefaults:\n  # Command to run when the stream is ready to be read, whenever it is\n  # published by a client or pulled from a server / camera.\n  # This is terminated with SIGINT when the stream is not ready anymore.\n  # The following environment variables are available:\n  # * MTX_PATH: path name\n  # * MTX_QUERY: query parameters (passed by publisher)\n  # * MTX_SOURCE_TYPE: source type\n  # * MTX_SOURCE_ID: source ID\n  # * RTSP_PORT: RTSP server port\n  # * G1, G2, ...: regular expression groups, if path name is\n  #   a regular expression.\n  runOnReady: curl http://my-custom-server/webhook?path=$MTX_PATH&source_type=$MTX_SOURCE_TYPE&source_id=$MTX_SOURCE_ID\n  # Restart the command if it exits.\n  runOnReadyRestart: no\n```\n\n`runOnNotReady` allows to run a command when a stream is not available anymore:\n\n```yml\npathDefaults:\n  # Command to run when the stream is not available anymore.\n  # Environment variables are the same of runOnReady.\n  runOnNotReady: curl http://my-custom-server/webhook?path=$MTX_PATH&source_type=$MTX_SOURCE_TYPE&source_id=$MTX_SOURCE_ID\n```\n\n`runOnRead` allows to run a command when a client starts reading:\n\n```yml\npathDefaults:\n  # Command to run when a client starts reading.\n  # This is terminated with SIGINT when a client stops reading.\n  # The following environment variables are available:\n  # * MTX_PATH: path name\n  # * MTX_QUERY: query parameters (passed by reader)\n  # * MTX_READER_TYPE: reader type\n  # * MTX_READER_ID: reader ID\n  # * RTSP_PORT: RTSP server port\n  # * G1, G2, ...: regular expression groups, if path name is\n  #   a regular expression.\n  runOnRead: curl http://my-custom-server/webhook?path=$MTX_PATH&reader_type=$MTX_READER_TYPE&reader_id=$MTX_READER_ID\n  # Restart the command if it exits.\n  runOnReadRestart: no\n```\n\n`runOnUnread` allows to run a command when a client stops reading:\n\n```yml\npathDefaults:\n  # Command to run when a client stops reading.\n  # Environment variables are the same of runOnRead.\n  runOnUnread: curl http://my-custom-server/webhook?path=$MTX_PATH&reader_type=$MTX_READER_TYPE&reader_id=$MTX_READER_ID\n```\n\n`runOnRecordSegmentCreate` allows to run a command when a recording segment is created:\n\n```yml\npathDefaults:\n  # Command to run when a recording segment is created.\n  # The following environment variables are available:\n  # * MTX_PATH: path name\n  # * MTX_SEGMENT_PATH: segment file path\n  # * RTSP_PORT: RTSP server port\n  # * G1, G2, ...: regular expression groups, if path name is\n  #   a regular expression.\n  runOnRecordSegmentCreate: curl http://my-custom-server/webhook?path=$MTX_PATH&segment_path=$MTX_SEGMENT_PATH\n```\n\n`runOnRecordSegmentComplete` allows to run a command when a recording segment is complete:\n\n```yml\npathDefaults:\n  # Command to run when a recording segment is complete.\n  # The following environment variables are available:\n  # * MTX_PATH: path name\n  # * MTX_SEGMENT_PATH: segment file path\n  # * MTX_SEGMENT_DURATION: segment duration\n  # * RTSP_PORT: RTSP server port\n  # * G1, G2, ...: regular expression groups, if path name is\n  #   a regular expression.\n  runOnRecordSegmentComplete: curl http://my-custom-server/webhook?path=$MTX_PATH&segment_path=$MTX_SEGMENT_PATH\n```\n\n### Control API\n\nThe server can be queried and controlled with an API, that can be enabled by setting the `api` parameter in the configuration:\n\n```yml\napi: yes\n```\n\nTo obtain a list of of active paths, run:\n\n```\ncurl http://127.0.0.1:9997/v3/paths/list\n```\n\nFull documentation of the Control API is available on the [dedicated site](https://bluenviron.github.io/mediamtx/).\n\nBe aware that by default the Control API is accessible by localhost only; to increase visibility or add authentication, check [Authentication](#authentication).\n\n### Metrics\n\nA metrics exporter, compatible with [Prometheus](https://prometheus.io/), can be enabled with the parameter `metrics: yes`; then the server can be queried for metrics with Prometheus or with a simple HTTP request:\n\n```\ncurl localhost:9998/metrics\n```\n\nObtaining:\n\n```ini\n# metrics of every path\npaths{name=\"[path_name]\",state=\"[state]\"} 1\npaths_bytes_received{name=\"[path_name]\",state=\"[state]\"} 1234\npaths_bytes_sent{name=\"[path_name]\",state=\"[state]\"} 1234\n\n# metrics of every HLS muxer\nhls_muxers{name=\"[name]\"} 1\nhls_muxers_bytes_sent{name=\"[name]\"} 187\n\n# metrics of every RTSP connection\nrtsp_conns{id=\"[id]\"} 1\nrtsp_conns_bytes_received{id=\"[id]\"} 1234\nrtsp_conns_bytes_sent{id=\"[id]\"} 187\n\n# metrics of every RTSP session\nrtsp_sessions{id=\"[id]\",state=\"idle\"} 1\nrtsp_sessions_bytes_received{id=\"[id]\",state=\"[state]\"} 1234\nrtsp_sessions_bytes_sent{id=\"[id]\",state=\"[state]\"} 187\nrtsp_sessions_rtp_packets_received{id=\"[id]\"} 123\nrtsp_sessions_rtp_packets_sent{id=\"[id]\"} 123\nrtsp_sessions_rtp_packets_lost{id=\"[id]\"} 123\nrtsp_sessions_rtp_packets_in_error{id=\"[id]\"} 123\nrtsp_sessions_rtp_packets_jitter{id=\"[id]\"} 123\nrtsp_sessions_rtcp_packets_received{id=\"[id]\"} 123\nrtsp_sessions_rtcp_packets_sent{id=\"[id]\"} 123\nrtsp_sessions_rtcp_packets_in_error{id=\"[id]\"} 123\n\n# metrics of every RTSPS connection\nrtsps_conns{id=\"[id]\"} 1\nrtsps_conns_bytes_received{id=\"[id]\"} 1234\nrtsps_conns_bytes_sent{id=\"[id]\"} 187\n\n# metrics of every RTSPS session\nrtsps_sessions{id=\"[id]\",state=\"[state]\"} 1\nrtsps_sessions_bytes_received{id=\"[id]\",state=\"[state]\"} 1234\nrtsps_sessions_bytes_sent{id=\"[id]\",state=\"[state]\"} 187\nrtsps_sessions_rtp_packets_received{id=\"[id]\"} 123\nrtsps_sessions_rtp_packets_sent{id=\"[id]\"} 123\nrtsps_sessions_rtp_packets_lost{id=\"[id]\"} 123\nrtsps_sessions_rtp_packets_in_error{id=\"[id]\"} 123\nrtsps_sessions_rtp_packets_jitter{id=\"[id]\"} 123\nrtsps_sessions_rtcp_packets_received{id=\"[id]\"} 123\nrtsps_sessions_rtcp_packets_sent{id=\"[id]\"} 123\nrtsps_sessions_rtcp_packets_in_error{id=\"[id]\"} 123\n\n# metrics of every RTMP connection\nrtmp_conns{id=\"[id]\",state=\"[state]\"} 1\nrtmp_conns_bytes_received{id=\"[id]\",state=\"[state]\"} 1234\nrtmp_conns_bytes_sent{id=\"[id]\",state=\"[state]\"} 187\n\n# metrics of every RTMPS connection\nrtmps_conns{id=\"[id]\",state=\"[state]\"} 1\nrtmps_conns_bytes_received{id=\"[id]\",state=\"[state]\"} 1234\nrtmps_conns_bytes_sent{id=\"[id]\",state=\"[state]\"} 187\n\n# metrics of every SRT connection\nsrt_conns{id=\"[id]\",state=\"[state]\"} 1\nsrt_conns_packets_sent{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_sent_unique{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_unique{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_send_loss{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_loss{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_retrans{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_retrans{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_sent_ack{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_ack{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_sent_nak{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_nak{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_sent_km{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_km{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_us_snd_duration{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_send_drop{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_drop{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_undecrypt{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_sent{id=\"[id]\",state=\"[state]\"} 187\nsrt_conns_bytes_received{id=\"[id]\",state=\"[state]\"} 1234\nsrt_conns_bytes_sent_unique{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_received_unique{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_received_loss{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_retrans{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_received_retrans{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_send_drop{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_received_drop{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_received_undecrypt{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_us_packets_send_period{id=\"[id]\",state=\"[state]\"} 123.123\nsrt_conns_packets_flow_window{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_flight_size{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_ms_rtt{id=\"[id]\",state=\"[state]\"} 123.123\nsrt_conns_mbps_send_rate{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_mbps_receive_rate{id=\"[id]\",state=\"[state]\"} 123.123\nsrt_conns_mbps_link_capacity{id=\"[id]\",state=\"[state]\"} 123.123\nsrt_conns_bytes_avail_send_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_avail_receive_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_mbps_max_bw{id=\"[id]\",state=\"[state]\"} -123\nsrt_conns_bytes_mss{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_send_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_send_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_ms_send_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_ms_send_tsb_pd_delay{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_receive_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_bytes_receive_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_ms_receive_buf{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_ms_receive_tsb_pd_delay{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_reorder_tolerance{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_avg_belated_time{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_send_loss_rate{id=\"[id]\",state=\"[state]\"} 123\nsrt_conns_packets_received_loss_rate{id=\"[id]\",state=\"[state]\"} 123\n\n# metrics of every WebRTC session\nwebrtc_sessions{id=\"[id]\",state=\"[state]\"} 1\nwebrtc_sessions_bytes_received{id=\"[id]\",state=\"[state]\"} 1234\nwebrtc_sessions_bytes_sent{id=\"[id]\",state=\"[state]\"} 187\n```\n\n### pprof\n\nA performance monitor, compatible with pprof, can be enabled with the parameter `pprof: yes`; then the server can be queried for metrics with pprof-compatible tools, like:\n\n```\ngo tool pprof -text http://localhost:9999/debug/pprof/goroutine\ngo tool pprof -text http://localhost:9999/debug/pprof/heap\ngo tool pprof -text http://localhost:9999/debug/pprof/profile?seconds=30\n```\n\n### SRT-specific features\n\n#### Standard stream ID syntax\n\nIn SRT, the stream ID is a string that is sent to the counterpart in order to advertise what action the caller is gonna do (publish or read), the path and the credentials. All these informations have to be encoded into a single string. This server supports two stream ID syntaxes, a custom one (that is the one reported in rest of the README) and also a [standard one](https://github.com/Haivision/srt/blob/master/docs/features/access-control.md) proposed by the authors of the protocol and sometimes enforced by some hardware. The standard syntax can be used in this way:\n\n```\nsrt://localhost:8890?streamid=#!::m=publish,r=mypath,u=myuser,s=mypass&pkt_size=1316\n```\n\nWhere:\n\n* key `m` contains the action (`publish` or `request`)\n* key `r` contains the path\n* key `u` contains the username\n* key `s` contains the password\n\n### WebRTC-specific features\n\n#### Authenticating with WHIP/WHEP\n\nWhen using WHIP or WHEP to establish a WebRTC connection, there are multiple ways to provide credentials.\n\nIf internal authentication or HTTP-based authentication is enabled, username and password can be passed through the `Authentication: Basic` header:\n\n```\nAuthentication: Basic [base64_encoded_credentials]\n```\n\nUsername and password can be also passed through the `Authentication: Bearer` header (since it's mandated by the specification):\n\n```\nAuthentication: Bearer username:password\n```\n\nIf JWT-based authentication is enabled, JWT can be passed through the `Authentication: Bearer` header:\n\n```\nAuthentication: Bearer [jwt]\n```\n\nThe JWT can also be passed through query parameters:\n\n```\nhttp://localhost:8889/mystream/whip?jwt=[jwt]\n```\n\n#### Solving WebRTC connectivity issues\n\nIf the server is hosted inside a container or is behind a NAT, additional configuration is required in order to allow the two WebRTC parts (server and client) to establish a connection.\n\nMake sure that `webrtcAdditionalHosts` includes your public IPs, that are IPs that can be used by clients to reach the server. If clients are on the same LAN as the server, then insert the LAN address of the server. If clients are coming from the internet, insert the public IP address of the server, or alternatively a DNS name, if you have one. You can insert multiple values to support all scenarios:\n\n```yml\nwebrtcAdditionalHosts: [192.168.x.x, 1.2.3.4, my-dns.example.org, ...]\n```\n\nIf there's a NAT / container between server and clients, it must be configured to route all incoming UDP packets on port 8189 to the server. If you're using Docker, this can be achieved with the flag:\n\n```sh\ndocker run --rm -it \\\n-p 8189:8189/udp\n....\nbluenviron/mediamtx\n```\n\nIf you still have problems, the UDP protocol might be blocked by a firewall. Enable the TCP protocol by enabling the local TCP listener:\n\n```yml\nwebrtcLocalTCPAddress: :8189\n```\n\nIf there's a NAT / container between server and clients, it must be configured to route all incoming TCP packets on port 8189 to the server.\n\nIf you still have problems, enable a STUN server:\n\n```yml\nwebrtcICEServers2:\n  - url: stun:stun.l.google.com:19302\n```\n\nWhen a STUN server is in use, connections can be established with the \"UDP hole punching\" method, that uses a random UDP port that does not need to be open.\n\nIf you really still have problems, you can force all WebRTC/ICE connections to pass through a TURN server, like [coturn](https://github.com/coturn/coturn), that must be configured externally. The server address and credentials must be set in the configuration file:\n\n```yml\nwebrtcICEServers2:\n- url: turn:host:port\n  username: user\n  password: password\n```\n\nWhere user and pass are the username and password of the server. Note that port is not optional.\n\nIf the server uses a secret-based authentication (for instance, coturn with the use-auth-secret option), it must be configured by using AUTH_SECRET as username, and the secret as password:\n\n```yml\nwebrtcICEServers2:\n- url: turn:host:port\n  username: AUTH_SECRET\n  password: secret\n```\n\nwhere secret is the secret of the TURN server. MediaMTX will generate a set of credentials by using the secret, and credentials will be sent to clients before the WebRTC/ICE connection is established.\n\nIn some cases you may want the browser to connect using TURN servers but have mediamtx not using TURN (for example if the TURN server is on the same network as mediamtx).  To allow this you can configure the TURN server to be client only:\n\n```yml\nwebrtcICEServers2:\n- url: turn:host:port\n  username: user\n  password: password\n  clientOnly: true\n```\n\n#### Supported browsers\n\nThe server can ingest and broadcast with WebRTC a wide variety of video and audio codecs (that are listed at the beginning of the README), but not all browsers can publish and read all codecs due to internal limitations that cannot be overcome by this or any other server.\n\nIn particular, reading and publishing H265 tracks with WebRTC was not possible until some time ago due to the lack of browser support. The situation recently improved and can be described as following:\n\n* Safari on iOS and macOS fully supports publishing and reading H265 tracks\n* Chrome on Windows supports publishing and reading H265 tracks when a GPU is present and when the browser is launched with the following flags:\n\n  ```\n  chrome.exe --enable-features=PlatformHEVCEncoderSupport,WebRtcAllowH265Receive,WebRtcAllowH265Send --force-fieldtrials=WebRTC-Video-H26xPacketBuffer/Enabled\n  ```\n\n  We are expecting these flags to become redundant in the future and the feature to be turned on by default.\n\nYou can check what codecs your browser can publish or read with WebRTC by [using this tool](https://jsfiddle.net/v24s8q1f/).\n\nIf you want to support most browsers, you can to re-encode the stream by using H264 and Opus codecs, for instance by using FFmpeg:\n\n```sh\nffmpeg -i rtsp://original-source \\\n-c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k \\\n-c:a libopus -b:a 64K -async 50 \\\n-f rtsp rtsp://localhost:8554/mystream\n```\n\n### HLS-specific features\n\n#### Supported browsers\n\nThe server can produce HLS streams with a variety of video and audio codecs (that are listed at the beginning of the README), but not all browsers can read all codecs due to internal limitations that cannot be overcome by this or any other server.\n\nYou can check what codecs your browser can read with HLS by [using this tool](https://jsfiddle.net/tjcyv5aw/).\n\nIf you want to support most browsers, you can to re-encode the stream by using H264 and AAC codecs, for instance by using FFmpeg:\n\n```sh\nffmpeg -i rtsp://original-source \\\n-c:v libx264 -pix_fmt yuv420p -preset ultrafast -b:v 600k \\\n-c:a aac -b:a 160k \\\n-f rtsp rtsp://localhost:8554/mystream\n```\n\n### RTSP-specific features\n\n#### Transport protocols\n\nThe RTSP protocol supports different underlying transport protocols, that are chosen by clients during the handshake with the server:\n\n* UDP: the most performant, but doesn't work when there's a NAT/firewall between server and clients. It doesn't support encryption.\n* UDP-multicast: allows to save bandwidth when clients are all in the same LAN, by sending packets once to a fixed multicast IP. It doesn't support encryption.\n* TCP: the most versatile, does support encryption.\n\nThe default transport protocol is UDP. To change the transport protocol, you have to tune the configuration of your client of choice.\n\n#### Encryption\n\nIncoming and outgoing RTSP streams can be encrypted with TLS, obtaining the RTSPS protocol. A TLS certificate is needed and can be generated with OpenSSL:\n\n```sh\nopenssl genrsa -out server.key 2048\nopenssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650\n```\n\nEdit `mediamtx.yml` and set the `rtspTransports`, `encryption`, `serverKey` and serverCert parameters:\n\n```yml\nrtspTransports: [tcp]\nrtspEncryption: optional\nrtspServerKey: server.key\nrtspServerCert: server.crt\n```\n\nStreams can be published and read with the `rtsps` scheme and the `8322` port:\n\n```\nrtsps://localhost:8322/mystream\n```\n\n#### Corrupted frames\n\nIn some scenarios, when publishing or reading from the server with RTSP, frames can get corrupted. This can be caused by multiple reasons:\n\n* the write queue of the server is too small and can't keep up with the stream throughput. A solution consists in increasing its size:\n\n  ```yml\n  writeQueueSize: 1024\n  ```\n\n* The stream throughput is too big and the stream can't be transmitted correctly with the UDP transport protocol. UDP is more performant, faster and more efficient than TCP, but doesn't have a retransmission mechanism, that is needed in case of streams that need a large bandwidth. A solution consists in switching to TCP:\n\n  ```yml\n  rtspTransports: [tcp]\n  ```\n\n  In case the source is a camera:\n\n  ```yml\n  paths:\n    test:\n      source: rtsp://..\n      rtspTransport: tcp\n   ```\n\n* The stream throughput is too big to be handled by the network between server and readers. Upgrade the network or decrease the stream bitrate by re-encoding it.\n\n### RTMP-specific features\n\n#### Encryption\n\nRTMP connections can be encrypted with TLS, obtaining the RTMPS protocol. A TLS certificate is needed and can be generated with OpenSSL:\n\n```yml\nopenssl genrsa -out server.key 2048\nopenssl req -new -x509 -sha256 -key server.key -out server.crt -days 3650\n```\n\nEdit mediamtx.yml and set the `rtmpEncryption`, `rtmpServerKey` and `rtmpServerCert` parameters:\n\n```yml\nrtmpEncryption: optional\nrtmpServerKey: server.key\nrtmpServerCert: server.crt\n```\n\nStreams can be published and read with the rtmps scheme and the 1937 port:\n\n```\nrtmps://localhost:1937/...\n```\n\nBe aware that RTMPS is currently unsupported by all major players. However, you can use a proxy like [stunnel](https://www.stunnel.org) or [nginx](https://nginx.org/) or a dedicated _MediaMTX_ instance to decrypt streams before reading them.\n\n## Compile from source\n\n### Standard\n\nInstall git and Go &ge; 1.23. Clone the repository, enter into the folder and start the building process:\n\n```sh\ngit clone https://github.com/bluenviron/mediamtx\ncd mediamtx\ngo generate ./...\nCGO_ENABLED=0 go build .\n```\n\nThe command will produce the `mediamtx` binary.\n\n### OpenWrt\n\nThe compilation procedure is the same as the standard one. On the OpenWrt device, install git and Go:\n\n```sh\nopkg update\nopkg install golang git git-http\n```\n\nClone the repository, enter into the folder and start the building process:\n\n```sh\ngit clone https://github.com/bluenviron/mediamtx\ncd mediamtx\ngo generate ./...\nCGO_ENABLED=0 go build .\n```\n\nThe command will produce the `mediamtx` binary.\n\nIf the OpenWrt device doesn't have enough resources to compile, you can [cross compile](#cross-compile) from another machine.\n\n### Custom libcamera\n\nIf you need to use a custom or external libcamera when interacting with the Raspberry Pi Camera, you have to compile [mediamtx-rpicamera](https://github.com/bluenviron/mediamtx-rpicamera) before compiling the server. Instructions are present in the `mediamtx-rpicamera` repository.\n\n### Cross compile\n\nCross compilation allows to build an executable for a target machine from another machine with different operating system or architecture. This is useful in case the target machine doesn't have enough resources for compilation or if you don't want to install the compilation dependencies on it.\n\nOn the machine you want to use to compile, install git and Go &ge; 1.23. Clone the repository, enter into the folder and start the building process:\n\n```sh\ngit clone https://github.com/bluenviron/mediamtx\ncd mediamtx\ngo generate ./...\nCGO_ENABLED=0 GOOS=my_os GOARCH=my_arch go build .\n```\n\nReplace `my_os` and `my_arch` with the operating system and architecture of your target machine. A list of all supported combinations can be obtained with:\n\n```sh\ngo tool dist list\n```\n\nFor instance:\n\n```sh\nCGO_ENABLED=0 GOOS=linux GOARCH=arm64 go build .\n```\n\nIn case of the `arm` architecture, there's an additional flag available, `GOARM`, that allows to set the ARM version:\n\n```sh\nCGO_ENABLED=0 GOOS=linux GOARCH=arm64 GOARM=7 go build .\n```\n\nIn case of the `mips` architecture, there's an additional flag available, `GOMIPS`, that allows to set additional parameters:\n\n```sh\nCGO_ENABLED=0 GOOS=linux GOARCH=mips GOMIPS=softfloat go build .\n```\n\nThe command will produce the `mediamtx` binary.\n\n### Compile for all supported platforms\n\nInstall Docker and launch:\n\n```sh\nmake binaries\n```\n\nThe command will produce tarballs in folder `binaries/`.\n\n## License\n\nAll the code in this repository is released under the [MIT License](LICENSE). Compiled binaries make use of some third-party dependencies:\n\n* hls.js, released under the [Apache License 2.0](https://github.com/video-dev/hls.js/blob/master/LICENSE)\n* all the dependencies listed into the [go.mod file](go.mod), which are all released under either the MIT license, BSD-3-Clause license or Apache License 2.0\n\n## Specifications\n\n|name|area|\n|----|----|\n|[RTSP / RTP / RTCP specifications](https://github.com/bluenviron/gortsplib#specifications)|RTSP|\n|[HLS specifications](https://github.com/bluenviron/gohlslib#specifications)|HLS|\n|[Action Message Format - AMF 0](https://veovera.org/docs/legacy/amf0-file-format-spec.pdf)|RTMP|\n|[FLV](https://veovera.org/docs/legacy/video-file-format-v10-1-spec.pdf)|RTMP|\n|[RTMP](https://veovera.org/docs/legacy/rtmp-v1-0-spec.pdf)|RTMP|\n|[Enhanced RTMP v2](https://veovera.org/docs/enhanced/enhanced-rtmp-v2.pdf)|RTMP|\n|[WebRTC: Real-Time Communication in Browsers](https://www.w3.org/TR/webrtc/)|WebRTC|\n|[RFC8835, Transports for WebRTC](https://datatracker.ietf.org/doc/html/rfc8835)|WebRTC|\n|[RFC7742, WebRTC Video Processing and Codec Requirements](https://datatracker.ietf.org/doc/html/rfc7742)|WebRTC|\n|[RFC7847, WebRTC Audio Codec and Processing Requirements](https://datatracker.ietf.org/doc/html/rfc7874)|WebRTC|\n|[RFC7875, Additional WebRTC Audio Codecs for Interoperability](https://datatracker.ietf.org/doc/html/rfc7875)|WebRTC|\n|[H.265 Profile for WebRTC](https://datatracker.ietf.org/doc/draft-ietf-avtcore-hevc-webrtc/)|WebRTC|\n|[WebRTC HTTP Ingestion Protocol (WHIP)](https://datatracker.ietf.org/doc/draft-ietf-wish-whip/)|WebRTC|\n|[WebRTC HTTP Egress Protocol (WHEP)](https://datatracker.ietf.org/doc/draft-murillo-whep/)|WebRTC|\n|[The SRT Protocol](https://haivision.github.io/srt-rfc/draft-sharabayko-srt.html)|SRT|\n|[Codec specifications](https://github.com/bluenviron/mediacommon#specifications)|codecs|\n|[Golang project layout](https://github.com/golang-standards/project-layout)|project layout|\n\n## Related projects\n\n* [gortsplib (RTSP library used internally)](https://github.com/bluenviron/gortsplib)\n* [gohlslib (HLS library used internally)](https://github.com/bluenviron/gohlslib)\n* [mediacommon (codecs and formats library used internally)](https://github.com/bluenviron/mediacommon)\n* [mediamtx-rpicamera (Raspberry Pi Camera component)](https://github.com/bluenviron/mediamtx-rpicamera)\n* [datarhei/gosrt (SRT library used internally)](https://github.com/datarhei/gosrt)\n* [pion/webrtc (WebRTC library used internally)](https://github.com/pion/webrtc)\n* [pion/sdp (SDP library used internally)](https://github.com/pion/sdp)\n* [pion/rtp (RTP library used internally)](https://github.com/pion/rtp)\n* [pion/rtcp (RTCP library used internally)](https://github.com/pion/rtcp)\n* [go-astits (MPEG-TS library used internally)](https://github.com/asticode/go-astits)\n* [go-mp4 (MP4 library used internally)](https://github.com/abema/go-mp4)\n* [hls.js (browser-side HLS library used internally)](https://github.com/video-dev/hls.js)\n",
        "releases": [
            {
                "name": "v1.11.1",
                "date": "2025-01-13T22:27:24Z"
            },
            {
                "name": "v1.11.0",
                "date": "2025-01-03T13:06:34Z"
            },
            {
                "name": "v1.10.0",
                "date": "2024-12-03T09:17:20Z"
            },
            {
                "name": "v1.9.3",
                "date": "2024-10-20T14:44:58Z"
            },
            {
                "name": "v1.9.2",
                "date": "2024-10-07T19:16:55Z"
            },
            {
                "name": "v1.9.1",
                "date": "2024-09-15T21:39:47Z"
            },
            {
                "name": "v1.9.0",
                "date": "2024-08-26T15:59:40Z"
            },
            {
                "name": "v1.8.5",
                "date": "2024-08-04T12:27:30Z"
            },
            {
                "name": "v1.8.4",
                "date": "2024-07-07T19:41:50Z"
            },
            {
                "name": "v1.8.3",
                "date": "2024-06-12T15:45:36Z"
            },
            {
                "name": "v1.8.2",
                "date": "2024-05-19T12:53:09Z"
            },
            {
                "name": "v1.8.1",
                "date": "2024-05-05T17:13:15Z"
            },
            {
                "name": "v1.8.0",
                "date": "2024-04-21T15:28:25Z"
            },
            {
                "name": "v1.7.0",
                "date": "2024-04-14T17:40:22Z"
            },
            {
                "name": "v1.6.0",
                "date": "2024-03-04T13:41:16Z"
            },
            {
                "name": "v1.5.1",
                "date": "2024-02-04T23:08:54Z"
            },
            {
                "name": "v1.5.0",
                "date": "2024-01-23T20:07:56Z"
            },
            {
                "name": "v1.4.2",
                "date": "2024-01-07T16:58:00Z"
            },
            {
                "name": "v1.4.1",
                "date": "2023-12-24T11:20:30Z"
            },
            {
                "name": "v1.4.0",
                "date": "2023-12-10T20:30:39Z"
            },
            {
                "name": "v1.3.1",
                "date": "2023-11-26T19:31:19Z"
            },
            {
                "name": "v1.3.0",
                "date": "2023-11-12T23:22:16Z"
            },
            {
                "name": "v1.2.1",
                "date": "2023-10-28T13:15:46Z"
            },
            {
                "name": "v1.2.0",
                "date": "2023-10-14T21:05:56Z"
            },
            {
                "name": "v1.1.1",
                "date": "2023-09-24T16:13:45Z"
            },
            {
                "name": "v1.1.0",
                "date": "2023-09-16T21:32:29Z"
            },
            {
                "name": "v1.0.3",
                "date": "2023-09-01T21:25:01Z"
            },
            {
                "name": "v1.0.2",
                "date": "2023-09-01T18:20:05Z"
            },
            {
                "name": "v1.0.1",
                "date": "2023-08-30T11:20:46Z"
            },
            {
                "name": "v1.0.0",
                "date": "2023-08-08T12:31:53Z"
            },
            {
                "name": "v0.23.8",
                "date": "2023-07-19T18:38:18Z"
            },
            {
                "name": "v0.23.7",
                "date": "2023-07-01T10:30:47Z"
            },
            {
                "name": "v0.23.6",
                "date": "2023-06-21T14:31:59Z"
            },
            {
                "name": "v0.23.5",
                "date": "2023-06-07T10:48:59Z"
            },
            {
                "name": "v0.23.4",
                "date": "2023-06-02T17:15:36Z"
            },
            {
                "name": "v0.23.3",
                "date": "2023-05-24T15:17:49Z"
            },
            {
                "name": "v0.23.2",
                "date": "2023-05-20T09:22:14Z"
            },
            {
                "name": "v0.23.1",
                "date": "2023-05-20T08:46:30Z"
            },
            {
                "name": "v0.23.0",
                "date": "2023-05-16T18:24:29Z"
            },
            {
                "name": "v0.22.2",
                "date": "2023-04-15T11:55:35Z"
            },
            {
                "name": "v0.22.1",
                "date": "2023-04-13T18:34:45Z"
            },
            {
                "name": "v0.22.0",
                "date": "2023-04-01T18:18:14Z"
            },
            {
                "name": "v0.21.6",
                "date": "2023-03-12T12:34:11Z"
            },
            {
                "name": "v0.21.5",
                "date": "2023-02-21T22:55:38Z"
            },
            {
                "name": "v0.21.4",
                "date": "2023-02-14T16:46:36Z"
            },
            {
                "name": "v0.21.3",
                "date": "2023-05-20T08:44:20Z"
            },
            {
                "name": "v0.21.2",
                "date": "2023-01-26T09:54:34Z"
            },
            {
                "name": "v0.21.1",
                "date": "2023-01-08T21:13:01Z"
            },
            {
                "name": "v0.21.0",
                "date": "2022-12-19T23:02:15Z"
            },
            {
                "name": "v0.20.4",
                "date": "2022-12-12T13:07:27Z"
            },
            {
                "name": "v0.20.3",
                "date": "2022-12-08T23:20:48Z"
            },
            {
                "name": "v0.20.2",
                "date": "2022-11-03T20:54:15Z"
            },
            {
                "name": "v0.20.1",
                "date": "2022-10-25T12:26:43Z"
            },
            {
                "name": "v0.20.0",
                "date": "2022-08-16T16:54:36Z"
            },
            {
                "name": "v0.19.3",
                "date": "2022-07-24T15:27:03Z"
            },
            {
                "name": "v0.19.2",
                "date": "2022-06-24T18:41:59Z"
            },
            {
                "name": "v0.19.1",
                "date": "2022-06-07T19:31:32Z"
            },
            {
                "name": "v0.19.0",
                "date": "2022-05-31T17:30:42Z"
            },
            {
                "name": "v0.18.5",
                "date": "2022-05-28T11:58:11Z"
            },
            {
                "name": "v0.18.4",
                "date": "2022-05-19T09:37:11Z"
            },
            {
                "name": "v0.18.3",
                "date": "2022-05-10T15:39:41Z"
            },
            {
                "name": "v0.18.2",
                "date": "2022-05-02T17:32:51Z"
            },
            {
                "name": "v0.18.1",
                "date": "2022-04-24T09:40:56Z"
            },
            {
                "name": "v0.18.0",
                "date": "2022-04-10T16:00:04Z"
            },
            {
                "name": "v0.17.17",
                "date": "2022-02-15T08:58:00Z"
            },
            {
                "name": "v0.17.16",
                "date": "2022-02-01T18:30:51Z"
            },
            {
                "name": "v0.17.15",
                "date": "2022-01-31T09:18:46Z"
            },
            {
                "name": "v0.17.14",
                "date": "2022-01-19T22:38:11Z"
            },
            {
                "name": "v0.17.13",
                "date": "2021-12-24T10:03:39Z"
            },
            {
                "name": "v0.17.12",
                "date": "2021-12-22T22:43:57Z"
            },
            {
                "name": "v0.17.11",
                "date": "2021-12-08T17:30:49Z"
            },
            {
                "name": "v0.17.10",
                "date": "2021-11-26T14:57:49Z"
            },
            {
                "name": "v0.17.9",
                "date": "2021-11-16T20:42:50Z"
            },
            {
                "name": "v0.17.8",
                "date": "2021-11-06T12:41:43Z"
            },
            {
                "name": "v0.17.7",
                "date": "2021-10-27T18:23:01Z"
            },
            {
                "name": "v0.17.6",
                "date": "2021-10-06T11:18:52Z"
            },
            {
                "name": "v0.17.5",
                "date": "2021-10-04T07:03:15Z"
            },
            {
                "name": "v0.17.4",
                "date": "2021-10-03T14:22:14Z"
            },
            {
                "name": "v0.17.3",
                "date": "2021-09-07T10:18:26Z"
            },
            {
                "name": "v0.17.2",
                "date": "2021-08-14T15:42:14Z"
            },
            {
                "name": "v0.17.1",
                "date": "2021-08-12T10:05:42Z"
            },
            {
                "name": "v0.17.0",
                "date": "2021-08-07T17:24:09Z"
            },
            {
                "name": "v0.16.4",
                "date": "2021-07-04T15:35:11Z"
            },
            {
                "name": "v0.16.3",
                "date": "2021-06-22T21:06:47Z"
            },
            {
                "name": "v0.16.2",
                "date": "2021-05-30T12:12:12Z"
            },
            {
                "name": "v0.16.1",
                "date": "2021-05-21T11:10:44Z"
            },
            {
                "name": "v0.16.0",
                "date": "2021-05-09T16:07:18Z"
            },
            {
                "name": "v0.15.5",
                "date": "2021-04-17T18:00:47Z"
            },
            {
                "name": "v0.15.4",
                "date": "2021-04-06T06:47:09Z"
            },
            {
                "name": "v0.15.3",
                "date": "2021-04-03T07:00:55Z"
            },
            {
                "name": "v0.15.2",
                "date": "2021-03-28T08:05:58Z"
            },
            {
                "name": "v0.15.1",
                "date": "2021-03-23T21:02:52Z"
            },
            {
                "name": "v0.15.0",
                "date": "2021-03-10T19:55:27Z"
            },
            {
                "name": "v0.14.2",
                "date": "2021-02-24T09:08:50Z"
            },
            {
                "name": "v0.14.1",
                "date": "2021-02-09T22:08:59Z"
            },
            {
                "name": "v0.14.0",
                "date": "2021-01-31T22:48:22Z"
            },
            {
                "name": "v0.13.3",
                "date": "2021-01-26T09:49:44Z"
            },
            {
                "name": "v0.13.2",
                "date": "2021-01-10T13:59:45Z"
            },
            {
                "name": "v0.13.1",
                "date": "2020-12-19T19:08:58Z"
            },
            {
                "name": "v0.13.0",
                "date": "2020-12-16T11:47:48Z"
            },
            {
                "name": "v0.12.2",
                "date": "2020-11-25T22:02:59Z"
            },
            {
                "name": "v0.12.1",
                "date": "2020-11-11T10:18:44Z"
            },
            {
                "name": "v0.12.0",
                "date": "2020-11-02T12:04:15Z"
            },
            {
                "name": "v0.11.0",
                "date": "2020-10-28T21:47:14Z"
            },
            {
                "name": "v0.10.1",
                "date": "2020-10-17T19:56:00Z"
            },
            {
                "name": "v0.10.0",
                "date": "2020-10-06T18:04:11Z"
            },
            {
                "name": "",
                "date": "2020-09-22T06:49:31Z"
            },
            {
                "name": "",
                "date": "2020-09-19T15:30:11Z"
            },
            {
                "name": "",
                "date": "2020-09-06T15:31:01Z"
            },
            {
                "name": "",
                "date": "2020-08-31T14:38:18Z"
            },
            {
                "name": "",
                "date": "2020-08-17T17:08:08Z"
            },
            {
                "name": "v0.9.10",
                "date": "2020-08-05T13:14:05Z"
            },
            {
                "name": "",
                "date": "2020-08-05T10:24:22Z"
            },
            {
                "name": "",
                "date": "2020-08-03T16:02:01Z"
            },
            {
                "name": "",
                "date": "2020-07-31T16:20:28Z"
            },
            {
                "name": "",
                "date": "2020-07-30T17:29:49Z"
            },
            {
                "name": "",
                "date": "2020-07-30T11:51:43Z"
            },
            {
                "name": null,
                "date": "2020-07-20T08:30:49Z"
            },
            {
                "name": "",
                "date": "2020-07-19T09:58:59Z"
            },
            {
                "name": "",
                "date": "2020-07-18T16:31:15Z"
            },
            {
                "name": "",
                "date": "2020-07-13T16:01:56Z"
            },
            {
                "name": "",
                "date": "2020-07-13T15:34:03Z"
            },
            {
                "name": "",
                "date": "2020-07-13T10:30:09Z"
            },
            {
                "name": "",
                "date": "2020-07-13T09:58:31Z"
            },
            {
                "name": "",
                "date": "2020-07-12T15:31:21Z"
            },
            {
                "name": "",
                "date": "2020-07-12T11:29:04Z"
            },
            {
                "name": "",
                "date": "2020-07-10T10:29:52Z"
            },
            {
                "name": null,
                "date": "2020-07-09T21:21:08Z"
            },
            {
                "name": null,
                "date": "2020-07-04T16:43:12Z"
            },
            {
                "name": null,
                "date": "2020-07-04T16:20:33Z"
            },
            {
                "name": null,
                "date": "2020-07-04T07:20:34Z"
            },
            {
                "name": null,
                "date": "2020-07-02T10:04:44Z"
            },
            {
                "name": "v0.8.0",
                "date": "2020-06-30T13:22:33Z"
            },
            {
                "name": null,
                "date": "2020-06-28T15:49:37Z"
            },
            {
                "name": "v0.7.0",
                "date": "2020-06-27T19:28:51Z"
            },
            {
                "name": null,
                "date": "2020-06-21T19:13:02Z"
            },
            {
                "name": null,
                "date": "2020-06-21T13:40:12Z"
            },
            {
                "name": "v0.6.4",
                "date": "2020-06-14T19:51:07Z"
            },
            {
                "name": "v0.6.3",
                "date": "2020-06-14T15:50:36Z"
            },
            {
                "name": "v0.6.2",
                "date": "2020-05-21T20:07:45Z"
            },
            {
                "name": "",
                "date": "2020-05-17T14:53:37Z"
            },
            {
                "name": "",
                "date": "2020-05-10T21:00:28Z"
            },
            {
                "name": "v0.5.5",
                "date": "2020-05-03T21:28:55Z"
            },
            {
                "name": "v0.5.4",
                "date": "2020-05-03T19:44:35Z"
            },
            {
                "name": "v0.5.3",
                "date": "2020-04-16T07:48:12Z"
            },
            {
                "name": "",
                "date": "2020-03-13T13:22:02Z"
            },
            {
                "name": null,
                "date": "2020-02-23T10:35:30Z"
            },
            {
                "name": "",
                "date": "2020-02-16T15:07:28Z"
            },
            {
                "name": null,
                "date": "2020-01-26T17:10:57Z"
            },
            {
                "name": null,
                "date": "2020-01-26T11:43:18Z"
            },
            {
                "name": null,
                "date": "2020-01-21T11:14:08Z"
            },
            {
                "name": null,
                "date": "2020-01-21T08:31:20Z"
            },
            {
                "name": null,
                "date": "2020-01-20T21:45:39Z"
            },
            {
                "name": null,
                "date": "2020-01-15T21:51:01Z"
            },
            {
                "name": null,
                "date": "2020-01-14T20:35:52Z"
            },
            {
                "name": null,
                "date": "2020-01-03T22:23:49Z"
            },
            {
                "name": null,
                "date": "2020-01-01T17:03:24Z"
            },
            {
                "name": null,
                "date": "2019-12-31T13:57:48Z"
            },
            {
                "name": null,
                "date": "2019-12-29T11:48:40Z"
            },
            {
                "name": null,
                "date": "2019-12-29T10:53:08Z"
            },
            {
                "name": null,
                "date": "2019-12-29T02:05:28Z"
            },
            {
                "name": null,
                "date": "2019-12-29T00:54:46Z"
            },
            {
                "name": null,
                "date": "2019-12-29T00:07:22Z"
            },
            {
                "name": null,
                "date": "2019-12-28T21:30:02Z"
            }
        ]
    }
}