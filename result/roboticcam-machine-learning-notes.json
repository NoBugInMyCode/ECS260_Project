{
    "https://api.github.com/repos/roboticcam/machine-learning-notes": {
        "forks": 1722,
        "watchers": 8494,
        "stars": 8494,
        "languages": {
            "Jupyter Notebook": 397574
        },
        "commits": [
            "2024-09-29T07:12:30Z",
            "2023-06-05T09:12:08Z",
            "2023-06-05T09:11:31Z",
            "2023-03-24T06:03:40Z",
            "2023-03-24T06:03:10Z",
            "2023-03-24T06:01:30Z",
            "2023-03-02T05:14:07Z",
            "2023-01-08T17:58:54Z",
            "2023-01-08T17:56:13Z",
            "2023-01-08T17:55:04Z",
            "2023-01-08T17:54:54Z",
            "2023-01-08T17:53:20Z",
            "2023-01-08T17:52:43Z",
            "2023-01-08T17:52:05Z",
            "2023-01-08T17:50:31Z",
            "2022-11-28T16:12:36Z",
            "2022-11-28T16:10:59Z",
            "2022-11-25T15:36:11Z",
            "2022-11-25T15:33:37Z",
            "2022-11-25T15:32:46Z",
            "2022-11-25T15:31:01Z",
            "2022-11-25T15:30:17Z",
            "2022-11-25T15:15:52Z",
            "2022-11-25T15:15:05Z",
            "2022-11-25T15:13:18Z",
            "2022-11-25T15:06:42Z",
            "2022-11-25T15:06:21Z",
            "2022-11-25T15:04:03Z",
            "2022-11-25T14:59:08Z",
            "2022-11-14T17:53:45Z"
        ],
        "creation_date": "2018-02-15T15:42:33Z",
        "contributors": 1,
        "topics": [],
        "subscribers": 388,
        "readme": "# Live Machine Learning Class:\n\n### \u4e2d\u6587\u673a\u5668\u5b66\u4e60\u7814\u7a76\u7ebf\u4e0a\u8bfe\n2022\u5e74\u6211\u575a\u6301\u6bcf\u5468\u65e5\u665a\u4e0a8:30\u76f4\u64ad\u673a\u5668\u5b66\u4e60\u7814\u7a76\u8bfe\u7a0b\u7cfb\u5217 ([\u5fae\u4fe1\u4e8c\u7ef4\u7801\u5728\u8fd9\u4e2a\u94fe\u63a5](https://github.com/roboticcam/machine-learning-notes/blob/master/files/class_qrcode.jpg))- From 2022, I hold regular 8:30pm Sunday Night live (SNL) broadcast on Machine Learning theory.\n\n### English version\nFrom April 2022, I started a machine learning research seminar series every 2-3 weeks in English via Zoom. It's at 7pm Hong Kong Time. I will continue to explain machine learning using an intermediate level mathematics. The current topic is: \"Gradient Descend Research\". You need a solid understanding of linear algebra, calculus, probability and statistics.\nYou can register via meetup https://www.meetup.com/machine-learning-hong-kong/ \n(Back in Australia, I also conducted research training to all machine learning PhD students at Australian universities, with over 100 students participating via Zoom.)\n\n# Learning Theory Classes\n\n* ### [Class 1: Introduction](https://github.com/roboticcam/machine-learning-notes/blob/master/files/1.introduction.pdf) ###\n* ### [Class 2: Concentration Inequality](https://github.com/roboticcam/machine-learning-notes/blob/master/files/2.concentration_inequality.pdf) ###\n* ### [Class 3: Rademarcher Complexity](https://github.com/roboticcam/machine-learning-notes/blob/master/files/3.rademarcher.pdf) ###\n* ### [Class 4: Neural Tangent Kernel](https://github.com/roboticcam/machine-learning-notes/blob/master/files/4.ntk.pdf) ###\n* ### [Class 5: PAC Bayes](https://github.com/roboticcam/machine-learning-notes/blob/master/files/5.pac_bayes.pdf) ###\n* ### [Class 6: Johnson\u2013Lindenstrauss lemma](https://github.com/roboticcam/machine-learning-notes/blob/master/files/j_l_lemma.pdf) ###\n\n\n# Video Tutorial to these notes \u89c6\u9891\u8d44\u6599\n\n* I recorded about 20% of these notes in videos in 2015 in Mandarin (all my notes and writings are in English) You may find them on [Youtube](https://www.youtube.com/channel/UConITmGn5PFr0hxTI2tWD4Q) and [bilibili](https://space.bilibili.com/327617676) and [Youku](http://i.youku.com/i/UMzIzNDgxNTg5Ng)       \n\n\u6211\u57282015\u5e74\u7528\u4e2d\u6587\u5f55\u5236\u4e86\u8fd9\u4e9b\u8bfe\u4ef6\u4e2d\u7ea610\uff05\u7684\u5185\u5bb9 (\u6211\u76ee\u524d\u7684\u8bfe\u4ef6\u90fd\u662f\u82f1\u6587\u7684)\u5927\u5bb6\u53ef\u4ee5\u5728[Youtube](https://www.youtube.com/channel/UConITmGn5PFr0hxTI2tWD4Q) [\u54d4\u54e9\u54d4\u54e9](https://space.bilibili.com/327617676) and [\u4f18\u9177](http://i.youku.com/i/UMzIzNDgxNTg5Ng) \u4e0b\u8f7d\n\n\n# Course on Foundational Mathematics in Machine Learning \u673a\u5668\u5b66\u4e60\u57fa\u7840\u6570\u5b66\u8bfe\u7a0b\n\n* ### [Class 1: Model Evaluation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/foundation_model_evaluation.pdf) ###\ncommon concepts and techniques for classification model evaluation, including bootstrapping sampling, confusion matrices, receiver operating characteristic (ROC) curves. \u5206\u7c7b\u6a21\u578b\u8bc4\u4f30\u7684\u5e38\u89c1\u6982\u5ff5\u548c\u6280\u672f\uff0c\u5305\u62ec\u81ea\u4e3e\u62bd\u6837\u3001\u6df7\u6dc6\u77e9\u9635\u3001\u63a5\u6536\u5668\u64cd\u4f5c\u7279\u5f81 (ROC) \u66f2\u7ebf\n\n* ### [Class 2: Decision Tree](https://github.com/roboticcam/machine-learning-notes/blob/master/files/foundation_decision_tree.pdf) ###\nIn addition to all the basics of decision trees, I've added a $\\chi^2$ test section to this note. \u9664\u4e86\u51b3\u7b56\u6811\u7684\u6240\u6709\u57fa\u7840\u77e5\u8bc6\u4e4b\u5916\uff0c\u6211\u8fd8\u5728\u6b64\u8bf4\u660e\u4e2d\u6dfb\u52a0\u4e86 $\\chi^2$ \u6d4b\u8bd5\u90e8\u5206\u3002\n\n* ### [Class 3: Simple Bayes](https://github.com/roboticcam/machine-learning-notes/blob/master/files/foundation_simple_bayes.pdf) ###\nThis note is intended to provide an intuitive explanation of the basic concepts of probability, Bayes' theorem, graphical models of probability. \u672c\u8bfe\u4ef6\u65e8\u5728\u5bf9\u6982\u7387\u7684\u57fa\u672c\u6982\u5ff5\u3001\u8d1d\u53f6\u65af\u5b9a\u7406\u3001\u6982\u7387\u7684\u56fe\u5f62\u6a21\u578b\u63d0\u4f9b\u76f4\u89c2\u7684\u89e3\u91ca\n\n* ### [Class 4: Regression](https://github.com/roboticcam/machine-learning-notes/blob/master/files/foundation_regression.pdf) ###\nThis note is to explain the century-old, simplest regression models: linear and polynomial regression, and some techniques for evaluating regression performance, especially the coefficient of determination (CoD) method. \u8fd9\u7bc7\u7b14\u8bb0\u662f\u4e3a\u4e86\u89e3\u91ca\u6700\u7b80\u5355\u7684\u56de\u5f52\u6a21\u578b\uff1a\u7ebf\u6027\u56de\u5f52\u548c\u591a\u9879\u5f0f\u56de\u5f52\uff0c\u4ee5\u53ca\u4e00\u4e9b\u8bc4\u4f30\u56de\u5f52\u6027\u80fd\u7684\u6280\u672f\uff0c\u5c24\u5176\u662f\u786e\u5b9a\u7cfb\u6570 (CoD) \u65b9\u6cd5\n\n* ### [Class 5: Neural Network](https://github.com/roboticcam/machine-learning-notes/blob/master/files/foundation_neural_network.pdf) ###\nFirst I show three different last output layer models: logistic, multinomial, and linear regression. Then I show the concept of gradient descent. The main part is to show a basic fully connected neural network and finally a convolutional neural network. \u9996\u5148\uff0c\u6211\u5c55\u793a\u4e86\u4e09\u4e2a\u4e0d\u540c\u7684\u6700\u540e\u8f93\u51fa\u5c42\u6a21\u578b\uff1a\u903b\u8f91\u56de\u5f52\u3001\u591a\u9879\u5f0f\u548c\u7ebf\u6027\u56de\u5f52\u3002\u7136\u540e\u6211\u5c55\u793a\u4e86\u68af\u5ea6\u4e0b\u964d\u7684\u6982\u5ff5\u3002\u4e3b\u8981\u90e8\u5206\u662f\u5c55\u793a\u4e00\u4e2a\u57fa\u672c\u7684\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\uff0c\u6700\u540e\u662f\u4e00\u4e2a\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u3002\n\n* ### [Class 6: Unsupervised Learning](https://github.com/roboticcam/machine-learning-notes/blob/master/files/foundation_unsupervised.pdf) ###\nThis note describes some common topics in unsupervised learning. From the most obvious methods like clustering, to topic modeling (Latent Diricher Allocation) and traditional word embeddings like the word2vec algorithm. \u672c\u8bfe\u4ef6\u63cf\u8ff0\u4e86\u65e0\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u4e00\u4e9b\u5e38\u89c1\u4e3b\u9898\u3002\u4ece\u6700\u660e\u663e\u7684\u65b9\u6cd5\uff08\u5982\u805a\u7c7b\uff09\u5230\u4e3b\u9898\u5efa\u6a21\u548c\u4f20\u7edf\u7684\u8bcd\u5d4c\u5165\uff08\u5982 word2vec \u7b97\u6cd5\uff09\u3002\n\n\n# Course on Intemediate Mathematics in Machine Learning \u673a\u5668\u5b66\u4e60\u4e2d\u7ea7\u6570\u5b66\u8bfe\u7a0b\n\nI'm currently updating/validating and correcting notes I've written over the past decade and incorporating them into an introduction/intermediate/advanced machine learning course. I will gradually delete all my previous Beamer notes and replace them with technical report notes. \u6211\u76ee\u524d\u6b63\u5728\u66f4\u65b0/\u9a8c\u8bc1\u548c\u66f4\u6b63\u6211\u5728\u8fc7\u53bb\u5341\u5e74\u4e2d\u5199\u7684\u7b14\u8bb0\uff0c\u5e76\u5c06\u5b83\u4eec\u5408\u5e76\u5230\u5165\u95e8/\u4e2d\u7ea7/\u9ad8\u7ea7\u673a\u5668\u5b66\u4e60\u8bfe\u7a0b\u4e2d\u3002 \u6211\u4f1a\u9010\u6e10\u5220\u9664\u4e4b\u524d\u5199\u7684 Beamer \u7b14\u8bb0\uff0c\u5e76\u7528\u6280\u672f\u62a5\u544a\u7b14\u8bb0\u4ee3\u66ff\u5b83\u4eec\u3002\n\n* ### [Expectation Maximization](https://github.com/roboticcam/machine-learning-notes/blob/master/files/intermediate_em.pdf) ###\nProof of convergence for E-M, examples of E-M through Gaussian Mixture Model, **[[gmm_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/gmm_demo.m)** and **[[kmeans_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kmeans_demo.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23901379)**\n\u6700\u5927\u671f\u671bE-M\u7684\u6536\u655b\u8bc1\u660e, E-M\u5230\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u7684\u4f8b\u5b50, **[[gmm_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/gmm_demo.m)** \u548c **[[kmeans_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kmeans_demo.m)** \u548c **[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av23901379)**\n\n* ### [Markov Chain Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/intermediate_mcmc.pdf) ###\nMCMC background, including random matrix, power method convergence, detailed balance and PageRank algorithm, some basic MCMC methods, including Metropolitan-Hasting, Gibbs, and LDA as an example MCMC\u80cc\u666f\uff0c\u5305\u62ec\u968f\u673a\u77e9\u9635\u3001\u5e42\u6cd5\u6536\u655b\u3001\u8be6\u7ec6\u5e73\u8861\u548cPageRank\u7b97\u6cd5\uff0c\u4e00\u4e9b\u57fa\u672c\u7684MCMC\u65b9\u6cd5\uff0c\u5305\u62ecMetropolitan-Hasting\u3001Gibbs\u548cLDA\u4e3a\u4f8b\n\n\n* ### [Variational Inference](https://github.com/roboticcam/machine-learning-notes/blob/master/files/intermediate_vb.pdf) ###\nExplain Variational Bayes both the non-exponential and exponential family distribution **[[vb_normal_gamma.m]](https://github.com/roboticcam/matlab_demos/blob/master/vb_normal_gamma.m)** and **[[bilibili video]](https://www.bilibili.com/video/av24062247)**   \u89e3\u91ca\u53d8\u5206\u8d1d\u53f6\u65af\u975e\u6307\u6570\u548c\u6307\u6570\u65cf\u5206\u5e03\u3002**[[vb_normal_gamma.m]](https://github.com/roboticcam/matlab_demos/blob/master/vb_normal_gamma.m)** \u548c **[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av24062247)** \n\n* ### [State Space Model (Dynamic model)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/intermediate_ssm.pdf) ###\nexplain in detail of Kalman Filter  **[[bilibili video]](https://www.bilibili.com/video/av24225243)**, **[[kalman_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kalman_demo.m)** and Hidden Markov Model **[[bilibili video]](https://www.bilibili.com/video/av24132174)** \n\n\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(\u52a8\u6001\u6a21\u578b) \u8be6\u7ec6\u89e3\u91ca\u4e86\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\n**[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av24225243)**, **[[kalman_demo.m]](https://github.com/roboticcam/matlab_demos/blob/master/kalman_demo.m)**\n\u548c\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b **[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av24132174)** \n\n\n# Sinovation DeeCamp \u521b\u65b0\u5de5\u573aDeeCAMP\u8bb2\u4e49\n\n* ### [DeeCamp 2019\uff1aStory of Softmax](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deecamp_2019.pdf) ###\n\nproperties of Softmax, Estimating softmax without compute denominator, Probability re-parameterization: Gumbel-Max trick and REBAR algorithm\n (softmax\u7684\u6545\u4e8b) Softmax\u7684\u5c5e\u6027, \u4f30\u8ba1softmax\u65f6\u4e0d\u9700\u8ba1\u7b97\u5206\u6bcd, \u6982\u7387\u91cd\u65b0\u53c2\u6570\u5316, Gumbel-Max\u6280\u5de7\u548cREBAR\u7b97\u6cd5\n\n* ### [DeeCamp 2018\uff1aWhen Probabilities meet Neural Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/DeeCamp2018_Xu_final.pptx) ###\n\nExpectation-Maximization & Matrix Capsule Networks; Determinantal Point Process & Neural Networks compression; Kalman Filter & LSTM; Model estimation & Binary classifier\n(\u5f53\u6982\u7387\u9047\u5230\u795e\u7ecf\u7f51\u7edc) \u4e3b\u9898\u5305\u62ec\uff1aEM\u7b97\u6cd5\u548c\u77e9\u9635\u80f6\u56ca\u7f51\u7edc; \u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u548c\u795e\u7ecf\u7f51\u7edc\u538b\u7f29; \u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u548cLSTM; \u6a21\u578b\u4f30\u8ba1\u548c\u4e8c\u5206\u7c7b\u95ee\u9898\u5173\u7cfb\n\n\n# Deep Learning Research Topics \u6df1\u5ea6\u5b66\u4e60\u7814\u7a76\n\n* ### [Variance Reduction](https://github.com/roboticcam/machine-learning-notes/blob/master/files/variance_reduction.pdf) ###\nREBAR, RELAX algorithm and some detailed explanation of re-parameterization of Gumbel conditionals   REBAR\uff0cRELAX\u7b97\u6cd5\u4ee5\u53ca\u5bf9Gumbel\u6761\u4ef6\u6982\u7387\u91cd\u65b0\u53c2\u6570\u5316\u7684\u4e00\u4e9b\u8be6\u7ec6\u8bf4\u660e\n\n* ### [New Research on Softmax function](https://github.com/roboticcam/machine-learning-notes/blob/master/files/softmax.pdf) ###\nOut-of-distribution, Neural Network Calibration, Gumbel-Max trick, Stochastic Beams Search (some of these lectures overlap with DeeCamp2019)  \u5206\u5e03\u5916\u3001\u795e\u7ecf\u7f51\u7edc\u6821\u51c6\u3001Gumbel-Max \u6280\u5de7\u3001\u968f\u673a\u5149\u675f(BEAM)\u641c\u7d22\uff08\u5176\u4e2d\u4e00\u4e9b\u8bb2\u5ea7\u4e0e DeeCamp2019 \u91cd\u53e0\uff09\n\n* ### [Mathematics for Generative Adversarial Networks](https://github.com/roboticcam/machine-learning-notes/blob/master/files/GAN.pdf) ###\nHow GAN works, Traditional GAN, Mathematics on W-GAN, Info-GAN, Bayesian GAN   GAN\u5982\u4f55\u5de5\u4f5c\uff0c\u4f20\u7edfGAN\uff0cW-GAN\u6570\u5b66\uff0cInfo-GAN\uff0c\u8d1d\u53f6\u65afGAN\n\n* ### [Advanced Variational Autoencoder](https://github.com/roboticcam/machine-learning-notes/blob/master/files/vb_nf.pdf) ###\nHow Varational Autoencoder works, Importance Weighted Autoencoders, Normalized Flow via ELBO, Adversarial Variational Bayes, Mixture Density VAE, stick-breaking VAE\n \u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u91cd\u8981\u6027\u52a0\u6743\u81ea\u7f16\u7801\u5668\uff0c\u901a\u8fc7ELBO\u7684\u6807\u51c6\u5316\u6d41\uff0c\u5bf9\u6297\u53d8\u5206\u8d1d\u53f6\u65af, \u6df7\u5408\u5bc6\u5ea6\u81ea\u7f16\u7801\u5668\uff0cstick-breaking \u81ea\u7f16\u7801\u5668\n \n* ### [Infinite Depth: NeuralODE and Adjoint Equation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/neuralODE_Adjoint.pdf) ###\n\nDiscuss Neural ODE and in particular the use of adjoint equation in Parameter training\n\u8ba8\u8bba\u795e\u7ecfODE\uff0c\u5c24\u5176\u662f\u5728\u53c2\u6570\u8bad\u7ec3\u4e2d\u4f7f\u7528\u4f34\u968f\u65b9\u7a0b\n\n* ### [Bayesian Inference and Deep Learning (Seminar Talk)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/bayesian_inference_deep_learning.pdf) ###\nThis is a seminar talk I gave on some modern examples in which Bayesian (or probabilistic) framework is to explain, assist and assisted by Deep Learning. \u8fd9\u662f\u6211\u7684\u6f14\u8bb2\u7a3f\u4ef6\u3002\u5f52\u7eb3\u4e86\u4e00\u4e9b\u6700\u8fd1\u7814\u7a76\u4f8b\u5b50\u4e2d\uff0c\u8d1d\u53f6\u65af\uff08\u6216\u6982\u7387\uff09\u6846\u67b6\u6765\u89e3\u91ca\uff0c\u5e2e\u52a9(\u6216\u88ab\u5e2e\u52a9\u4e8e)\u6df1\u5ea6\u5b66\u4e60\u3002\n\n\n# Optimization Method \u4f18\u5316\u65b9\u6cd5\n\n* ### [Tutorial on Gradient Descend Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/gradient_desend.pdf) ###\nThis is a progressive research note on Implicit Bias and Implicit Regularization of Gradient Descent Algorithms (check out my biweekly seminars), Convergence Research for Stochastic Gradient Descent etc.\u8fd9\u662f\u5173\u4e8e\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u7684\u9690\u5f0f\u504f\u5dee\u548c\u9690\u5f0f\u6b63\u5219\u5316\u7684\u6e10\u8fdb\u5f0f\u7814\u7a76\u7b14\u8bb0\uff08\u67e5\u770b\u6211\u7684\u53cc\u5468\u7814\u8ba8\u4f1a\uff09\u3001\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u7684\u6536\u655b\u7814\u7a76\u7b49\u3002\n\n\n* ### [Tutorial on Duality](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dual.pdf) ###\nLagrangian duality, dual function, KKT condition, example on support vector machines and Farkas Lemma \u62c9\u683c\u6717\u65e5\u5bf9\u5076\u3001\u5bf9\u5076\u51fd\u6570\u3001KKT \u6761\u4ef6\u3001\u652f\u6301\u5411\u91cf\u673a\u793a\u4f8b \u548c Farkas \u5f15\u7406\n\n\n* ### [Conjugate Gradient Descend](https://github.com/roboticcam/machine-learning-notes/blob/master/files/conjugate.pdf) ###\nA quick explanation of Conjugate Gradient Descend     \u5171\u8f6d\u68af\u5ea6\u4e0b\u964d\u7684\u5feb\u901f\u89e3\u91ca\n\n\n# Deep Learning Basics \u6df1\u5ea6\u5b66\u4e60\u57fa\u7840\n\n* ### [Convolution Neural Networks: from basic to recent Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cnn_beyond.pdf) ###\ndetailed explanation of CNN, various Loss function, Centre Loss, contrastive Loss, Residual Networks, Capsule Networks, YOLO, SSD   \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff1a\u4ece\u57fa\u7840\u5230\u6700\u8fd1\u7684\u7814\u7a76\uff1a\u5305\u62ec\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u8be6\u7ec6\u89e3\u91ca\uff0c\u5404\u79cd\u635f\u5931\u51fd\u6570\uff0c\u4e2d\u5fc3\u635f\u5931\u51fd\u6570\uff0c\u5bf9\u6bd4\u635f\u5931\u51fd\u6570\uff0c\u6b8b\u5dee\u7f51\u7edc\uff0c\u80f6\u56ca\u7f51\u7edc, YOLO\uff0cSSD\n\n* ### [Restricted Boltzmann Machine](https://github.com/roboticcam/machine-learning-notes/blob/master/files/rbm_cd.pdf) ###\nRestricted Boltzmann Machine (RBM) and Contrastive Divergence (CD) Basics  \u53d7\u9650\u73bb\u5c14\u5179\u66fc\u673a (RBM) \u548c\u5bf9\u6bd4\u53d1\u6563 (CD) \u57fa\u7840\u77e5\u8bc6\n\n\n# 3D Geometry Computer vision 3D\u51e0\u4f55\u8ba1\u7b97\u673a\u89c6\u89c9 \n\n* ### [3D Geometry Fundamentals](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cv_3d_foundation.pdf) ###\nCamera Models, Intrinsic and Extrinsic parameter estimation, Epipolar Geometry, 3D reconstruction, Depth Estimation  \u76f8\u673a\u6a21\u578b\uff0c\u5185\u90e8\u548c\u5916\u90e8\u53c2\u6570\u4f30\u8ba1\uff0c\u5bf9\u6781\u51e0\u4f55\uff0c\u4e09\u7ef4\u91cd\u5efa\uff0c\u56fe\u50cf\u6df1\u5ea6\u4f30\u8ba1\n\n* ### [Recent Deep 3D Geometry based Research](https://github.com/roboticcam/machine-learning-notes/blob/master/files/cv_3d_research.pdf) ###\nRecent research of the following topics: Single image to Camera Model estimation, Multi-Person 3D pose estimation from multi-view, GAN-based 3D pose estimation, Deep Structure-from-Motion, Deep Learning based Depth Estimation,  \u4ee5\u4e0b\u4e3b\u9898\u7684\u6700\u65b0\u7814\u7a76\uff1a\u5355\u56fe\u50cf\u5230\u76f8\u673a\u6a21\u578b\u7684\u4f30\u8ba1\uff0c\u57fa\u4e8e\u591a\u89c6\u56fe\u7684\u591a\u4eba3D\u59ff\u52bf\u4f30\u8ba1\uff0c\u57fa\u4e8eGAN\u76843D\u59ff\u52bf\u4f30\u8ba1\uff0c\u57fa\u4e8e\u8fd0\u52a8\u7684\u6df1\u5ea6\u7ed3\u6784\uff0c\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6df1\u5ea6\u4f30\u8ba1\n\nThis section is co-authored with PhD student Yang Li \u672c\u90e8\u5206\u4e0e\u535a\u58eb\u7814\u7a76\u751f\u674e\u6768\u5408\u5199\n\n# Reinforcement Learning \u5f3a\u5316\u5b66\u4e60\n\n* ### [Reinforcement Learning Basics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dqn.pdf) ###\nbasic knowledge in reinforcement learning, Markov Decision Process, Bellman Equation and move onto Deep Q-Learning   \u6df1\u5ea6\u589e\u5f3a\u5b66\u4e60: \u5f3a\u5316\u5b66\u4e60\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8d1d\u5c14\u66fc\u65b9\u7a0b\uff0c\u6df1\u5ea6Q\u5b66\u4e60\n\n* ### [Monto Carlo Tree Search](https://github.com/roboticcam/machine-learning-notes/blob/master/files/mcts.pdf) ###\nMonto Carlo Tree Search, alphaGo learning algorithm   \u8499\u6258\u5361\u7f57\u6811\u641c\u7d22\uff0calphaGo\u5b66\u4e60\u7b97\u6cd5\n\n* ### [Policy Gradient](https://github.com/roboticcam/machine-learning-notes/blob/master/files/policy_gradient.pdf) ###\nPolicy Gradient Theorem, Mathematics on Trusted Region Optimization in RL, Natural Gradients on TRPO, Proximal Policy Optimization (PPO), Conjugate Gradient Algorithm   \u653f\u7b56\u68af\u5ea6\u5b9a\u7406, RL\u4e2d\u53ef\u4fe1\u533a\u57df\u4f18\u5316\u7684\u6570\u5b66,TRPO\u81ea\u7136\u68af\u5ea6, \u8fd1\u4f3c\u7b56\u7565\u4f18\u5316(PPO), \u5171\u8f6d\u68af\u5ea6\u7b97\u6cd5\n\n\n# Natural Language Processing \u81ea\u7136\u8bed\u8a00\u5904\u7406\n\n* ### [Word Embeddings](https://github.com/roboticcam/machine-learning-notes/blob/master/files/word_vector.pdf) ###\nGloVe, Fasttext, negative sampling   \u7cfb\u7edf\u7684\u4ecb\u7ecd\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u201c\u8bcd\u8868\u793a\u201d\u4e2d\u7684\u6280\u5de7\n\n* ### [Deep Natural Language Processing](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deep_nlp.pdf) ###\nRNN, LSTM, Seq2Seq with Attenion, Beam search, Attention is all you need, Convolution Seq2Seq, Pointer Networks   \u6df1\u5ea6\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff1a\u9012\u5f52\u795e\u7ecf\u7f51\u7edc,LSTM,\u5177\u6709\u6ce8\u610f\u529b\u673a\u5236\u7684Seq2Seq\uff0c\u96c6\u675f\u641c\u7d22\uff0c\u6307\u9488\u7f51\u7edc\u548c \"Attention is all you need\", \u5377\u79efSeq2Seq\n\n\n# Data Science PowerPoint and Source Code \u6570\u636e\u79d1\u5b66 PowerPoint \u548c\u6e90\u4ee3\u7801\n\n* ### [introduction to Deep Learning and ChatGPT](https://github.com/roboticcam/machine-learning-notes/blob/master/files/deep_learning_chatgpt.pdf)\nan introduction to deep learning and ChatGPT [video link](https://www.bilibili.com/video/BV14M4y1R7h4/)\n\n\n* ### [30 minutes introduction to AI and Machine Learning](https://github.com/roboticcam/machine-learning-notes/blob/master/files/30_min_AI.pptx)\nAn extremely gentle 30 minutes introduction to AI and Machine Learning. \n\n* **[[costFunction.m]](https://github.com/roboticcam/matlab_demos/blob/master/costFunction.m)** \n* **[[soft_max.m]](https://github.com/roboticcam/matlab_demos/blob/master/soft_max.m)** \n* **[[industry data science Jupyter notebook]](https://github.com/roboticcam/machine-learning-notes/blob/master/files/industry_master_class.ipynb)**\n\n* ### [Recommendation system](https://github.com/roboticcam/machine-learning-notes/blob/master/files/recommendation.pdf) ###\ncollaborative filtering, Factorization Machines, Non-Negative Matrix factorisation, Multiplicative Update Rule     \u63a8\u8350\u7cfb\u7edf: \u534f\u540c\u8fc7\u6ee4\uff0c\u5206\u89e3\u673a\uff0c\u975e\u8d1f\u77e9\u9635\u5206\u89e3\uff0c\u548c\u671f\u4e2d\u201c\u4e58\u6cd5\u66f4\u65b0\u89c4\u5219\u201d\u7684\u4ecb\u7ecd\n\n\n# Probabilistic Model \u6982\u7387\u6a21\u578b\u8bfe\u4ef6\n\n* ### [Probabilistic Estimation](https://github.com/roboticcam/machine-learning-notes/blob/master/files/probability.pdf) ###\nsome useful distributions, conjugacy, MLE, MAP, Exponential family and natural parameters     \u4e00\u4e9b\u5e38\u7528\u7684\u5206\u5e03\uff0c\u5171\u8f6d\u7279\u6027\uff0c\u6700\u5927\u4f3c\u7136\u4f30\u8ba1, \u6700\u5927\u540e\u9a8c\u4f30\u8ba1, \u6307\u6570\u65cf\u548c\u81ea\u7136\u53c2\u6570\n\n# Monte-Carlo Inference \u8499\u7279\u5361\u6d1b\u63a8\u7406\n\n* ### [Introduction to Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/introduction_monte_carlo.pdf) ###\ninverse CDF, rejection, adaptive rejection, importance sampling **[[adaptive_rejection_sampling.m]](https://github.com/roboticcam/matlab_demos/blob/master/adaptive_rejection_sampling.m)** and **[[hybrid_gmm.m]](https://github.com/roboticcam/matlab_demos/blob/master/hybrid_gmm.m)** \u7d2f\u79ef\u5206\u5e03\u51fd\u6570\u9006\u91c7\u6837, \u62d2\u7edd\u5f0f\u91c7\u6837, \u81ea\u9002\u5e94\u62d2\u7edd\u5f0f\u91c7\u6837, \u91cd\u8981\u6027\u91c7\u6837 **[[adaptive_rejection_sampling.m]](https://github.com/roboticcam/matlab_demos/blob/master/adaptive_rejection_sampling.m)** \u548c **[[hybrid_gmm.m]](https://github.com/roboticcam/matlab_demos/blob/master/hybrid_gmm.m)**\n\n* ### [Markov Chain Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/files/markov_chain_monte_carlo.pdf) ###\nM-H, Gibbs, Slice Sampling, Elliptical Slice sampling, Swendesen-Wang, demonstrate collapsed Gibbs using LDA **[[lda_gibbs_example.m]](https://github.com/roboticcam/matlab_demos/blob/master/lda_gibbs_example.m)** and **[[test_autocorrelation.m]](https://github.com/roboticcam/matlab_demos/blob/master/test_autocorrelation.m)** and **[[gibbs.m]](https://github.com/roboticcam/matlab_demos/blob/master/gibbs.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23980130)** \u9a6c\u5c14\u53ef\u592b\u94fe\u8499\u7279\u5361\u6d1b\u7684\u5404\u79cd\u65b9\u6cd5 **[[lda_gibbs_example.m]](https://github.com/roboticcam/matlab_demos/blob/master/lda_gibbs_example.m)** \u548c **[[test_autocorrelation.m]](https://github.com/roboticcam/matlab_demos/blob/master/test_autocorrelation.m)** \u548c **[[gibbs.m]](https://github.com/roboticcam/matlab_demos/blob/master/gibbs.m)** \u548c **[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av23980130)**\n\n\n* ### [Particle Filter (Sequential Monte-Carlo)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/particle_filter.pdf) ###\nSequential Monte-Carlo, Condensational Filter algorithm, Auxiliary Particle Filter **[[bilibili video]](https://www.bilibili.com/video/av24285449)**    \u7c92\u5b50\u6ee4\u6ce2\u5668\uff08\u5e8f\u5217\u8499\u7279\u5361\u6d1b\uff09**[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av24285449)**\n\n# Advanced Probabilistic Model \u9ad8\u7ea7\u6982\u7387\u6a21\u578b\u8bfe\u4ef6\n\n* ### [Bayesian Non Parametrics (BNP) and its inference basics](https://github.com/roboticcam/machine-learning-notes/blob/master/files/non_parametrics.pdf) ###\nDircihlet Process (DP), Chinese Restaurant Process insights, Slice sampling for DP **[[dirichlet_process.m]](https://github.com/roboticcam/matlab_demos/blob/master/dirichlet_process.m)** and **[[bilibili video]](https://www.bilibili.com/video/av23881062)** and **[[Jupyter Notebook]](https://github.com/roboticcam/python_machine_learning/blob/master/chinese_restaurant_process.ipynb)**\n\n\u975e\u53c2\u8d1d\u53f6\u65af\u53ca\u5176\u63a8\u5bfc\u57fa\u7840: \u72c4\u5229\u514b\u96f7\u8fc7\u7a0b,\u4e2d\u56fd\u9910\u9986\u8fc7\u7a0b,\u72c4\u5229\u514b\u96f7\u8fc7\u7a0bSlice\u91c7\u6837 **[[dirichlet_process.m]](https://github.com/roboticcam/matlab_demos/blob/master/dirichlet_process.m)** \u548c **[[B\u7ad9\u89c6\u9891\u94fe\u63a5]](https://www.bilibili.com/video/av23881062)** \u548c **[[Jupyter Notebook]](https://github.com/roboticcam/python_machine_learning/blob/master/chinese_restaurant_process.ipynb)**\n\n* ### [Bayesian Non Parametrics (BNP) extensions](https://github.com/roboticcam/machine-learning-notes/blob/master/files/non_parametrics_extensions.pdf) ###\nHierarchical DP, HDP-HMM, Indian Buffet Process (IBP)     \u975e\u53c2\u8d1d\u53f6\u65af\u6269\u5c55: \u5c42\u6b21\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b\uff0c\u5206\u5c42\u72c4\u5229\u514b\u96f7\u8fc7\u7a0b-\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff0c\u5370\u5ea6\u81ea\u52a9\u9910\u8fc7\u7a0b(IBP)\n\n* ### [Completely Random Measure (early draft - written in 2015)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/random_measure.pdf) ###\nLevy-Khintchine representation, Compound Poisson Process, Gamma Process, Negative Binomial Process     Levy-Khintchine\u8868\u793a\uff0c\u590d\u5408Poisson\u8fc7\u7a0b\uff0cGamma\u8fc7\u7a0b\uff0c\u8d1f\u4e8c\u9879\u8fc7\u7a0b\n\n* ### [Sample correlated integers from HDP and Copula](https://github.com/roboticcam/machine-learning-notes/blob/master/files/copula_dp.pdf) ###\nThis is an alternative explanation to our [IJCAI 2016 papers](https://www.ijcai.org/Proceedings/16/Papers/210.pdf). The derivations are different from the paper, but portraits the same story.     \u8fd9\u662f\u5bf9\u6211\u7684[IJCAI2016\u8bba\u6587](https://www.ijcai.org/Proceedings/16/Papers/210.pdf) \u7684\u4e00\u4e2a\u4e0d\u540c\u89e3\u91ca\u3002\u867d\u7136\u5199\u7684\u65b9\u6cd5\u516c\u5f0f\u63a8\u5bfc\u4e0d\u540c\uff0c\u4f46\u63cf\u7ed8\u7684\u662f\u540c\u4e00\u4e8b\u60c5\n\n* ### [Determinantal Point Process](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dpp.pdf) ###\nexplain the details of DPP\u2019s marginal distribution, L-ensemble, its sampling strategy, our work in time-varying DPP     \u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u89e3\u91ca:\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u7684\u8fb9\u7f18\u5206\u5e03\uff0cL-ensemble\uff0c\u5176\u62bd\u6837\u7b56\u7565\uff0c\u6211\u4eec\u5728\u201c\u65f6\u53d8\u884c\u5217\u5f0f\u70b9\u8fc7\u7a0b\u201d\u4e2d\u7684\u5de5\u4f5c\u7ec6\u8282\n\n* ### [Determinantal Point Process Basics (updated)](https://github.com/roboticcam/machine-learning-notes/blob/master/files/dpp_new.pdf) ###\nthis is a re-write of the previous DPP tutorial without the time-vaying part      \u8fd9\u662f\u4e4b\u524dDPP\u6559\u7a0b\u7684\u91cd\u5199\uff0c\u6ca1\u6709\u65f6\u95f4\u53d8\u5316\u90e8\u5206\n\n# Special Thanks\n* I want to thank all the Universities where I have worked for tolerating me indulging my love of knowledge dissemination. \n\u6211\u8981\u611f\u8c22\u6240\u6709\u6211\u5de5\u4f5c\u8fc7\u7684\u5927\u5b66\u5bb9\u5fcd\u6211\u6c89\u8ff7\u4e8e\u77e5\u8bc6\u4f20\u64ad\n\n* I always look for high quality PhD students in Machine Learning, both in terms of probabilistic model and Deep Learning theory. Contact me on xuyida@hkbu.edu.hk     \u5982\u679c\u4f60\u60f3\u52a0\u5165\u6211\u7684\u673a\u5668\u5b66\u4e60\u535a\u58eb\u751f\u56e2\u961f\u6216\u6709\u5174\u8da3\u5408\u4f5c, \u8bf7\u901a\u8fc7xuyida@hkbu.edu.hk\u4e0e\u6211\u8054\u7cfb\u3002\n",
        "releases": []
    }
}