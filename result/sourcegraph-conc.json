{
    "https://api.github.com/repos/sourcegraph/conc": {
        "forks": 327,
        "watchers": 9574,
        "stars": 9574,
        "languages": {
            "Go": 79621,
            "Makefile": 787
        },
        "commits": [
            "2024-01-21T21:45:20Z",
            "2024-01-21T21:44:01Z",
            "2024-01-21T21:42:30Z",
            "2024-01-19T18:08:15Z",
            "2024-01-19T17:52:23Z",
            "2024-01-19T17:50:06Z",
            "2024-01-08T18:24:09Z",
            "2023-11-12T17:16:38Z",
            "2023-11-12T16:16:35Z",
            "2023-11-12T16:09:25Z",
            "2023-08-03T02:37:53Z",
            "2023-11-12T14:57:59Z",
            "2023-06-02T18:56:21Z",
            "2023-06-01T21:56:05Z",
            "2023-06-01T21:50:57Z",
            "2023-05-03T04:23:57Z",
            "2023-04-10T17:42:32Z",
            "2023-03-03T17:24:14Z",
            "2023-02-27T22:56:24Z",
            "2023-02-25T04:04:07Z",
            "2023-02-25T01:11:57Z",
            "2023-02-25T01:06:16Z",
            "2023-02-24T23:12:31Z",
            "2023-02-24T18:05:27Z",
            "2023-02-24T17:46:06Z",
            "2023-02-21T17:07:27Z",
            "2023-02-21T12:10:46Z",
            "2023-02-21T12:09:16Z",
            "2023-01-22T01:27:01Z",
            "2023-02-17T05:24:52Z"
        ],
        "creation_date": "2023-01-02T22:52:07Z",
        "contributors": 17,
        "topics": [
            "concurrency",
            "go",
            "golang",
            "goroutines"
        ],
        "subscribers": 64,
        "readme": "![conch](https://user-images.githubusercontent.com/12631702/210295964-785cc63d-d697-420c-99ff-f492eb81dec9.svg)\n\n# `conc`: better structured concurrency for go\n\n[![Go Reference](https://pkg.go.dev/badge/github.com/sourcegraph/conc.svg)](https://pkg.go.dev/github.com/sourcegraph/conc)\n[![Sourcegraph](https://img.shields.io/badge/view%20on-sourcegraph-A112FE?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAYAAAAeP4ixAAAEZklEQVRoQ+2aXWgUZxSG3292sxtNN43BhBakFPyhxSujRSxiU1pr7SaGXqgUxOIEW0IFkeYighYUxAuLUlq0lrq2iCDpjWtmFVtoG6QVNOCFVShVLyxIk0DVjZLMxt3xTGTccd2ZOd/8JBHci0CY9zvnPPN+/7sCIXwKavOwAcy2QgngQiIztDSE0OwQlDPYR1ebiaH6J5kZChyfW12gRG4QVgGTBfMchMbFP9Sn5nlZL2D0JjLD6710lc+z0NfqSGTXQRQ4bX07Mq423yoBL3OSyHSvUxirMuaEvgbJWrdcvkHMoJwxYuq4INUhyuWvQa1jvdMGxAvCxJlyEC9XOBCWL04wwRzpbDoDQ7wfZJzIQLi5Eggk6DiRhZgWIAbE3NrM4A3LPT8Q7UgqAqLqTmLSHLGPkyzG/qXEczhd0q6RH+zaSBfaUoc4iQx19pIClIscrTkNZzG6gd7qMY6eC2Hqyo705ZfTf+eqJmhMzcSbYtQpOXc92ZsZjLVAL4YNUQbJ5Ttg4CQrQdGYj44Xr9m1XJCzmZusFDJOWNpHjmh5x624a2ZFtOKDVL+uNo2TuXE3bZQQZUf8gtgqP31uI94Z/rMqix+IGiRfWw3xN9dCgVx+L3WrHm4Dju6PXz/EkjuXJ6R+IGgyOE1TbZqTq9y1eo0EZo7oMo1ktPu3xjHvuiLT5AFNszUyDULtWpzE2/fEsey8O5TbWuGWwxrs5rS7nFNMWJrNh2No74s9Ec4vRNmRRzPXMP19fBMSVsGcOJ98G8N3Wl2gXcbTjbX7vUBxLaeASDQCm5Cu/0E2tvtb0Ea+BowtskFD0wvlc6Rf2M+Jx7dTu7ubFr2dnKDRaMQe2v/tcIrNB7FH0O50AcrBaApmRDVwFO31ql3pD8QW4dP0feNwl/Q+kFEtRyIGyaWXnpy1OO0qNJWHo1y6iCmAGkBb/Ru+HenDWIF2mo4r8G+tRRzoniSn2uqFLxANhe9LKHVyTbz6egk9+x5w5fK6ulSNNMhZ/Feno+GebLZV6isTTa6k5qNl5RnZ5u56Ib6SBvFzaWBBVFZzvnERWlt/Cg4l27XChLCqFyLekjhy6xJyoytgjPf7opIB8QPx7sYFiMXHPGt76m741MhCKMZfng0nBOIjmoJPsLqWHwgFpe6V6qtfcopxveR2Oy+J0ntIN/zCWkf8QNAJ7y6d8Bq4lxLc2/qJl5K7t432XwcqX5CrI34gzATWuYILQtdQPyePDK3iuOekCR3Efjhig1B1Uq5UoXEEoZX7d1q535J5S9VOeFyYyEBku5XTMXXKQTToX5Rg7OI44nbW5oKYeYK4EniMeF0YFNSmb+grhc84LyRCEP1/OurOcipCQbKxDeK2V5FcVyIDMQvsgz5gwFhcWWwKyRlvQ3gv29RwWoDYAbIofNyBxI9eDlQ+n3YgsgCWnr4MStGXQXmv9pF2La/k3OccV54JEBM4yp9EsXa/3LfO0dGPcYq0Y7DfZB8nJzZw2rppHgKgVHs8L5wvRwAAAABJRU5ErkJggg==)](https://sourcegraph.com/github.com/sourcegraph/conc)\n[![Go Report Card](https://goreportcard.com/badge/github.com/sourcegraph/conc)](https://goreportcard.com/report/github.com/sourcegraph/conc)\n[![codecov](https://codecov.io/gh/sourcegraph/conc/branch/main/graph/badge.svg?token=MQZTEA1QWT)](https://codecov.io/gh/sourcegraph/conc)\n[![Discord](https://img.shields.io/badge/discord-chat-%235765F2)](https://discord.gg/bvXQXmtRjN)\n\n`conc` is your toolbelt for structured concurrency in go, making common tasks\neasier and safer.\n\n```sh\ngo get github.com/sourcegraph/conc\n```\n\n# At a glance\n\n- Use [`conc.WaitGroup`](https://pkg.go.dev/github.com/sourcegraph/conc#WaitGroup) if you just want a safer version of `sync.WaitGroup`\n- Use [`pool.Pool`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#Pool) if you want a concurrency-limited task runner\n- Use [`pool.ResultPool`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#ResultPool) if you want a concurrent task runner that collects task results\n- Use [`pool.(Result)?ErrorPool`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#ErrorPool) if your tasks are fallible\n- Use [`pool.(Result)?ContextPool`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#ContextPool) if your tasks should be canceled on failure\n- Use [`stream.Stream`](https://pkg.go.dev/github.com/sourcegraph/conc/stream#Stream) if you want to process an ordered stream of tasks in parallel with serial callbacks\n- Use [`iter.Map`](https://pkg.go.dev/github.com/sourcegraph/conc/iter#Map) if you want to concurrently map a slice\n- Use [`iter.ForEach`](https://pkg.go.dev/github.com/sourcegraph/conc/iter#ForEach) if you want to concurrently iterate over a slice\n- Use [`panics.Catcher`](https://pkg.go.dev/github.com/sourcegraph/conc/panics#Catcher) if you want to catch panics in your own goroutines\n\nAll pools are created with\n[`pool.New()`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#New)\nor\n[`pool.NewWithResults[T]()`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#NewWithResults),\nthen configured with methods:\n\n- [`p.WithMaxGoroutines()`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#Pool.MaxGoroutines) configures the maximum number of goroutines in the pool\n- [`p.WithErrors()`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#Pool.WithErrors) configures the pool to run tasks that return errors\n- [`p.WithContext(ctx)`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#Pool.WithContext) configures the pool to run tasks that should be canceled on first error\n- [`p.WithFirstError()`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#ErrorPool.WithFirstError) configures error pools to only keep the first returned error rather than an aggregated error\n- [`p.WithCollectErrored()`](https://pkg.go.dev/github.com/sourcegraph/conc/pool#ResultContextPool.WithCollectErrored) configures result pools to collect results even when the task errored\n\n# Goals\n\nThe main goals of the package are:\n1) Make it harder to leak goroutines\n2) Handle panics gracefully\n3) Make concurrent code easier to read\n\n## Goal #1: Make it harder to leak goroutines\n\nA common pain point when working with goroutines is cleaning them up. It's\nreally easy to fire off a `go` statement and fail to properly wait for it to\ncomplete.\n\n`conc` takes the opinionated stance that all concurrency should be scoped.\nThat is, goroutines should have an owner and that owner should always\nensure that its owned goroutines exit properly.\n\nIn `conc`, the owner of a goroutine is always a `conc.WaitGroup`. Goroutines\nare spawned in a `WaitGroup` with `(*WaitGroup).Go()`, and\n`(*WaitGroup).Wait()` should always be called before the `WaitGroup` goes out\nof scope.\n\nIn some cases, you might want a spawned goroutine to outlast the scope of the\ncaller. In that case, you could pass a `WaitGroup` into the spawning function.\n\n```go\nfunc main() {\n    var wg conc.WaitGroup\n    defer wg.Wait()\n\n    startTheThing(&wg)\n}\n\nfunc startTheThing(wg *conc.WaitGroup) {\n    wg.Go(func() { ... })\n}\n```\n\nFor some more discussion on why scoped concurrency is nice, check out [this\nblog\npost](https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/).\n\n## Goal #2: Handle panics gracefully\n\nA frequent problem with goroutines in long-running applications is handling\npanics. A goroutine spawned without a panic handler will crash the whole process\non panic. This is usually undesirable.\n\nHowever, if you do add a panic handler to a goroutine, what do you do with the\npanic once you catch it? Some options:\n1) Ignore it\n2) Log it\n3) Turn it into an error and return that to the goroutine spawner\n4) Propagate the panic to the goroutine spawner\n\nIgnoring panics is a bad idea since panics usually mean there is actually\nsomething wrong and someone should fix it.\n\nJust logging panics isn't great either because then there is no indication to the spawner\nthat something bad happened, and it might just continue on as normal even though your\nprogram is in a really bad state.\n\nBoth (3) and (4) are reasonable options, but both require the goroutine to have\nan owner that can actually receive the message that something went wrong. This\nis generally not true with a goroutine spawned with `go`, but in the `conc`\npackage, all goroutines have an owner that must collect the spawned goroutine.\nIn the conc package, any call to `Wait()` will panic if any of the spawned goroutines\npanicked. Additionally, it decorates the panic value with a stacktrace from the child\ngoroutine so that you don't lose information about what caused the panic.\n\nDoing this all correctly every time you spawn something with `go` is not\ntrivial and it requires a lot of boilerplate that makes the important parts of\nthe code more difficult to read, so `conc` does this for you.\n\n<table>\n<tr>\n<th><code>stdlib</code></th>\n<th><code>conc</code></th>\n</tr>\n<tr>\n<td>\n\n```go\ntype caughtPanicError struct {\n    val   any\n    stack []byte\n}\n\nfunc (e *caughtPanicError) Error() string {\n    return fmt.Sprintf(\n        \"panic: %q\\n%s\",\n        e.val,\n        string(e.stack)\n    )\n}\n\nfunc main() {\n    done := make(chan error)\n    go func() {\n        defer func() {\n            if v := recover(); v != nil {\n                done <- &caughtPanicError{\n                    val: v,\n                    stack: debug.Stack()\n                }\n            } else {\n                done <- nil\n            }\n        }()\n        doSomethingThatMightPanic()\n    }()\n    err := <-done\n    if err != nil {\n        panic(err)\n    }\n}\n```\n</td>\n<td>\n\n```go\nfunc main() {\n    var wg conc.WaitGroup\n    wg.Go(doSomethingThatMightPanic)\n    // panics with a nice stacktrace\n    wg.Wait()\n}\n```\n</td>\n</tr>\n</table>\n\n## Goal #3: Make concurrent code easier to read\n\nDoing concurrency correctly is difficult. Doing it in a way that doesn't\nobfuscate what the code is actually doing is more difficult. The `conc` package\nattempts to make common operations easier by abstracting as much boilerplate\ncomplexity as possible.\n\nWant to run a set of concurrent tasks with a bounded set of goroutines? Use\n`pool.New()`. Want to process an ordered stream of results concurrently, but\nstill maintain order? Try `stream.New()`. What about a concurrent map over\na slice? Take a peek at `iter.Map()`.\n\nBrowse some examples below for some comparisons with doing these by hand.\n\n# Examples\n\nEach of these examples forgoes propagating panics for simplicity. To see\nwhat kind of complexity that would add, check out the \"Goal #2\" header above.\n\nSpawn a set of goroutines and waiting for them to finish:\n\n<table>\n<tr>\n<th><code>stdlib</code></th>\n<th><code>conc</code></th>\n</tr>\n<tr>\n<td>\n\n```go\nfunc main() {\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            // crashes on panic!\n            doSomething()\n        }()\n    }\n    wg.Wait()\n}\n```\n</td>\n<td>\n\n```go\nfunc main() {\n    var wg conc.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Go(doSomething)\n    }\n    wg.Wait()\n}\n```\n</td>\n</tr>\n</table>\n\nProcess each element of a stream in a static pool of goroutines:\n\n<table>\n<tr>\n<th><code>stdlib</code></th>\n<th><code>conc</code></th>\n</tr>\n<tr>\n<td>\n\n```go\nfunc process(stream chan int) {\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for elem := range stream {\n                handle(elem)\n            }\n        }()\n    }\n    wg.Wait()\n}\n```\n</td>\n<td>\n\n```go\nfunc process(stream chan int) {\n    p := pool.New().WithMaxGoroutines(10)\n    for elem := range stream {\n        elem := elem\n        p.Go(func() {\n            handle(elem)\n        })\n    }\n    p.Wait()\n}\n```\n</td>\n</tr>\n</table>\n\nProcess each element of a slice in a static pool of goroutines:\n\n<table>\n<tr>\n<th><code>stdlib</code></th>\n<th><code>conc</code></th>\n</tr>\n<tr>\n<td>\n\n```go\nfunc process(values []int) {\n    feeder := make(chan int, 8)\n\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n            for elem := range feeder {\n                handle(elem)\n            }\n        }()\n    }\n\n    for _, value := range values {\n        feeder <- value\n    }\n    close(feeder)\n    wg.Wait()\n}\n```\n</td>\n<td>\n\n```go\nfunc process(values []int) {\n    iter.ForEach(values, handle)\n}\n```\n</td>\n</tr>\n</table>\n\nConcurrently map a slice:\n\n<table>\n<tr>\n<th><code>stdlib</code></th>\n<th><code>conc</code></th>\n</tr>\n<tr>\n<td>\n\n```go\nfunc concMap(\n    input []int,\n    f func(int) int,\n) []int {\n    res := make([]int, len(input))\n    var idx atomic.Int64\n\n    var wg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        wg.Add(1)\n        go func() {\n            defer wg.Done()\n\n            for {\n                i := int(idx.Add(1) - 1)\n                if i >= len(input) {\n                    return\n                }\n\n                res[i] = f(input[i])\n            }\n        }()\n    }\n    wg.Wait()\n    return res\n}\n```\n</td>\n<td>\n\n```go\nfunc concMap(\n    input []int,\n    f func(*int) int,\n) []int {\n    return iter.Map(input, f)\n}\n```\n</td>\n</tr>\n</table>\n\nProcess an ordered stream concurrently:\n\n\n<table>\n<tr>\n<th><code>stdlib</code></th>\n<th><code>conc</code></th>\n</tr>\n<tr>\n<td>\n\n```go\nfunc mapStream(\n    in chan int,\n    out chan int,\n    f func(int) int,\n) {\n    tasks := make(chan func())\n    taskResults := make(chan chan int)\n\n    // Worker goroutines\n    var workerWg sync.WaitGroup\n    for i := 0; i < 10; i++ {\n        workerWg.Add(1)\n        go func() {\n            defer workerWg.Done()\n            for task := range tasks {\n                task()\n            }\n        }()\n    }\n\n    // Ordered reader goroutines\n    var readerWg sync.WaitGroup\n    readerWg.Add(1)\n    go func() {\n        defer readerWg.Done()\n        for result := range taskResults {\n            item := <-result\n            out <- item\n        }\n    }()\n\n    // Feed the workers with tasks\n    for elem := range in {\n        resultCh := make(chan int, 1)\n        taskResults <- resultCh\n        tasks <- func() {\n            resultCh <- f(elem)\n        }\n    }\n\n    // We've exhausted input.\n    // Wait for everything to finish\n    close(tasks)\n    workerWg.Wait()\n    close(taskResults)\n    readerWg.Wait()\n}\n```\n</td>\n<td>\n\n```go\nfunc mapStream(\n    in chan int,\n    out chan int,\n    f func(int) int,\n) {\n    s := stream.New().WithMaxGoroutines(10)\n    for elem := range in {\n        elem := elem\n        s.Go(func() stream.Callback {\n            res := f(elem)\n            return func() { out <- res }\n        })\n    }\n    s.Wait()\n}\n```\n</td>\n</tr>\n</table>\n\n# Status\n\nThis package is currently pre-1.0. There are likely to be minor breaking\nchanges before a 1.0 release as we stabilize the APIs and tweak defaults.\nPlease open an issue if you have questions, concerns, or requests that you'd\nlike addressed before the 1.0 release. Currently, a 1.0 is targeted for \nMarch 2023.\n",
        "releases": [
            {
                "name": "v0.3.0",
                "date": "2023-02-26T02:46:34Z"
            },
            {
                "name": "v0.2.0",
                "date": "2023-01-17T19:18:42Z"
            },
            {
                "name": "v0.1.0",
                "date": "2023-01-02T23:18:26Z"
            }
        ]
    }
}