{
    "https://api.github.com/repos/openai/shap-e": {
        "forks": 964,
        "watchers": 11765,
        "stars": 11765,
        "languages": {
            "Python": 481006,
            "Jupyter Notebook": 8520
        },
        "commits": [
            "2023-11-08T17:19:41Z",
            "2023-07-11T16:41:38Z",
            "2023-06-07T01:42:30Z",
            "2023-05-11T23:31:47Z",
            "2023-05-09T00:21:21Z",
            "2023-05-09T00:21:09Z",
            "2023-05-05T20:14:59Z",
            "2023-05-05T19:58:16Z",
            "2023-05-05T17:56:08Z",
            "2023-05-05T16:59:49Z",
            "2023-05-05T16:59:05Z",
            "2023-05-05T04:25:54Z",
            "2023-05-05T00:12:35Z",
            "2023-04-19T18:54:08Z"
        ],
        "creation_date": "2023-04-19T18:54:32Z",
        "contributors": 8,
        "topics": [],
        "subscribers": 234,
        "readme": "# Shap-E\n\nThis is the official code and model release for [Shap-E: Generating Conditional 3D Implicit Functions](https://arxiv.org/abs/2305.02463).\n\n * See [Usage](#usage) for guidance on how to use this repository.\n * See [Samples](#samples) for examples of what our text-conditional model can generate.\n\n# Samples\n\nHere are some highlighted samples from our text-conditional model. For random samples on selected prompts, see [samples.md](samples.md).\n\n<table>\n    <tbody>\n        <tr>\n            <td align=\"center\">\n                <img src=\"samples/a_chair_that_looks_like_an_avocado/2.gif\" alt=\"A chair that looks like an avocado\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/an_airplane_that_looks_like_a_banana/3.gif\" alt=\"An airplane that looks like a banana\">\n            </td align=\"center\">\n            <td align=\"center\">\n                <img src=\"samples/a_spaceship/0.gif\" alt=\"A spaceship\">\n            </td>\n        </tr>\n        <tr>\n            <td align=\"center\">A chair that looks<br>like an avocado</td>\n            <td align=\"center\">An airplane that looks<br>like a banana</td>\n            <td align=\"center\">A spaceship</td>\n        </tr>\n        <tr>\n            <td align=\"center\">\n                <img src=\"samples/a_birthday_cupcake/3.gif\" alt=\"A birthday cupcake\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/a_chair_that_looks_like_a_tree/2.gif\" alt=\"A chair that looks like a tree\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/a_green_boot/3.gif\" alt=\"A green boot\">\n            </td>\n        </tr>\n        <tr>\n            <td align=\"center\">A birthday cupcake</td>\n            <td align=\"center\">A chair that looks<br>like a tree</td>\n            <td align=\"center\">A green boot</td>\n        </tr>\n        <tr>\n            <td align=\"center\">\n                <img src=\"samples/a_penguin/1.gif\" alt=\"A penguin\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/ube_ice_cream_cone/3.gif\" alt=\"Ube ice cream cone\">\n            </td>\n            <td align=\"center\">\n                <img src=\"samples/a_bowl_of_vegetables/2.gif\" alt=\"A bowl of vegetables\">\n            </td>\n        </tr>\n        <tr>\n            <td align=\"center\">A penguin</td>\n            <td align=\"center\">Ube ice cream cone</td>\n            <td align=\"center\">A bowl of vegetables</td>\n        </tr>\n    </tbody>\n<table>\n\n# Usage\n\nInstall with `pip install -e .`.\n\nTo get started with examples, see the following notebooks:\n\n* [sample_text_to_3d.ipynb](shap_e/examples/sample_text_to_3d.ipynb) - sample a 3D model, conditioned on a text prompt.\n* [sample_image_to_3d.ipynb](shap_e/examples/sample_image_to_3d.ipynb) - sample a 3D model, conditioned on a synthetic view image. To get the best result, you should remove background from the input image.\n* [encode_model.ipynb](shap_e/examples/encode_model.ipynb) - loads a 3D model or a trimesh, creates a batch of multiview renders and a point cloud, encodes them into a latent, and renders it back. For this to work, install Blender version 3.3.1 or higher, and set the environment variable `BLENDER_PATH` to the path of the Blender executable.\n",
        "releases": []
    }
}