{
    "https://api.github.com/repos/AUTOMATIC1111/stable-diffusion-webui": {
        "forks": 27396,
        "watchers": 146190,
        "stars": 146190,
        "languages": {
            "Python": 1840622,
            "JavaScript": 175861,
            "CSS": 44551,
            "HTML": 27503,
            "Shell": 13304,
            "Batchfile": 2631
        },
        "commits": [
            "2024-07-27T12:49:39Z",
            "2024-07-27T12:47:49Z",
            "2024-07-27T03:53:05Z",
            "2024-07-20T08:54:14Z",
            "2024-07-20T08:51:12Z",
            "2024-07-20T08:47:50Z",
            "2024-07-20T08:47:27Z",
            "2024-07-20T08:46:45Z",
            "2024-07-20T08:46:24Z",
            "2024-07-20T08:45:57Z",
            "2024-07-20T08:44:59Z",
            "2024-07-20T08:43:39Z",
            "2024-07-20T08:43:03Z",
            "2024-07-20T08:42:29Z",
            "2024-07-20T08:41:34Z",
            "2024-07-20T08:40:39Z",
            "2024-07-20T08:39:53Z",
            "2024-07-20T06:59:28Z",
            "2024-07-19T22:33:07Z",
            "2024-07-19T21:54:24Z",
            "2024-07-19T21:15:55Z",
            "2024-07-19T21:15:10Z",
            "2024-07-19T21:08:44Z",
            "2024-07-19T21:08:08Z",
            "2024-07-19T20:44:22Z",
            "2024-07-19T19:00:54Z",
            "2024-07-18T22:53:54Z",
            "2024-07-18T14:49:49Z",
            "2024-07-16T17:50:25Z",
            "2024-07-16T03:07:22Z"
        ],
        "creation_date": "2022-08-22T14:05:26Z",
        "contributors": 30,
        "topics": [
            "ai",
            "ai-art",
            "deep-learning",
            "diffusion",
            "gradio",
            "image-generation",
            "image2image",
            "img2img",
            "pytorch",
            "stable-diffusion",
            "text2image",
            "torch",
            "txt2img",
            "unstable",
            "upscaling",
            "web"
        ],
        "subscribers": 1101,
        "readme": "# Stable Diffusion web UI\r\nA web interface for Stable Diffusion, implemented using Gradio library.\r\n\r\n![](screenshot.png)\r\n\r\n## Features\r\n[Detailed feature showcase with images](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features):\r\n- Original txt2img and img2img modes\r\n- One click install and run script (but you still must install python and git)\r\n- Outpainting\r\n- Inpainting\r\n- Color Sketch\r\n- Prompt Matrix\r\n- Stable Diffusion Upscale\r\n- Attention, specify parts of text that the model should pay more attention to\r\n    - a man in a `((tuxedo))` - will pay more attention to tuxedo\r\n    - a man in a `(tuxedo:1.21)` - alternative syntax\r\n    - select text and press `Ctrl+Up` or `Ctrl+Down` (or `Command+Up` or `Command+Down` if you're on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)\r\n- Loopback, run img2img processing multiple times\r\n- X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters\r\n- Textual Inversion\r\n    - have as many embeddings as you want and use any names you like for them\r\n    - use multiple embeddings with different numbers of vectors per token\r\n    - works with half precision floating point numbers\r\n    - train embeddings on 8GB (also reports of 6GB working)\r\n- Extras tab with:\r\n    - GFPGAN, neural network that fixes faces\r\n    - CodeFormer, face restoration tool as an alternative to GFPGAN\r\n    - RealESRGAN, neural network upscaler\r\n    - ESRGAN, neural network upscaler with a lot of third party models\r\n    - SwinIR and Swin2SR ([see here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092)), neural network upscalers\r\n    - LDSR, Latent diffusion super resolution upscaling\r\n- Resizing aspect ratio options\r\n- Sampling method selection\r\n    - Adjust sampler eta values (noise multiplier)\r\n    - More advanced noise setting options\r\n- Interrupt processing at any time\r\n- 4GB video card support (also reports of 2GB working)\r\n- Correct seeds for batches\r\n- Live prompt token length validation\r\n- Generation parameters\r\n     - parameters you used to generate images are saved with that image\r\n     - in PNG chunks for PNG, in EXIF for JPEG\r\n     - can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI\r\n     - can be disabled in settings\r\n     - drag and drop an image/text-parameters to promptbox\r\n- Read Generation Parameters Button, loads parameters in promptbox to UI\r\n- Settings page\r\n- Running arbitrary python code from UI (must run with `--allow-code` to enable)\r\n- Mouseover hints for most UI elements\r\n- Possible to change defaults/mix/max/step values for UI elements via text config\r\n- Tiling support, a checkbox to create images that can be tiled like textures\r\n- Progress bar and live image generation preview\r\n    - Can use a separate neural network to produce previews with almost none VRAM or compute requirement\r\n- Negative prompt, an extra text field that allows you to list what you don't want to see in generated image\r\n- Styles, a way to save part of prompt and easily apply them via dropdown later\r\n- Variations, a way to generate same image but with tiny differences\r\n- Seed resizing, a way to generate same image but at slightly different resolution\r\n- CLIP interrogator, a button that tries to guess prompt from an image\r\n- Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway\r\n- Batch Processing, process a group of files using img2img\r\n- Img2img Alternative, reverse Euler method of cross attention control\r\n- Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions\r\n- Reloading checkpoints on the fly\r\n- Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one\r\n- [Custom scripts](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts) with many extensions from community\r\n- [Composable-Diffusion](https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/), a way to use multiple prompts at once\r\n     - separate prompts using uppercase `AND`\r\n     - also supports weights for prompts: `a cat :1.2 AND a dog AND a penguin :2.2`\r\n- No token limit for prompts (original stable diffusion lets you use up to 75 tokens)\r\n- DeepDanbooru integration, creates danbooru style tags for anime prompts\r\n- [xformers](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers), major speed increase for select cards: (add `--xformers` to commandline args)\r\n- via extension: [History tab](https://github.com/yfszzx/stable-diffusion-webui-images-browser): view, direct and delete images conveniently within the UI\r\n- Generate forever option\r\n- Training tab\r\n     - hypernetworks and embeddings options\r\n     - Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)\r\n- Clip skip\r\n- Hypernetworks\r\n- Loras (same as Hypernetworks but more pretty)\r\n- A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt\r\n- Can select to load a different VAE from settings screen\r\n- Estimated completion time in progress bar\r\n- API\r\n- Support for dedicated [inpainting model](https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion) by RunwayML\r\n- via extension: [Aesthetic Gradients](https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients), a way to generate images with a specific aesthetic by using clip images embeds (implementation of [https://github.com/vicgalle/stable-diffusion-aesthetic-gradients](https://github.com/vicgalle/stable-diffusion-aesthetic-gradients))\r\n- [Stable Diffusion 2.0](https://github.com/Stability-AI/stablediffusion) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20) for instructions\r\n- [Alt-Diffusion](https://arxiv.org/abs/2211.06679) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion) for instructions\r\n- Now without any bad letters!\r\n- Load checkpoints in safetensors format\r\n- Eased resolution restriction: generated image's dimensions must be a multiple of 8 rather than 64\r\n- Now with a license!\r\n- Reorder elements in the UI from settings screen\r\n- [Segmind Stable Diffusion](https://huggingface.co/segmind/SSD-1B) support\r\n\r\n## Installation and Running\r\nMake sure the required [dependencies](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies) are met and follow the instructions available for:\r\n- [NVidia](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs) (recommended)\r\n- [AMD](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs) GPUs.\r\n- [Intel CPUs, Intel GPUs (both integrated and discrete)](https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon) (external wiki page)\r\n- [Ascend NPUs](https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs) (external wiki page)\r\n\r\nAlternatively, use online services (like Google Colab):\r\n\r\n- [List of Online Services](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services)\r\n\r\n### Installation on Windows 10/11 with NVidia-GPUs using release package\r\n1. Download `sd.webui.zip` from [v1.0.0-pre](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre) and extract its contents.\r\n2. Run `update.bat`.\r\n3. Run `run.bat`.\r\n> For more details see [Install-and-Run-on-NVidia-GPUs](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs)\r\n\r\n### Automatic Installation on Windows\r\n1. Install [Python 3.10.6](https://www.python.org/downloads/release/python-3106/) (Newer version of Python does not support torch), checking \"Add Python to PATH\".\r\n2. Install [git](https://git-scm.com/download/win).\r\n3. Download the stable-diffusion-webui repository, for example by running `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git`.\r\n4. Run `webui-user.bat` from Windows Explorer as normal, non-administrator, user.\r\n\r\n### Automatic Installation on Linux\r\n1. Install the dependencies:\r\n```bash\r\n# Debian-based:\r\nsudo apt install wget git python3 python3-venv libgl1 libglib2.0-0\r\n# Red Hat-based:\r\nsudo dnf install wget git python3 gperftools-libs libglvnd-glx\r\n# openSUSE-based:\r\nsudo zypper install wget git python3 libtcmalloc4 libglvnd\r\n# Arch-based:\r\nsudo pacman -S wget git python3\r\n```\r\nIf your system is very new, you need to install python3.11 or python3.10:\r\n```bash\r\n# Ubuntu 24.04\r\nsudo add-apt-repository ppa:deadsnakes/ppa\r\nsudo apt update\r\nsudo apt install python3.11\r\n\r\n# Manjaro/Arch\r\nsudo pacman -S yay\r\nyay -S python311 # do not confuse with python3.11 package\r\n\r\n# Only for 3.11\r\n# Then set up env variable in launch script\r\nexport python_cmd=\"python3.11\"\r\n# or in webui-user.sh\r\npython_cmd=\"python3.11\"\r\n```\r\n2. Navigate to the directory you would like the webui to be installed and execute the following command:\r\n```bash\r\nwget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh\r\n```\r\nOr just clone the repo wherever you want:\r\n```bash\r\ngit clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\r\n```\r\n\r\n3. Run `webui.sh`.\r\n4. Check `webui-user.sh` for options.\r\n### Installation on Apple Silicon\r\n\r\nFind the instructions [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon).\r\n\r\n## Contributing\r\nHere's how to add code to this repo: [Contributing](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)\r\n\r\n## Documentation\r\n\r\nThe documentation was moved from this README over to the project's [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki).\r\n\r\nFor the purposes of getting Google and other search engines to crawl the wiki, here's a link to the (not for humans) [crawlable wiki](https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki).\r\n\r\n## Credits\r\nLicenses for borrowed code can be found in `Settings -> Licenses` screen, and also in `html/licenses.html` file.\r\n\r\n- Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref\r\n- k-diffusion - https://github.com/crowsonkb/k-diffusion.git\r\n- Spandrel - https://github.com/chaiNNer-org/spandrel implementing\r\n  - GFPGAN - https://github.com/TencentARC/GFPGAN.git\r\n  - CodeFormer - https://github.com/sczhou/CodeFormer\r\n  - ESRGAN - https://github.com/xinntao/ESRGAN\r\n  - SwinIR - https://github.com/JingyunLiang/SwinIR\r\n  - Swin2SR - https://github.com/mv-lab/swin2sr\r\n- LDSR - https://github.com/Hafiidz/latent-diffusion\r\n- MiDaS - https://github.com/isl-org/MiDaS\r\n- Ideas for optimizations - https://github.com/basujindal/stable-diffusion\r\n- Cross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.\r\n- Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)\r\n- Sub-quadratic Cross Attention layer optimization - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)\r\n- Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we're not using his code, but we are using his ideas).\r\n- Idea for SD upscale - https://github.com/jquesnelle/txt2imghd\r\n- Noise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot\r\n- CLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogator\r\n- Idea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch\r\n- xformers - https://github.com/facebookresearch/xformers\r\n- DeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooru\r\n- Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)\r\n- Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix\r\n- Security advice - RyotaK\r\n- UniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC\r\n- TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd\r\n- LyCORIS - KohakuBlueleaf\r\n- Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling\r\n- Hypertile - tfernd - https://github.com/tfernd/HyperTile\r\n- Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.\r\n- (You)\r\n",
        "releases": [
            {
                "name": "1.10.0",
                "date": "2024-07-27T03:55:24Z"
            },
            {
                "name": "1.10.0-RC",
                "date": "2024-07-06T08:28:39Z"
            },
            {
                "name": "1.9.4",
                "date": "2024-05-28T18:21:30Z"
            },
            {
                "name": "1.9.3",
                "date": "2024-04-22T15:03:02Z"
            },
            {
                "name": "1.9.0",
                "date": "2024-04-13T03:40:16Z"
            },
            {
                "name": "1.9.0-RC",
                "date": "2024-04-06T18:49:00Z"
            },
            {
                "name": "1.8.0",
                "date": "2024-03-02T04:08:18Z"
            },
            {
                "name": "1.8.0-RC",
                "date": "2024-02-17T08:50:56Z"
            },
            {
                "name": "1.7.0",
                "date": "2023-12-16T07:01:59Z"
            },
            {
                "name": "1.7.0-RC",
                "date": "2023-12-04T06:40:49Z"
            },
            {
                "name": "1.6.0",
                "date": "2023-08-31T04:40:36Z"
            },
            {
                "name": "1.6.0-RC",
                "date": "2023-08-24T08:19:18Z"
            },
            {
                "name": "1.5.2",
                "date": "2023-08-23T12:57:10Z"
            },
            {
                "name": "1.5.1",
                "date": "2023-07-27T06:04:31Z"
            },
            {
                "name": "1.5.1-RC",
                "date": "2023-07-25T13:32:54Z"
            },
            {
                "name": "1.5.0",
                "date": "2023-07-25T05:21:57Z"
            },
            {
                "name": "1.5.0-RC",
                "date": "2023-07-18T15:25:13Z"
            },
            {
                "name": "1.4.0",
                "date": "2023-06-27T05:40:25Z"
            },
            {
                "name": "1.4.0-RC",
                "date": "2023-06-09T19:51:14Z"
            },
            {
                "name": "1.3.2",
                "date": "2023-06-05T03:17:04Z"
            },
            {
                "name": "1.3.1",
                "date": "2023-06-01T18:37:48Z"
            },
            {
                "name": "",
                "date": "2023-05-27T17:24:28Z"
            },
            {
                "name": "1.2.1",
                "date": "2023-05-14T10:37:25Z"
            },
            {
                "name": "1.2.0",
                "date": "2023-05-13T05:21:55Z"
            },
            {
                "name": "1.1.0",
                "date": "2023-05-01T11:36:52Z"
            },
            {
                "name": "v1.0.0-pre",
                "date": "2023-01-24T19:20:02Z"
            }
        ]
    }
}