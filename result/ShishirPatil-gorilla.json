{
    "https://api.github.com/repos/ShishirPatil/gorilla": {
        "forks": 1035,
        "watchers": 11709,
        "stars": 11709,
        "languages": {
            "Python": 1423597,
            "Jupyter Notebook": 422759,
            "JavaScript": 179796,
            "CSS": 5525,
            "Rust": 3380,
            "Scheme": 2111,
            "Shell": 1829,
            "HTML": 973,
            "C++": 869,
            "Dockerfile": 166
        },
        "commits": [
            "2025-01-21T00:04:51Z",
            "2025-01-19T06:32:20Z",
            "2025-01-18T00:13:24Z",
            "2025-01-16T01:46:32Z",
            "2025-01-16T01:38:08Z",
            "2025-01-16T01:35:17Z",
            "2025-01-15T16:11:19Z",
            "2025-01-12T02:45:40Z",
            "2025-01-11T09:14:33Z",
            "2025-01-05T17:36:22Z",
            "2025-01-05T03:16:42Z",
            "2025-01-04T06:03:59Z",
            "2025-01-03T07:52:31Z",
            "2025-01-03T05:40:43Z",
            "2024-12-29T12:17:57Z",
            "2024-12-29T12:17:20Z",
            "2024-12-26T10:50:31Z",
            "2024-12-25T14:49:18Z",
            "2024-12-22T14:59:03Z",
            "2024-12-22T03:20:53Z",
            "2024-12-21T13:47:18Z",
            "2024-12-21T13:36:53Z",
            "2024-12-20T12:12:11Z",
            "2024-12-20T07:16:26Z",
            "2024-12-19T06:10:38Z",
            "2024-12-19T04:51:09Z",
            "2024-12-18T02:05:45Z",
            "2024-12-14T01:35:18Z",
            "2024-12-13T21:41:45Z",
            "2024-12-11T09:18:25Z"
        ],
        "creation_date": "2023-05-19T00:46:45Z",
        "contributors": 30,
        "topics": [
            "api",
            "api-documentation",
            "chatgpt",
            "claude-api",
            "gpt-4-api",
            "llm",
            "openai-api",
            "openai-functions"
        ],
        "subscribers": 98,
        "readme": "# Gorilla: Large Language Model Connected with Massive APIs\n\n<div align=\"center\">\n  <img src=\"https://github.com/ShishirPatil/gorilla/blob/gh-pages/assets/img/logo.png\" width=\"50%\" height=\"50%\">\n</div>\n\n<div align=\"center\">\n  \n[![Arxiv](https://img.shields.io/badge/Gorilla_Paper-2305.15334-<COLOR>.svg?style=flat-square)](https://arxiv.org/abs/2305.15334) [![Discord](https://img.shields.io/discord/1111172801899012102?label=Discord&logo=discord&logoColor=green&style=flat-square)](https://discord.gg/grXXvj9Whz) [![Gorilla Website](https://img.shields.io/badge/Website-gorilla.cs.berkeley.edu-blue?style=flat-square)](https://gorilla.cs.berkeley.edu/) [![Gorilla Blog](https://img.shields.io/badge/Blog-gorilla.cs.berkeley.edu/blog.html-blue?style=flat-square)](https://gorilla.cs.berkeley.edu/blog.html) [![Hugging Face](https://img.shields.io/badge/\ud83e\udd17-gorilla--llm-yellow.svg?style=flat-square)](https://huggingface.co/gorilla-llm)\n\n</div>\n\n## Latest Updates\n> \ud83d\udce2 Check out our detailed [Berkeley Function Calling Leaderboard changelog](/berkeley-function-call-leaderboard/CHANGELOG.md) (Last updated: ![Last Updated](https://img.shields.io/github/last-commit/ShishirPatil/gorilla?path=berkeley-function-call-leaderboard/CHANGELOG.md)) for the latest dataset / model updates to the Berkeley Function Calling Leaderboard!\n\n\n- \ud83c\udfaf [10/04/2024] Introducing the Agent Arena by Gorilla X LMSYS Chatbot Arena! Compare different agents in tasks like search, finance, RAG, and beyond. Explore which models and tools work best for specific tasks through our novel ranking system and community-driven prompt hub. [[Blog](https://gorilla.cs.berkeley.edu/blogs/14_agent_arena.html)] [[Arena](http://agent-arena.com)] [[Leaderboard](http://agent-arena.com/leaderboard)] [[Dataset](https://github.com/ShishirPatil/gorilla/tree/main/agent-arena#evaluation-directory)] [[Tweet](https://x.com/shishirpatil_/status/1841876885757977044)]\n\n- \ud83d\udce3 [09/21/2024] Announcing BFCL V3 - Evaluating multi-turn and multi-step function calling capabilities! New state-based evaluation system tests models on handling complex workflows, sequential functions, and service states. [[Blog](https://gorilla.cs.berkeley.edu/blogs/13_bfcl_v3_multi_turn.html)] [[Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html)] [[Code](https://github.com/ShishirPatil/gorilla/tree/main/berkeley-function-call-leaderboard)] [[Tweet](https://x.com/shishirpatil_/status/1837205152132153803)]\n\n- \ud83d\ude80 [08/20/2024] Released BFCL V2 \u2022 Live! The Berkeley Function-Calling Leaderboard now features enterprise-contributed data and real-world scenarios. [[Blog](https://gorilla.cs.berkeley.edu/blogs/12_bfcl_v2_live.html)] [[Live Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard_live.html)] [[V2 Categories Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard.html)] [[Tweet](https://x.com/shishirpatil_/status/1825577931697233999)]\n\n- \u26a1\ufe0f [04/12/2024] Excited to release GoEx - a runtime for LLM-generated actions like code, API calls, and more. Featuring \"post-facto validation\" for assessing LLM actions after execution, \"undo\" and \"damage confinement\" abstractions to manage unintended actions & risks. This paves the way for fully autonomous LLM agents, enhancing interaction between apps & services with human-out-of-loop. [[Blog](https://gorilla.cs.berkeley.edu/blogs/10_gorilla_exec_engine.html)] [[Code](https://github.com/ShishirPatil/gorilla/tree/main/goex)] [[Paper](https://arxiv.org/abs/2404.06921)] [[Tweet](https://x.com/shishirpatil_/status/1778485140257452375)]\n\n- \u23f0 [04/01/2024] Introducing cost and latency metrics into [Berkeley function calling leaderboard](https://gorilla.cs.berkeley.edu/leaderboard)!\n- :rocket: [03/15/2024] RAFT: Adapting Language Model to Domain Specific RAG is live! [[MSFT-Meta blog](https://techcommunity.microsoft.com/t5/ai-ai-platform-blog/bg-p/AIPlatformBlog)] [[Berkeley Blog](https://gorilla.cs.berkeley.edu/blogs/9_raft.html)]\n- :trophy: [02/26/2024] [Berkeley Function Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard) is live!\n- :dart: [02/25/2024] [OpenFunctions v2](https://gorilla.cs.berkeley.edu/blogs/7_open_functions_v2.html) sets new SoTA for open-source LLMs!\n- :fire: [11/16/2023] Excited to release [Gorilla OpenFunctions](https://gorilla.cs.berkeley.edu/blogs/4_open_functions.html)\n- \ud83d\udcbb [06/29/2023] Released [gorilla-cli](https://github.com/gorilla-llm/gorilla-cli), LLMs for your CLI!\n- \ud83d\udfe2 [06/06/2023] Released Commercially usable, Apache 2.0 licensed Gorilla models\n- :rocket: [05/30/2023] Provided the [CLI interface](inference/README.md) to chat with Gorilla!\n- :rocket: [05/28/2023] Released Torch Hub and TensorFlow Hub Models!\n- :rocket: [05/27/2023] Released the first Gorilla model! [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP?usp=sharing) or [:hugs:](https://huggingface.co/gorilla-llm/gorilla-7b-hf-delta-v0)!\n- :fire: [05/27/2023] We released the APIZoo contribution guide for community API contributions!\n- :fire: [05/25/2023] We release the APIBench dataset and the evaluation code of Gorilla!\n\n\n## About\n\n**Gorilla enables LLMs to use tools by invoking APIs. Given a natural language query, Gorilla comes up with the semantically- and syntactically- correct API to invoke.** \n\nWith Gorilla, we are the first to demonstrate how to use LLMs to invoke 1,600+ (and growing) API calls accurately while reducing hallucination. This repository contains [inference code](/gorilla/inference) for running Gorilla finetuned models, [evaluation code](/gorilla/eval) for reproducing results from our paper, and [APIBench](/data) - the largest collection of APIs, curated and easy to be trained on!\n\nSince our initial release, we've served ~500k requests and witnessed incredible adoption by developers worldwide. The project has expanded to include tools, evaluations, leaderboard, end-to-end finetuning recipes, infrastructure components, and the Gorilla API Store:\n\n| Project | Type | Description (click to expand) |\n|---------|------|---------------------------|\n| [Gorilla Paper](https://arxiv.org/abs/2305.15334) | \ud83e\udd16 Model<br>\ud83d\udcdd Fine-tuning<br>\ud83d\udcda Dataset<br>\ud83d\udcca Evaluation<br>\ud83d\udd27 Infra | <details><summary>Large Language Model Connected with Massive APIs</summary>\u2022 Novel finetuning approach for API invocation<br>\u2022 Evaluation on 1,600+ APIs (APIBench)<br>\u2022 Retrieval-augmented training for test-time adaptation |\n| [Gorilla OpenFunctions-V2](openfunctions/) | \ud83e\udd16 Model | <details><summary>Drop-in alternative for function calling, supporting multiple complex data types and parallel execution</summary>\u2022 Multiple & parallel function execution with OpenAI-compatible endpoints<br>\u2022 Native support for Python, Java, JavaScript, and REST APIs with expanded data types<br>\u2022 Function relevance detection to reduce hallucinations<br>\u2022 Enhanced RESTful API formatting capabilities<br>\u2022 State-of-the-art performance among open-source models</details> |\n| [Berkeley Function Calling Leaderboard (BFCL)](berkeley-function-call-leaderboard/) | \ud83d\udcca Evaluation<br>\ud83c\udfc6 Leaderboard<br>\ud83d\udd27 Function Calling Infra<br>\ud83d\udcda Dataset | <details><summary>Comprehensive evaluation of function-calling capabilities</summary>\u2022 V1: Expert-curated dataset for evaluating single-turn function calling<br>\u2022 V2: Enterprise-contributed data for real-world scenarios<br>\u2022 V3: Multi-turn & multi-step function calling evaluation<br>\u2022 Cost and latency metrics for all models<br>\u2022 Interactive API explorer for testing<br>\u2022 Community-driven benchmarking platform</details> |\n| [Agent Arena](agent-arena/) | \ud83d\udcca Evaluation<br>\ud83c\udfc6 Leaderboard | <details><summary>Compare LLM agents across models, tools, and frameworks</summary>\u2022 Head-to-head agent comparisons with ELO rating system<br>\u2022 Framework compatibility testing (LangChain, AutoGPT)<br>\u2022 Community-driven evaluation platform<br>\u2022 Real-world task performance metrics</details> |\n| [Gorilla Execution Engine (GoEx)](goex/) | \ud83d\udd27 Infra | <details><summary>Runtime for executing LLM-generated actions with safety guarantees</summary>\u2022 Post-facto validation for verifying LLM actions after execution<br>\u2022 Undo capabilities and damage confinement for risk mitigation<br>\u2022 OAuth2 and API key authentication for multiple services<br>\u2022 Support for RESTful APIs, databases, and filesystem operations<br>\u2022 Docker-based sandboxed execution environment</details> |\n| [Retrieval-Augmented Fine-tuning (RAFT)](raft/) | \ud83d\udcdd Fine-tuning<br>\ud83e\udd16 Model | <details><summary>Fine-tuning LLMs for robust domain-specific retrieval</summary>\u2022 Novel fine-tuning recipe for domain-specific RAG<br>\u2022 Chain-of-thought answers with direct document quotes<br>\u2022 Training with oracle and distractor documents<br>\u2022 Improved performance on PubMed, HotpotQA, and Gorilla benchmarks<br>\u2022 Efficient adaptation of smaller models for domain QA</details> |\n| [Gorilla CLI](https://github.com/gorilla-llm/gorilla-cli) | \ud83e\udd16 Model<br>\ud83d\udd27 Local CLI Infra | <details><summary>LLMs for your command-line interface</summary>\u2022 User-friendly CLI tool supporting ~1500 APIs (Kubernetes, AWS, GCP, etc.)<br>\u2022 Natural language command generation with multi-LLM fusion<br>\u2022 Privacy-focused with explicit execution approval<br>\u2022 Command history and interactive selection interface</details> |\n| [Gorilla API Zoo](apizoo/) | \ud83d\udcda Dataset | <details><summary>A community-maintained repository of up-to-date API documentation</summary>\u2022 Centralized, searchable index of APIs across domains<br>\u2022 Structured documentation format with arguments, versioning, and examples<br>\u2022 Community-driven updates to keep pace with API changes<br>\u2022 Rich data source for model training and fine-tuning<br>\u2022 Enables retrieval-augmented training and inference<br>\u2022 Reduces hallucination through up-to-date documentation</details> |\n\n## Getting Started\n\n### Quick Start\nTry Gorilla in your browser:\n- \ud83d\ude80 [Gorilla Colab Demo](https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP?usp=sharing): Try the base Gorilla model\n- \ud83c\udf10 [Gorilla Gradio Demo](https://huggingface.co/spaces/gorilla-llm/gorilla-demo/): Interactive web interface\n- \ud83d\udd25 [OpenFunctions Colab Demo](https://colab.research.google.com/drive/16M5J2H9F8YQora_W2PDnp120slZH-Mqd?usp=sharing): Try the latest OpenFunctions model\n- \ud83c\udfaf [OpenFunctions Website Demo](https://gorilla.cs.berkeley.edu/leaderboard.html#api-explorer): Experiment with function calling\n- \ud83d\udcca [Berkeley Function Calling Leaderboard](https://gorilla.cs.berkeley.edu/leaderboard): Compare function calling capabilities\n\n### Installation Options\n\n1. **Gorilla CLI** - Fastest way to get started\n```bash\npip install gorilla-cli\ngorilla generate 100 random characters into a file called test.txt\n```\n[Learn more about Gorilla CLI \u2192](https://github.com/gorilla-llm/gorilla-cli)\n\n2. **Run Gorilla Locally**\n```bash\ngit clone https://github.com/ShishirPatil/gorilla.git\ncd gorilla/inference\n```\n[Detailed local setup instructions \u2192](/gorilla/inference/README.md)\n\n3. **Use OpenFunctions**\n```python\nimport openai\n\nopenai.api_key = \"EMPTY\"\nopenai.api_base = \"http://luigi.millennium.berkeley.edu:8000/v1\"\n\n# Define your functions\nfunctions = [{\n    \"name\": \"get_current_weather\",\n    \"description\": \"Get weather in a location\",\n    \"parameters\": {\n        \"type\": \"object\",\n        \"properties\": {\n            \"location\": {\"type\": \"string\"},\n            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]}\n        },\n        \"required\": [\"location\"]\n    }\n}]\n\n# Make API call\ncompletion = openai.ChatCompletion.create(\n    model=\"gorilla-openfunctions-v2\",\n    messages=[{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}],\n    functions=functions\n)\n```\n[OpenFunctions documentation \u2192](/openfunctions/README.md)\n\n### \ud83d\udd27 Other Quick Starts\n\n- \ud83d\udcca **Evaluation & Benchmarking**\n  - [Berkeley Function Calling Leaderboard](/berkeley-function-call-leaderboard/README.md): Compare function calling capabilities\n  - [Agent Arena](/agent-arena/README.md): Evaluate agent workflows\n  - [Gorilla Paper Evaluation Scripts](/gorilla/eval/README.md): Run your own evaluations\n\n- \ud83d\udee0\ufe0f **Development Tools**\n  - [GoEx](/goex/README.md): Safe execution of LLM-generated actions\n  - [RAFT](/raft/README.md): Fine-tune models for domain-specific tasks\n  - [API Store](/data/README.md): Contribute and use APIs\n\n\n## Frequently Asked Questions\n1. I would like to use Gorilla commercially. Is there going to be an Apache 2.0 licensed version?\n\nYes! We now have models that you can use commercially without any obligations.\n\n\n2. Can we use Gorilla with other tools like Langchain etc?\n\nAbsolutely! You've highlighted a great aspect of our tools. Gorilla is  an  end-to-end model, specifically tailored to serve correct API calls (tools) without requiring any additional coding. It's designed to work as part of a wider ecosystem and can be flexibly integrated within agentic frameworks and other tools.\n\nLangchain, is a versatile developer tool. Its \"agents\" can efficiently swap in any LLM, Gorilla included, making it a highly adaptable solution for various needs.\n\nThe beauty of these tools truly shines when they collaborate, complementing each other's strengths and capabilities to create an even more powerful and comprehensive solution. This is where your contribution can make a difference. We enthusiastically welcome any inputs to further refine and enhance these tools. \n\nCheck out our blog on [How to Use Gorilla: A Step-by-Step Walkthrough](https://gorilla.cs.berkeley.edu/blogs/5_how_to_gorilla.html) to see all the different ways you can integrate Gorilla in your projects.\n\n## Project Roadmap\nIn the immediate future, we plan to release the following:\n\n- [ ] Multimodal function-calling leaderboard\n- [ ] Agentic function-calling leaderboard\n- [ ] New batch of user contributed live function calling evals. \n- [ ] BFCL metrics to evaluate contamination\n- [ ] Openfunctions-v3 model to support more languages and multi-turn capability\n- [x] Agent Arena to compare LLM agents across models, tools, and frameworks [10/04/2024]\n- [x] Multi-turn and multi-step function calling evaluation [09/21/2024]\n- [x] User contributed Live Function Calling Leaderboard [08/20/2024]\n- [x] BFCL systems metrics including cost and latency [04/01/2024]\n- [x] Gorilla Execution Engine (GoEx) - Runtime for executing LLM-generated actions with safety guarantees [04/12/2024]\n- [x] Berkeley Function Calling leaderboard (BFCL) for evaluating tool-calling/function-calling models [02/26/2024]\n- [x] Openfunctions-v2 with more languages (Java, JS, Python), relevance detection [02/26/2024]\n- [x] API Zoo Index for easy access to all APIs [02/16/2024]\n- [x] Openfunctions-v1, Apache 2.0, with parallel and multiple function calling [11/16/2023]\n- [x] Openfunctions-v0, Apache 2.0 function calling model [11/16/2023]\n- [X] Release a commercially usable, Apache 2.0 licensed Gorilla model [06/05/2023] \n- [X] Release weights for all APIs from APIBench [05/28/2023]\n- [X] Run Gorilla LLM locally [05/28/2023]\n- [X] Release weights for HF model APIs [05/27/2023]\n- [X] Hosted Gorilla LLM chat for HF model APIs [05/27/2023]\n- [X] Opening up the APIZoo for contributions from community\n- [X] Dataset and Eval Code\n\n## License\n\nGorilla is Apache 2.0 licensed, making it suitable for both academic and commercial use.\n\n## Contact\n\n- \ud83d\udcac Join our [Discord Community](https://discord.gg/grXXvj9Whz)\n- \ud83d\udc26 Follow us on [X](https://x.com/shishirpatil_)\n\n## Citation\n\n```text\n@article{patil2023gorilla,\n  title={Gorilla: Large Language Model Connected with Massive APIs},\n  author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},\n  year={2023},\n  journal={arXiv preprint arXiv:2305.15334},\n} \n```\n",
        "releases": [
            {
                "name": "Berkeley Function Calling Leaderboard Updates (v1.2)",
                "date": "2025-01-05T04:39:54Z"
            },
            {
                "name": "Berkeley Function Calling Leaderboard Updates (v1.1)",
                "date": "2024-08-27T06:13:22Z"
            },
            {
                "name": "Berkeley Function Calling Leaderboard Updates (v1.0)",
                "date": "2024-08-15T04:35:13Z"
            },
            {
                "name": "GoEx and Berkeley Function Calling Leaderboard Updates",
                "date": "2024-06-05T05:43:19Z"
            },
            {
                "name": "RAFT and Berkeley Function Calling Leaderboard Updates",
                "date": "2024-04-11T03:38:11Z"
            },
            {
                "name": "Gorilla v0.1: OpenFunctions-v2, Berkeley Function Calling Leaderboard, and more.",
                "date": "2024-03-12T07:56:58Z"
            },
            {
                "name": "Gorilla release v0.0.1",
                "date": "2023-07-18T08:14:15Z"
            }
        ]
    }
}