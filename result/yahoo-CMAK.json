{
    "https://api.github.com/repos/yahoo/CMAK": {
        "forks": 2509,
        "watchers": 11858,
        "stars": 11858,
        "languages": {
            "Scala": 935774,
            "HTML": 141311,
            "Shell": 21675,
            "CSS": 5799,
            "JavaScript": 4693,
            "Less": 1379
        },
        "commits": [
            "2022-12-12T20:20:56Z",
            "2022-12-12T20:18:32Z",
            "2022-12-12T20:17:22Z",
            "2022-07-29T09:15:55Z",
            "2022-07-15T11:13:25Z",
            "2022-04-28T23:01:12Z",
            "2022-04-28T22:50:52Z",
            "2022-04-28T21:52:13Z",
            "2022-04-28T19:01:46Z",
            "2022-04-28T18:54:39Z",
            "2022-04-27T23:10:58Z",
            "2022-04-27T23:09:43Z",
            "2022-03-17T22:05:43Z",
            "2022-03-01T02:17:32Z",
            "2021-12-07T22:12:15Z",
            "2021-10-19T01:12:42Z",
            "2021-08-12T17:15:35Z",
            "2021-07-29T11:43:07Z",
            "2021-07-29T10:42:10Z",
            "2021-07-29T07:04:11Z",
            "2021-07-29T07:03:54Z",
            "2021-07-29T05:51:21Z",
            "2021-07-29T04:31:22Z",
            "2021-07-29T03:18:00Z",
            "2021-07-28T10:25:35Z",
            "2021-07-28T10:04:10Z",
            "2021-07-27T07:26:31Z",
            "2021-07-27T05:18:31Z",
            "2021-07-27T03:13:20Z",
            "2021-07-27T03:13:07Z"
        ],
        "creation_date": "2015-01-28T18:33:21Z",
        "contributors": 30,
        "topics": [
            "big-data",
            "cluster-management",
            "kafka",
            "scala"
        ],
        "subscribers": 528,
        "readme": "CMAK (Cluster Manager for Apache Kafka, previously known as Kafka Manager)\n=============\n\nCMAK (previously known as Kafka Manager) is a tool for managing [Apache Kafka](http://kafka.apache.org) clusters.\n_See below for details about the name change._\n\nCMAK supports the following:\n\n - Manage multiple clusters\n - Easy inspection of cluster state (topics, consumers, offsets, brokers, replica distribution, partition distribution)\n - Run preferred replica election\n - Generate partition assignments with option to select brokers to use\n - Run reassignment of partition (based on generated assignments)\n - Create a topic with optional topic configs (0.8.1.1 has different configs than 0.8.2+)\n - Delete topic (only supported on 0.8.2+ and remember set delete.topic.enable=true in broker config)\n - Topic list now indicates topics marked for deletion (only supported on 0.8.2+)\n - Batch generate partition assignments for multiple topics with option to select brokers to use\n - Batch run reassignment of partition for multiple topics\n - Add partitions to existing topic\n - Update config for existing topic\n - Optionally enable JMX polling for broker level and topic level metrics.\n - Optionally filter out consumers that do not have ids/ owners/ & offsets/ directories in zookeeper.\n\nCluster Management\n\n![cluster](/img/cluster.png)\n\n***\n\nTopic List\n\n![topic](/img/topic-list.png)\n\n***\n\nTopic View\n\n![topic](/img/topic.png)\n\n***\n\nConsumer List View\n\n![consumer](/img/consumer-list.png)\n\n***\n\nConsumed Topic View\n\n![consumer](/img/consumed-topic.png)\n\n***\n\nBroker List\n\n![broker](/img/broker-list.png)\n\n***\n\nBroker View\n\n![broker](/img/broker.png)\n\n***\n\nRequirements\n------------\n\n1. [Kafka 0.8.*.* or 0.9.*.* or 0.10.*.* or 0.11.*.*](http://kafka.apache.org/downloads.html)\n2. Java 11+\n\nConfiguration\n-------------\n\nThe minimum configuration is the zookeeper hosts which are to be used for CMAK (pka kafka manager) state.\nThis can be found in the application.conf file in conf directory.  The same file will be packaged\nin the distribution zip file; you may modify settings after unzipping the file on the desired server.\n\n    cmak.zkhosts=\"my.zookeeper.host.com:2181\"\n\nYou can specify multiple zookeeper hosts by comma delimiting them, like so:\n\n    cmak.zkhosts=\"my.zookeeper.host.com:2181,other.zookeeper.host.com:2181\"\n\nAlternatively, use the environment variable `ZK_HOSTS` if you don't want to hardcode any values.\n\n    ZK_HOSTS=\"my.zookeeper.host.com:2181\"\n\nYou can optionally enable/disable the following functionality by modifying the default list in application.conf :\n\n    application.features=[\"KMClusterManagerFeature\",\"KMTopicManagerFeature\",\"KMPreferredReplicaElectionFeature\",\"KMReassignPartitionsFeature\"]\n\n - KMClusterManagerFeature - allows adding, updating, deleting cluster from CMAK (pka Kafka Manager)\n - KMTopicManagerFeature - allows adding, updating, deleting topic from a Kafka cluster\n - KMPreferredReplicaElectionFeature - allows running of preferred replica election for a Kafka cluster\n - KMReassignPartitionsFeature - allows generating partition assignments and reassigning partitions\n\nConsider setting these parameters for larger clusters with jmx enabled :\n\n - cmak.broker-view-thread-pool-size=< 3 * number_of_brokers>\n - cmak.broker-view-max-queue-size=< 3 * total # of partitions across all topics>\n - cmak.broker-view-update-seconds=< cmak.broker-view-max-queue-size / (10 * number_of_brokers) >\n\nHere is an example for a kafka cluster with 10 brokers, 100 topics, with each topic having 10 partitions giving 1000 total partitions with JMX enabled :\n\n - cmak.broker-view-thread-pool-size=30\n - cmak.broker-view-max-queue-size=3000\n - cmak.broker-view-update-seconds=30\n\nThe follow control consumer offset cache's thread pool and queue :\n\n - cmak.offset-cache-thread-pool-size=< default is # of processors>\n - cmak.offset-cache-max-queue-size=< default is 1000>\n - cmak.kafka-admin-client-thread-pool-size=< default is # of processors>\n - cmak.kafka-admin-client-max-queue-size=< default is 1000>\n\nYou should increase the above for large # of consumers with consumer polling enabled.  Though it mainly affects ZK based consumer polling.\n\nKafka managed consumer offset is now consumed by KafkaManagedOffsetCache from the \"__consumer_offsets\" topic.  Note, this has not been tested with large number of offsets being tracked.  There is a single thread per cluster consuming this topic so it may not be able to keep up on large # of offsets being pushed to the topic.\n\n### Authenticating a User with LDAP\nWarning, you need to have SSL configured with CMAK (pka Kafka Manager) to ensure your credentials aren't passed unencrypted.\nAuthenticating a User with LDAP is possible by passing the user credentials with the Authorization header.\nLDAP authentication is done on first visit, if successful, a cookie is set.\nOn next request, the cookie value is compared with credentials from Authorization header.\nLDAP support is through the basic authentication filter.\n\n1. Configure basic authentication\n- basicAuthentication.enabled=true\n- basicAuthentication.realm=< basic authentication realm>\n\n2. Encryption parameters (optional, otherwise randomly generated on startup) :\n- basicAuthentication.salt=\"some-hex-string-representing-byte-array\"\n- basicAuthentication.iv=\"some-hex-string-representing-byte-array\"\n- basicAuthentication.secret=\"my-secret-string\"\n\n3. Configure LDAP / LDAP + StartTLS / LDAPS authentication\n\n_Note: LDAP is unencrypted and insecure. LDAPS is a commonly implemented \nextension that implements an encryption layer in a manner similar to how \nHTTPS adds encryption to an HTTP. LDAPS has not been documented, and the \nspecification is not formally defined anywhere. LDAP + StartTLS is the \ncurrently recommended way to start an encrypted channel, and it upgrades \nan existing LDAP connection to achieve this encryption._\n\n- basicAuthentication.ldap.enabled=< Boolean flag to enable/disable ldap authentication >\n- basicAuthentication.ldap.server=< fqdn of LDAP server >\n- basicAuthentication.ldap.port=< port of LDAP server (typically 389 for LDAP and LDAP + StartTLS and typically 636 for LDAPS) >\n- basicAuthentication.ldap.username=< LDAP search username >\n- basicAuthentication.ldap.password=< LDAP search password >\n- basicAuthentication.ldap.search-base-dn=< LDAP search base >\n- basicAuthentication.ldap.search-filter=< LDAP search filter >\n- basicAuthentication.ldap.connection-pool-size=< maximum number of connection to LDAP server >\n- basicAuthentication.ldap.ssl=< Boolean flag to enable/disable LDAPS (usually incompatible with StartTLS) >\n- basicAuthentication.ldap.starttls=< Boolean flat to enable StartTLS (usually incompatible with SSL) >\n\n4. (Optional) Limit access to a specific LDAP Group\n- basicAuthentication.ldap.group-filter=< LDAP group filter >\n- basicAuthentication.ldap.ssl-trust-all=< Boolean flag to allow non-expired invalid certificates >\n\n#### Example (Online LDAP Test Server):\n\n- basicAuthentication.ldap.enabled=true\n- basicAuthentication.ldap.server=\"ldap.forumsys.com\"\n- basicAuthentication.ldap.port=389\n- basicAuthentication.ldap.username=\"cn=read-only-admin,dc=example,dc=com\"\n- basicAuthentication.ldap.password=\"password\"\n- basicAuthentication.ldap.search-base-dn=\"dc=example,dc=com\"\n- basicAuthentication.ldap.search-filter=\"(uid=$capturedLogin$)\"\n- basicAuthentication.ldap.group-filter=\"cn=allowed-group,ou=groups,dc=example,dc=com\"\n- basicAuthentication.ldap.connection-pool-size=10\n- basicAuthentication.ldap.ssl=false\n- basicAuthentication.ldap.ssl-trust-all=false\n- basicAuthetication.ldap.starttls=false\n\n\nDeployment\n----------\n\nThe command below will create a zip file which can be used to deploy the application.\n\n    ./sbt clean dist\n\nPlease refer to play framework documentation on [production deployment/configuration](https://www.playframework.com/documentation/2.4.x/ProductionConfiguration).\n\nIf java is not in your path, or you need to build against a specific java version,\nplease use the following (the example assumes zulu java11):\n\n    $ PATH=/usr/lib/jvm/zulu-11-amd64/bin:$PATH \\\n      JAVA_HOME=/usr/lib/jvm/zulu-11-amd64 \\\n      /path/to/sbt -java-home /usr/lib/jvm/zulu-11-amd64 clean dist\n\nThis ensures that the 'java' and 'javac' binaries in your path are first looked up in the\ncorrect location. Next, for all downstream tools that only listen to JAVA_HOME, it points\nthem to the java11 location. Lastly, it tells sbt to use the java11 location as\nwell.\n\nStarting the service\n--------------------\n\nAfter extracting the produced zipfile, and changing the working directory to it, you can\nrun the service like this:\n\n    $ bin/cmak\n\nBy default, it will choose port 9000. This is overridable, as is the location of the\nconfiguration file. For example:\n\n    $ bin/cmak -Dconfig.file=/path/to/application.conf -Dhttp.port=8080\n\nAgain, if java is not in your path, or you need to run against a different version of java,\nadd the -java-home option as follows:\n\n    $ bin/cmak -java-home /usr/lib/jvm/zulu-11-amd64\n\nStarting the service with Security\n----------------------------------\n\nTo add JAAS configuration for SASL, add the config file location at start:\n\n    $ bin/cmak -Djava.security.auth.login.config=/path/to/my-jaas.conf\n\nNOTE: Make sure the user running CMAK (pka kafka manager) has read permissions on the jaas config file\n\n\nPackaging\n---------\n\nIf you'd like to create a Debian or RPM package instead, you can run one of:\n\n    sbt debian:packageBin\n\n    sbt rpm:packageBin\n\nCredits\n-------\n\nMost of the utils code has been adapted to work with [Apache Curator](http://curator.apache.org) from [Apache Kafka](http://kafka.apache.org).\n\nName and Management\n-------\n\nCMAK was renamed from its previous name due to [this issue](https://github.com/yahoo/kafka-manager/issues/713). CMAK is designed to be used with Apache Kafka and is offered to support the needs of the Kafka community. This project is currently managed by employees at Verizon Media and the community who supports this project. \n\nLicense\n-------\n\nLicensed under the terms of the Apache License 2.0. See accompanying LICENSE file for terms.\n\nConsumer/Producer Lag\n-------\n\nProducer offset is polled.  Consumer offset is read from the offset topic for Kafka based consumers.  This means the reported lag may be negative since we are consuming offset from the offset topic faster then polling the producer offset.  This is normal and not a problem.\n\nMigration from Kafka Manager to CMAK\n-------\n\n1. Copy config files from old version to new version (application.conf, consumer.properties)\n2. Change start script to use bin/cmak instead of bin/kafka-manager\n\n",
        "releases": [
            {
                "name": "3.0.0.6",
                "date": "2022-04-29T18:02:53Z"
            },
            {
                "name": "3.0.0.5",
                "date": "2020-06-20T19:19:11Z"
            },
            {
                "name": "3.0.0.4",
                "date": "2020-03-03T07:11:52Z"
            },
            {
                "name": "3.0.0.3",
                "date": "2020-03-03T04:02:04Z"
            },
            {
                "name": "3.0.0.2",
                "date": "2020-02-27T07:12:31Z"
            }
        ]
    }
}