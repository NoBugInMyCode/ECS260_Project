{
    "https://api.github.com/repos/jindongwang/transferlearning": {
        "forks": 3825,
        "watchers": 13666,
        "stars": 13666,
        "languages": {
            "Python": 1501543,
            "MATLAB": 72099,
            "Jupyter Notebook": 60826,
            "Shell": 54108,
            "Makefile": 24074,
            "Cuda": 17791,
            "C++": 4582,
            "CMake": 3012
        },
        "commits": [
            "2024-12-25T06:54:16Z",
            "2024-12-19T08:01:50Z",
            "2024-11-29T09:03:44Z",
            "2024-11-29T09:03:31Z",
            "2024-11-21T08:48:37Z",
            "2024-11-20T20:21:02Z",
            "2024-11-01T03:11:37Z",
            "2024-11-01T03:11:15Z",
            "2024-10-21T02:29:22Z",
            "2024-10-16T06:54:24Z",
            "2024-10-12T04:26:31Z",
            "2024-10-12T04:25:40Z",
            "2024-09-25T03:16:42Z",
            "2024-09-24T07:24:16Z",
            "2024-09-23T07:53:12Z",
            "2024-09-09T06:25:00Z",
            "2024-09-03T05:43:47Z",
            "2024-09-02T03:43:29Z",
            "2024-08-15T02:34:54Z",
            "2024-08-15T02:33:43Z",
            "2024-08-06T08:27:54Z",
            "2024-08-05T05:50:55Z",
            "2024-07-31T06:27:10Z",
            "2024-07-29T02:54:55Z",
            "2024-07-09T06:51:25Z",
            "2024-05-22T08:50:55Z",
            "2024-04-25T06:15:33Z",
            "2024-04-25T06:15:30Z",
            "2024-04-18T09:34:53Z",
            "2024-04-18T06:56:30Z"
        ],
        "creation_date": "2017-04-30T11:32:21Z",
        "contributors": 30,
        "topics": [
            "deep-learning",
            "domain-adaptation",
            "domain-adaption",
            "domain-generalization",
            "few-shot",
            "few-shot-learning",
            "generalization",
            "machine-learning",
            "meta-learning",
            "paper",
            "papers",
            "representation-learning",
            "self-supervised-learning",
            "style-transfer",
            "survey",
            "theory",
            "transfer-learning",
            "transferlearning",
            "tutorial-code",
            "unsupervised-learning"
        ],
        "subscribers": 340,
        "readme": "[![Contributors][contributors-shield]][contributors-url]\n[![Forks][forks-shield]][forks-url]\n[![Stargazers][stars-shield]][stars-url]\n[![Issues][issues-shield]][issues-url]\n\n<h1 align=\"center\">\n  <br>\n  <img src=\"png/logo.jpg\" alt=\"Transfer Leanring\" width=\"500\">\n</h1>\n\n<h4 align=\"center\">Everything about Transfer Learning. \u8fc1\u79fb\u5b66\u4e60.</h4>\n\n<p align=\"center\">\n  <strong><a href=\"#0papers-\u8bba\u6587\">Papers</a></strong> \u2022\n  <strong><a href=\"#1introduction-and-tutorials-\u7b80\u4ecb\u4e0e\u6559\u7a0b\">Tutorials</a></strong> \u2022\n  <a href=\"#2transfer-learning-areas-and-papers-\u7814\u7a76\u9886\u57df\u4e0e\u76f8\u5173\u8bba\u6587\">Research areas</a> \u2022\n  <a href=\"#3theory-and-survey-\u7406\u8bba\u4e0e\u7efc\u8ff0\">Theory</a> \u2022\n  <a href=\"#3theory-and-survey-\u7406\u8bba\u4e0e\u7efc\u8ff0\">Survey</a> \u2022\n  <strong><a href=\"https://github.com/jindongwang/transferlearning/tree/master/code\">Code</a></strong> \u2022\n  <strong><a href=\"#7datasets-and-benchmarks-\u6570\u636e\u96c6\u4e0e\u8bc4\u6d4b\u7ed3\u679c\">Dataset & benchmark</a></strong>\n</p>\n<p align=\"center\">\n  <a href=\"#6transfer-learning-thesis-\u7855\u535a\u58eb\u8bba\u6587\">Thesis</a> \u2022\n  <a href=\"#5transfer-learning-scholars-\u8457\u540d\u5b66\u8005\">Scholars</a> \u2022\n  <a href=\"#8transfer-learning-challenges-\u8fc1\u79fb\u5b66\u4e60\u6bd4\u8d5b\">Contests</a> \u2022\n  <a href=\"#journals-and-conferences\">Journal/conference</a> \u2022\n  <a href=\"#applications-\u8fc1\u79fb\u5b66\u4e60\u5e94\u7528\">Applications</a> \u2022\n  <a href=\"#other-resources-\u5176\u4ed6\u8d44\u6e90\">Others</a> \u2022\n  <a href=\"#contributing-\u6b22\u8fce\u53c2\u4e0e\u8d21\u732e\">Contributing</a>\n</p>\n\n**Widely used by top conferences and journals:** \n- Conferences: [[CVPR'22](https://openaccess.thecvf.com/content/CVPR2022W/FaDE-TCV/html/Zhang_Segmenting_Across_Places_The_Need_for_Fair_Transfer_Learning_With_CVPRW_2022_paper.html)] [[NeurIPS'21](https://proceedings.neurips.cc/paper/2021/file/731b03008e834f92a03085ef47061c4a-Paper.pdf)] [[IJCAI'21](https://arxiv.org/abs/2103.03097)] [[ESEC/FSE'20](https://dl.acm.org/doi/abs/10.1145/3368089.3409696)] [[IJCNN'20](https://ieeexplore.ieee.org/abstract/document/9207556)] [[ACMMM'18](https://dl.acm.org/doi/abs/10.1145/3240508.3240512)] [[ICME'19](https://ieeexplore.ieee.org/abstract/document/8784776/)]\n- Journals: [[IEEE TKDE](https://ieeexplore.ieee.org/abstract/document/9782500/)] [[ACM TIST](https://dl.acm.org/doi/abs/10.1145/3360309)] [[Information sciences](https://www.sciencedirect.com/science/article/pii/S0020025520308458)] [[Neurocomputing](https://www.sciencedirect.com/science/article/pii/S0925231221007025)] [[IEEE Transactions on Cognitive and Developmental Systems](https://ieeexplore.ieee.org/abstract/document/9659817)]\n\n```\n@Misc{transferlearning.xyz,\nhowpublished = {\\url{http://transferlearning.xyz}},   \ntitle = {Everything about Transfer Learning and Domain Adapation},  \nauthor = {Wang, Jindong and others}  \n}  \n```\n\n[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![MIT License](https://img.shields.io/badge/license-MIT-green.svg)](https://opensource.org/licenses/MIT) [![LICENSE](https://img.shields.io/badge/license-Anti%20996-blue.svg)](https://github.com/996icu/996.ICU/blob/master/LICENSE) [![996.icu](https://img.shields.io/badge/link-996.icu-red.svg)](https://996.icu) \n\nRelated Codes:\n  - Large language model evaluation: [[llm-eval](https://llm-eval.github.io/)]\n  - Large language model enhancement: [[llm-enhance](https://llm-enhance.github.io/)]\n  - Robust machine learning: [[robustlearn: robust machine learning](https://github.com/microsoft/robustlearn)]\n  - Semi-supervised learning: [[USB: unified semi-supervised learning benchmark](https://github.com/microsoft/Semi-supervised-learning)] | [[TorchSSL: a unified SSL library](https://github.com/TorchSSL/TorchSSL)] \n  - LLM benchmark: [[PromptBench: adversarial robustness of prompts of LLMs](https://github.com/microsoft/promptbench)]\n  - Federated learning: [[PersonalizedFL: library for personalized federated learning](https://github.com/microsoft/PersonalizedFL)]\n  - Activity recognition and machine learning [[Activity recognition](https://github.com/jindongwang/activityrecognition)]\uff5c[[Machine learning](https://github.com/jindongwang/MachineLearning)]\n\n- - -\n\n**NOTE:** You can directly open the code in [Gihub Codespaces](https://docs.github.com/en/codespaces/getting-started/quickstart#introduction) on the web to run them without downloading! Also, try [github.dev](https://github.dev/jindongwang/transferlearning).\n\n## 0.Papers (\u8bba\u6587)\n\n[Awesome transfer learning papers (\u8fc1\u79fb\u5b66\u4e60\u6587\u7ae0\u6c47\u603b)](https://github.com/jindongwang/transferlearning/tree/master/doc/awesome_paper.md)\n\n- [Paperweekly](http://www.paperweekly.site/collections/231/papers): A website to recommend and read paper notes\n\n**Latest papers**: \n\n- By topic: [doc/awesome_papers.md](/doc/awesome_paper.md)\n- By date: [doc/awesome_paper_date.md](/doc/awesome_paper_date.md)\n\n*Updated at 2024-12-25:*\n\n- Privacy in Fine-tuning Large Language Models: Attacks, Defenses, and Future Directions [[arxiv](http://arxiv.org/abs/2412.16504)]\n  - Privacy in LLM fine-tuning \n\n- Learning to Generate Gradients for Test-Time Adaptation via Test-Time Training Layers [[arxiv](http://arxiv.org/abs/2412.16901)]\n  - Generate gradients for TTA \n\n*Updated at 2024-12-19:*\n\n- Is Large-Scale Pretraining the Secret to Good Domain Generalization? [[arxiv](https://arxiv.org/abs/2412.02856)]\n  - Large-scale pre-training vs domain generalization \n\n*Updated at 2024-11-29:*\n\n- Generating Out-Of-Distribution Scenarios Using Language Models [[arxiv](https://arxiv.org/abs/2411.16554)]\n  - Generating OOD settings using language models \n\n*Updated at 2024-11-01:*\n\n- Unified Domain Generalization and Adaptation for Multi-View 3D Object Detection [[arxiv](https://arxiv.org/abs/2410.22461)]\n  - Unified domain generalization and adaptation for multi-view 3D object detection\n\n- - -\n\n## 1.Introduction and Tutorials (\u7b80\u4ecb\u4e0e\u6559\u7a0b)\n\nWant to quickly learn transfer learning\uff1f\u60f3\u5c3d\u5feb\u5165\u95e8\u8fc1\u79fb\u5b66\u4e60\uff1f\u770b\u4e0b\u9762\u7684\u6559\u7a0b\u3002\n\n- Books \u4e66\u7c4d\n  - **Introduction to Transfer Learning: Algorithms and Practice** [[Buy or read](https://link.springer.com/book/9789811975837)]\n  - **\u300a\u8fc1\u79fb\u5b66\u4e60\u300b\uff08\u6768\u5f3a\uff09** [[Buy](https://item.jd.com/12930984.html)] [[English version](https://www.cambridge.org/core/books/transfer-learning/CCFFAFE3CDBC245047F1DEC71D9EF3C7)]\n  - **\u300a\u8fc1\u79fb\u5b66\u4e60\u5bfc\u8bba\u300b(\u738b\u664b\u4e1c\u3001\u9648\u76ca\u5f3a\u8457)** [[Homepage](http://jd92.wang/tlbook)] [[Buy](https://item.jd.com/13272157.html)]\n\n- Blogs \u535a\u5ba2\n  - [Zhihu blogs - \u77e5\u4e4e\u4e13\u680f\u300a\u5c0f\u738b\u7231\u8fc1\u79fb\u300b\u7cfb\u5217\u6587\u7ae0](https://zhuanlan.zhihu.com/p/130244395)\n\t\n- Video tutorials \u89c6\u9891\u6559\u7a0b\n  - Transfer learning \u8fc1\u79fb\u5b66\u4e60:\n    - [Recent advance of transfer learning - 2022\u5e74\u6700\u65b0\u8fc1\u79fb\u5b66\u4e60\u53d1\u5c55\u73b0\u72b6\u63a2\u8ba8](https://www.bilibili.com/video/BV1nY411E7Uc/)\n    - [Definitions of transfer learning area - \u8fc1\u79fb\u5b66\u4e60\u9886\u57df\u540d\u8bcd\u89e3\u91ca](https://www.bilibili.com/video/BV1fu411o7BW) [[Article](https://zhuanlan.zhihu.com/p/428097044)]\n    - [Transfer learning by Hung-yi Lee @ NTU - \u53f0\u6e7e\u5927\u5b66\u674e\u5b8f\u6bc5\u7684\u89c6\u9891\u8bb2\u89e3(\u4e2d\u6587\u89c6\u9891)](https://www.youtube.com/watch?v=qD6iD4TFsdQ)\n  - Domain generalization \u9886\u57df\u6cdb\u5316\uff1a\n    - [IJCAI-ECAI'22 tutorial on domain generalization - \u9886\u57df\u6cdb\u5316tutorial](https://dgresearch.github.io/)\n    - [Domain generalization - \u8fc1\u79fb\u5b66\u4e60\u65b0\u5174\u7814\u7a76\u65b9\u5411\u9886\u57df\u6cdb\u5316](https://www.bilibili.com/video/BV1ro4y1S7dd/)\n  - Domain adaptation \u9886\u57df\u81ea\u9002\u5e94\uff1a\n    - [Domain adaptation - \u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5(\u4e2d\u6587)](https://www.bilibili.com/video/BV1T7411R75a/) \n  \n\n- Brief introduction and slides \u7b80\u4ecb\u4e0eppt\u8d44\u6599\n  - [Recent advance of transfer learning](https://jd92.wang/assets/files/l16_aitime.pdf)\n  - [Domain generalization survey](http://jd92.wang/assets/files/DGSurvey-ppt.pdf)\n  - [Brief introduction in Chinese](https://github.com/jindongwang/transferlearning/blob/master/doc/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B.md)\n\t- [PPT (English)](http://jd92.wang/assets/files/l03_transferlearning.pdf) | [PPT (\u4e2d\u6587)](http://jd92.wang/assets/files/l08_tl_zh.pdf)\n  - \u8fc1\u79fb\u5b66\u4e60\u4e2d\u7684\u9886\u57df\u81ea\u9002\u5e94\u65b9\u6cd5 Domain adaptation: [PDF](http://jd92.wang/assets/files/l12_da.pdf) \uff5c [Video on Bilibili](https://www.bilibili.com/video/BV1T7411R75a/) | [Video on Youtube](https://www.youtube.com/watch?v=RbIsHNtluwQ&t=22s)\n  - Tutorial on transfer learning by Qiang Yang: [IJCAI'13](http://ijcai13.org/files/tutorial_slides/td2.pdf) | [2016 version](http://kddchina.org/file/IntroTL2016.pdf)\n\n- Talk is cheap, show me the code \u52a8\u624b\u6559\u7a0b\u3001\u4ee3\u7801\u3001\u6570\u636e \n  - [Pytorch tutorial on transfer learning](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n\t- [Pytorch finetune](https://github.com/jindongwang/transferlearning/tree/master/code/AlexNet_ResNet)\n\t- [DeepDA: a unified deep domain adaptation toolbox](https://github.com/jindongwang/transferlearning/tree/master/code/DeepDA)\n\t- [DeepDG: a unified deep domain generalization toolbox](https://github.com/jindongwang/transferlearning/tree/master/code/DeepDG)\n\t- [\u66f4\u591a More...](https://github.com/jindongwang/transferlearning/tree/master/code)\n\n- [Transfer Learning Scholars and Labs - \u8fc1\u79fb\u5b66\u4e60\u9886\u57df\u7684\u8457\u540d\u5b66\u8005\u3001\u4ee3\u8868\u5de5\u4f5c\u53ca\u5b9e\u9a8c\u5ba4\u4ecb\u7ecd](https://github.com/jindongwang/transferlearning/blob/master/doc/scholar_TL.md)\n- [Negative transfer - \u8d1f\u8fc1\u79fb](https://www.zhihu.com/question/66492194/answer/242870418)\n\n- - -\n\n## 2.Transfer Learning Areas and Papers (\u7814\u7a76\u9886\u57df\u4e0e\u76f8\u5173\u8bba\u6587)\n\n- [Survey](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#survey)\n- [Theory](#theory)\n- [Per-training/Finetuning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#per-trainingfinetuning)\n- [Knowledge distillation](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#knowledge-distillation)\n- [Traditional domain adaptation](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#traditional-domain-adaptation)\n- [Deep domain adaptation](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#deep-domain-adaptation)\n- [Domain generalization](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#domain-generalization)\n- [Source-free domain adaptation](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#source-free-domain-adaptation)\n- [Multi-source domain adaptation](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#multi-source-domain-adaptation)\n- [Heterogeneous transfer learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#heterogeneous-transfer-learning)\n- [Online transfer learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#online-transfer-learning)\n- [Zero-shot / few-shot learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#zero-shot--few-shot-learning)\n- [Multi-task learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#multi-task-learning)\n- [Transfer reinforcement learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#transfer-reinforcement-learning)\n- [Transfer metric learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#transfer-metric-learning)\n- [Federated transfer learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#federated-transfer-learning)\n- [Lifelong transfer learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#lifelong-transfer-learning)\n- [Safe transfer learning](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#safe-transfer-learning)\n- [Transfer learning applications](https://github.com/jindongwang/transferlearning/blob/master/doc/awesome_paper.md#transfer-learning-applications)\n\n- - -\n\n## 3.Theory and Survey (\u7406\u8bba\u4e0e\u7efc\u8ff0)\n\nHere are some articles on transfer learning theory and survey.\n\n**Survey (\u7efc\u8ff0\u6587\u7ae0)\uff1a**\n\n- 2023 Source-Free Unsupervised Domain Adaptation: A Survey [[arxiv](http://arxiv.org/abs/2301.00265)]\n- 2022 [Transfer Learning for Future Wireless Networks: A Comprehensive Survey](https://arxiv.org/abs/2102.07572)\n- 2022 [A Review of Deep Transfer Learning and Recent Advancements](https://arxiv.org/abs/2201.09679)\n- 2022 [Transferability in Deep Learning: A Survey](https://paperswithcode.com/paper/transferability-in-deep-learning-a-survey), from Mingsheng Long in THU.\n- 2021 Domain generalization: IJCAI-21 [Generalizing to Unseen Domains: A Survey on Domain Generalization](https://arxiv.org/abs/2103.03097) | [\u77e5\u4e4e\u6587\u7ae0](https://zhuanlan.zhihu.com/p/354740610) | [\u5fae\u4fe1\u516c\u4f17\u53f7](https://mp.weixin.qq.com/s/DsoVDYqLB1N7gj9X5UnYqw)\n  - First survey on domain generalization\n  - \u7b2c\u4e00\u7bc7\u5bf9Domain generalization (\u9886\u57df\u6cdb\u5316)\u7684\u7efc\u8ff0\n- 2021 Vision-based activity recognition: [A Survey of Vision-Based Transfer Learning in Human Activity Recognition](https://www.mdpi.com/2079-9292/10/19/2412)\n- 2021 ICSAI [A State-of-the-Art Survey of Transfer Learning in Structural Health Monitoring](https://ieeexplore.ieee.org/abstract/document/9664171)\n- 2020 [Transfer learning: survey and classification](https://link.springer.com/chapter/10.1007/978-981-15-5345-5_13), Advances in Intelligent Systems and Computing. \n- 2020 \u8fc1\u79fb\u5b66\u4e60\u6700\u65b0survey\uff0c\u6765\u81ea\u4e2d\u79d1\u9662\u8ba1\u7b97\u6240\u5e84\u798f\u632f\u56e2\u961f\uff0c\u53d1\u8868\u5728Proceedings of the IEEE: [A Comprehensive Survey on Transfer Learning](https://arxiv.org/abs/1911.02685)\n- 2020 \u8d1f\u8fc1\u79fb\u7684\u7efc\u8ff0\uff1a[Overcoming Negative Transfer: A Survey](https://arxiv.org/abs/2009.00909)\n- 2020 \u77e5\u8bc6\u84b8\u998f\u7684\u7efc\u8ff0: [Knowledge Distillation: A Survey](https://arxiv.org/abs/2006.05525)\n- \u7528transfer learning\u8fdb\u884csentiment classification\u7684\u7efc\u8ff0\uff1a[A Survey of Sentiment Analysis Based on Transfer Learning](https://ieeexplore.ieee.org/abstract/document/8746210) \n- 2019 \u4e00\u7bc7\u65b0survey\uff1a[Transfer Adaptation Learning: A Decade Survey](https://arxiv.org/abs/1903.04687)\n- 2018 \u4e00\u7bc7\u8fc1\u79fb\u5ea6\u91cf\u5b66\u4e60\u7684\u7efc\u8ff0: [Transfer Metric Learning: Algorithms, Applications and Outlooks](https://arxiv.org/abs/1810.03944)\n- 2018 \u4e00\u7bc7\u6700\u8fd1\u7684\u975e\u5bf9\u79f0\u60c5\u51b5\u4e0b\u7684\u5f02\u6784\u8fc1\u79fb\u5b66\u4e60\u7efc\u8ff0\uff1a[Asymmetric Heterogeneous Transfer Learning: A Survey](https://arxiv.org/abs/1804.10834)\n- 2018 Neural style transfer\u7684\u4e00\u4e2asurvey\uff1a[Neural Style Transfer: A Review](https://arxiv.org/abs/1705.04058)\n- 2018 \u6df1\u5ea6domain adaptation\u7684\u4e00\u4e2a\u7efc\u8ff0\uff1a[Deep Visual Domain Adaptation: A Survey](https://www.sciencedirect.com/science/article/pii/S0925231218306684)\n- 2017 \u591a\u4efb\u52a1\u5b66\u4e60\u7684\u7efc\u8ff0\uff0c\u6765\u81ea\u9999\u6e2f\u79d1\u6280\u5927\u5b66\u6768\u5f3a\u56e2\u961f\uff1a[A survey on multi-task learning](https://arxiv.org/abs/1707.08114)\n- 2017 \u5f02\u6784\u8fc1\u79fb\u5b66\u4e60\u7684\u7efc\u8ff0\uff1a[A survey on heterogeneous transfer learning](https://link.springer.com/article/10.1186/s40537-017-0089-0)\n- 2017 \u8de8\u9886\u57df\u6570\u636e\u8bc6\u522b\u7684\u7efc\u8ff0\uff1a[Cross-dataset recognition: a survey](https://arxiv.org/abs/1705.04396)\n- 2016 [A survey of transfer learning](https://pan.baidu.com/s/1gfgXLXT)\u3002\u5176\u4e2d\u4ea4\u4ee3\u4e86\u4e00\u4e9b\u6bd4\u8f83\u7ecf\u5178\u7684\u5982\u540c\u6784\u3001\u5f02\u6784\u7b49\u5b66\u4e60\u65b9\u6cd5\u4ee3\u8868\u6027\u6587\u7ae0\u3002\n- 2015 \u4e2d\u6587\u7efc\u8ff0\uff1a[\u8fc1\u79fb\u5b66\u4e60\u7814\u7a76\u8fdb\u5c55](https://pan.baidu.com/s/1bpautob)\n- 2010 [A survey on transfer learning](http://ieeexplore.ieee.org/abstract/document/5288526/)\n- Survey on applications - \u5e94\u7528\u5bfc\u5411\u7684\u7efc\u8ff0\uff1a\n\t- \u89c6\u89c9domain adaptation\u7efc\u8ff0\uff1a[Visual Domain Adaptation: A Survey of Recent Advances](https://pan.baidu.com/s/1o8BR7Vc)\n\t- \u8fc1\u79fb\u5b66\u4e60\u5e94\u7528\u4e8e\u884c\u4e3a\u8bc6\u522b\u7efc\u8ff0\uff1a[Transfer Learning for Activity Recognition: A Survey](https://pan.baidu.com/s/1kVABOYr)\n\t- \u8fc1\u79fb\u5b66\u4e60\u4e0e\u589e\u5f3a\u5b66\u4e60\uff1a[Transfer Learning for Reinforcement Learning Domains: A Survey](https://pan.baidu.com/s/1slfr0w1)\n\t- \u591a\u4e2a\u6e90\u57df\u8fdb\u884c\u8fc1\u79fb\u7684\u7efc\u8ff0\uff1a[A Survey of Multi-source Domain Adaptation](https://pan.baidu.com/s/1eSGREF4)\u3002\n\n**Theory \uff08\u7406\u8bba\u6587\u7ae0\uff09:**\n\n- ICML-20 [Few-shot domain adaptation by causal mechanism transfer](https://arxiv.org/pdf/2002.03497.pdf)\n\t- The first work on causal transfer learning\n\t- \u65e5\u672c\u7406\u8bba\u7ec4\u5927\u4f6cSugiyama\u7684\u5de5\u4f5c\uff0ccausal transfer learning\n- CVPR-19 [Characterizing and Avoiding Negative Transfer](https://arxiv.org/abs/1811.09751)\n\t- Characterizing and avoid negative transfer\n\t- \u5f62\u5f0f\u5316\u5e76\u63d0\u51fa\u5982\u4f55\u907f\u514d\u8d1f\u8fc1\u79fb\n- ICML-20 [On Learning Language-Invariant Representations for Universal Machine Translation](https://arxiv.org/abs/2008.04510)\n  - Theory for universal machine translation\n  - \u5bf9\u7edf\u4e00\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u8fdb\u884c\u4e86\u7406\u8bba\u8bba\u8bc1\n- NIPS-06 [Analysis of Representations for Domain Adaptation](https://dl.acm.org/citation.cfm?id=2976474)\n- ML-10 [A Theory of Learning from Different Domains](https://link.springer.com/article/10.1007/s10994-009-5152-4)\n- NIPS-08 [Learning Bounds for Domain Adaptation](http://papers.nips.cc/paper/3212-learning-bounds-for-domain-adaptation)\n- COLT-09 [Domain adaptation: Learning bounds and algorithms](https://arxiv.org/abs/0902.3430)\n- MMD paper\uff1a[A Hilbert Space Embedding for Distributions](https://link.springer.com/chapter/10.1007/978-3-540-75225-7_5) and [A Kernel Two-Sample Test](http://www.jmlr.org/papers/v13/gretton12a.html)\n- Multi-kernel MMD paper: [Optimal kernel choice for large-scale two-sample tests](http://papers.nips.cc/paper/4727-optimal-kernel-choice-for-large-scale-two-sample-tests)\n\n_ _ _\n\n## 4.Code (\u4ee3\u7801)\n\nUnified codebases for:\n- [Deep domain adaptation](https://github.com/jindongwang/transferlearning/tree/master/code/DeepDA)\n- [Deep domain generalization](https://github.com/jindongwang/transferlearning/tree/master/code/DeepDG)\n- See all codes here: https://github.com/jindongwang/transferlearning/tree/master/code.\n\nMore: see [HERE](https://github.com/jindongwang/transferlearning/tree/master/code) and [HERE](https://colab.research.google.com/drive/1MVuk95mMg4ecGyUAIG94vedF81HtWQAr?usp=sharing) for an instant run using Google's Colab.\n\n_ _ _\n\n## 5.Transfer Learning Scholars (\u8457\u540d\u5b66\u8005)\n\nHere are some transfer learning scholars and labs.\n\n**\u5168\u90e8\u5217\u8868\u4ee5\u53ca\u4ee3\u8868\u5de5\u4f5c\u6027\u89c1[\u8fd9\u91cc](https://github.com/jindongwang/transferlearning/blob/master/doc/scholar_TL.md)** \n\nPlease note that this list is far not complete. A full list can be seen in [here](https://github.com/jindongwang/transferlearning/blob/master/doc/scholar_TL.md). Transfer learning is an active field. *If you are aware of some scholars, please add them here.*\n\n_ _ _\n\n## 6.Transfer Learning Thesis (\u7855\u535a\u58eb\u8bba\u6587)\n\nHere are some popular thesis on transfer learning.\n\n[\u8fd9\u91cc](https://pan.baidu.com/share/init?surl=iuzZhHdumrD64-yx_VAybA), \u63d0\u53d6\u7801\uff1atxyz\u3002\n\n- - -\n\n## 7.Datasets and Benchmarks (\u6570\u636e\u96c6\u4e0e\u8bc4\u6d4b\u7ed3\u679c)\n\nPlease see [HERE](https://github.com/jindongwang/transferlearning/blob/master/data) for the popular transfer learning **datasets and benchmark** results.\n\n[\u8fd9\u91cc](https://github.com/jindongwang/transferlearning/blob/master/data)\u6574\u7406\u4e86\u5e38\u7528\u7684\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e00\u4e9b\u5df2\u53d1\u8868\u7684\u6587\u7ae0\u5728\u8fd9\u4e9b\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u3002\n\n- - -\n\n## 8.Transfer Learning Challenges (\u8fc1\u79fb\u5b66\u4e60\u6bd4\u8d5b)\n\n- [Visual Domain Adaptation Challenge (VisDA)](http://ai.bu.edu/visda-2018/)\n\n- - -\n\n## Journals and Conferences\n\nSee [here](https://github.com/jindongwang/transferlearning/blob/master/doc/venues.md) for a full list of related journals and conferences.\n\n- - -\n\n## Applications (\u8fc1\u79fb\u5b66\u4e60\u5e94\u7528)\n\n- [Computer vision](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#computer-vision)\n- [Medical and healthcare](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#medical-and-healthcare)\n- [Natural language processing](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#natural-language-processing)\n- [Time series](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#time-series)\n- [Speech](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#speech)\n- [Multimedia](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#multimedia)\n- [Recommendation](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#recommendation)\n- [Human activity recognition](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#human-activity-recognition)\n- [Autonomous driving](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#autonomous-driving)\n- [Others](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md#others)\n\nSee [HERE](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md) for transfer learning applications.\n\n\u8fc1\u79fb\u5b66\u4e60\u5e94\u7528\u8bf7\u89c1[\u8fd9\u91cc](https://github.com/jindongwang/transferlearning/blob/master/doc/transfer_learning_application.md)\u3002\n\n- - -\n\n## Other Resources (\u5176\u4ed6\u8d44\u6e90)\n\n- Call for papers:\n  - [Advances in Transfer Learning: Theory, Algorithms, and Applications](https://www.frontiersin.org/research-topics/21133/advances-in-transfer-learning-theory-algorithms-and-applications), DDL: October 2021\n\n- Related projects:\n  - Salad: [A semi-supervised domain adaptation library](https://domainadaptation.org)\n\n- - -\n\n## Contributing (\u6b22\u8fce\u53c2\u4e0e\u8d21\u732e)\n\nIf you are interested in contributing, please refer to [HERE](https://github.com/jindongwang/transferlearning/blob/master/CONTRIBUTING.md) for instructions in contribution.\n\n- - -\n\n### Copyright notice\n\n> ***[Notes]This Github repo can be used by following the corresponding licenses. I want to emphasis that it may contain some PDFs or thesis, which were downloaded by me and can only be used for academic purposes. The copyrights of these materials are owned by corresponding publishers or organizations. All this are for better academic research. If any of the authors or publishers have concerns, please contact me to delete or replace them.***\n\n[contributors-shield]: https://img.shields.io/github/contributors/jindongwang/transferlearning.svg?style=for-the-badge\n[contributors-url]: https://github.com/jindongwang/transferlearning/graphs/contributors\n[forks-shield]: https://img.shields.io/github/forks/jindongwang/transferlearning.svg?style=for-the-badge\n[forks-url]: https://github.com/jindongwang/transferlearning/network/members\n[stars-shield]: https://img.shields.io/github/stars/jindongwang/transferlearning.svg?style=for-the-badge\n[stars-url]: https://github.com/jindongwang/transferlearning/stargazers\n[issues-shield]: https://img.shields.io/github/issues/jindongwang/transferlearning.svg?style=for-the-badge\n[issues-url]: https://github.com/jindongwang/transferlearning/issues\n[license-shield]: https://img.shields.io/github/license/jindongwang/transferlearning.svg?style=for-the-badge\n[license-url]: https://github.com/jindongwang/transferlearning/blob/main/LICENSE.txt\n",
        "releases": []
    }
}