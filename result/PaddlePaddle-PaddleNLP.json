{
    "https://api.github.com/repos/PaddlePaddle/PaddleNLP": {
        "forks": 2977,
        "watchers": 12305,
        "stars": 12305,
        "languages": {
            "Python": 26522925,
            "Cuda": 1324154,
            "Shell": 1289377,
            "C++": 1009811,
            "Jupyter Notebook": 115407,
            "CMake": 15518,
            "C": 8584,
            "Makefile": 3831,
            "Dockerfile": 426
        },
        "commits": [
            "2025-01-21T07:38:15Z",
            "2025-01-21T07:19:36Z",
            "2025-01-21T06:52:10Z",
            "2025-01-17T03:13:33Z",
            "2025-01-16T09:21:23Z",
            "2025-01-16T06:14:37Z",
            "2025-01-15T05:22:22Z",
            "2025-01-15T05:22:01Z",
            "2025-01-15T03:15:06Z",
            "2025-01-14T10:01:20Z",
            "2025-01-14T09:32:42Z",
            "2025-01-14T07:16:55Z",
            "2025-01-14T06:03:39Z",
            "2025-01-14T02:41:54Z",
            "2025-01-10T08:48:29Z",
            "2025-01-10T06:15:22Z",
            "2025-01-10T06:07:55Z",
            "2025-01-10T03:26:19Z",
            "2025-01-10T03:10:14Z",
            "2025-01-10T03:08:25Z",
            "2025-01-10T03:04:58Z",
            "2025-01-09T07:13:32Z",
            "2025-01-08T11:48:40Z",
            "2025-01-08T08:56:56Z",
            "2025-01-08T08:15:43Z",
            "2025-01-08T03:07:16Z",
            "2025-01-07T10:06:58Z",
            "2025-01-07T03:16:26Z",
            "2025-01-06T12:13:38Z",
            "2025-01-06T11:46:46Z"
        ],
        "creation_date": "2021-02-05T13:07:42Z",
        "contributors": 30,
        "topics": [
            "bert",
            "compression",
            "distributed-training",
            "document-intelligence",
            "embedding",
            "ernie",
            "information-extraction",
            "llama",
            "llm",
            "neural-search",
            "nlp",
            "paddlenlp",
            "pretrained-models",
            "question-answering",
            "search-engine",
            "semantic-analysis",
            "sentiment-analysis",
            "transformers",
            "uie"
        ],
        "subscribers": 105,
        "readme": "**\u7b80\u4f53\u4e2d\u6587**\ud83c\udc04 | [English\ud83c\udf0e](./README_en.md)\n\n<p align=\"center\">\n  <img src=\"https://user-images.githubusercontent.com/1371212/175816733-8ec25eb0-9af3-4380-9218-27c154518258.png\" align=\"middle\"  width=\"500\" />\n</p>\n\n------------------------------------------------------------------------------------------\n\n<p align=\"center\">\n    <a href=\"./LICENSE\"><img src=\"https://img.shields.io/badge/license-Apache%202-dfd.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/releases\"><img src=\"https://img.shields.io/github/v/release/PaddlePaddle/PaddleNLP?color=ffa\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/python-3.7+-aff.svg\"></a>\n    <a href=\"\"><img src=\"https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/graphs/contributors\"><img src=\"https://img.shields.io/github/contributors/PaddlePaddle/PaddleNLP?color=9ea\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/PaddlePaddle/PaddleNLP?color=3af\"></a>\n    <a href=\"https://pypi.org/project/paddlenlp/\"><img src=\"https://img.shields.io/pypi/dm/paddlenlp?color=9cf\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/issues\"><img src=\"https://img.shields.io/github/issues/PaddlePaddle/PaddleNLP?color=9cc\"></a>\n    <a href=\"https://github.com/PaddlePaddle/PaddleNLP/stargazers\"><img src=\"https://img.shields.io/github/stars/PaddlePaddle/PaddleNLP?color=ccf\"></a>\n</p>\n\n<h4 align=\"center\">\n  <a href=#\u7279\u6027> \u7279\u6027 </a> |\n  <a href=#\u6a21\u578b\u652f\u6301> \u6a21\u578b\u652f\u6301 </a> |\n  <a href=#\u5b89\u88c5> \u5b89\u88c5 </a> |\n  <a href=#\u5feb\u901f\u5f00\u59cb> \u5feb\u901f\u5f00\u59cb </a> |\n  <a href=#\u793e\u533a\u4ea4\u6d41> \u793e\u533a\u4ea4\u6d41 </a>\n</h4>\n\n**PaddleNLP**\u662f\u4e00\u6b3e\u57fa\u4e8e\u98de\u6868\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u7684\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u5f00\u53d1\u5957\u4ef6\uff0c\u652f\u6301\u5728\u591a\u79cd\u786c\u4ef6\u4e0a\u8fdb\u884c\u9ad8\u6548\u7684\u5927\u6a21\u578b\u8bad\u7ec3\u3001\u65e0\u635f\u538b\u7f29\u4ee5\u53ca\u9ad8\u6027\u80fd\u63a8\u7406\u3002PaddleNLP \u5177\u5907**\u7b80\u5355\u6613\u7528**\u548c**\u6027\u80fd\u6781\u81f4**\u7684\u7279\u70b9\uff0c\u81f4\u529b\u4e8e\u52a9\u529b\u5f00\u53d1\u8005\u5b9e\u73b0\u9ad8\u6548\u7684\u5927\u6a21\u578b\u4ea7\u4e1a\u7ea7\u5e94\u7528\u3002\n\n<a href=\"https://trendshift.io/repositories/2246\" target=\"_blank\"><img src=\"https://trendshift.io/api/badge/repositories/2246\" alt=\"PaddlePaddle%2FPaddleNLP | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\"/></a>\n\n## News \ud83d\udce2\n* **2024.12.16 [PaddleNLP v3.0 Beta3](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta3)**\uff1a\u5927\u6a21\u578b\u529f\u80fd\u5168\u65b0\u5347\u7ea7\uff0c\u65b0\u589e\u4e86 Llama-3.2\u3001DeepSeekV2\u6a21\u578b\uff0c\u5347\u7ea7\u4e86 TokenizerFast\uff0c\u5feb\u901f\u5206\u8bcd\uff0c\u91cd\u6784\u4e86 SFTTrainer\uff0c\u4e00\u952e\u5f00\u542f SFT \u8bad\u7ec3\u3002\u6b64\u5916\uff0cPaddleNLP \u8fd8\u652f\u6301\u4e86\u4f18\u5316\u5668\u72b6\u6001\u7684\u5378\u8f7d\u548c\u91cd\u8f7d\u529f\u80fd\uff0c\u5b9e\u73b0\u4e86\u7cbe\u7ec6\u5316\u7684\u91cd\u65b0\u8ba1\u7b97\uff0c\u8bad\u7ec3\u6027\u80fd\u63d0\u53477%\u3002\u5728 Unified Checkpoint \u65b9\u9762\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u4e86\u5f02\u6b65\u4fdd\u5b58\u903b\u8f91\uff0c\u65b0\u589e Checkpoint \u538b\u7f29\u529f\u80fd\uff0c\u53ef\u8282\u770178.5%\u5b58\u50a8\u7a7a\u95f4\u3002\n\u6700\u540e\uff0c\u5728\u5927\u6a21\u578b\u63a8\u7406\u65b9\u9762\uff0c\u5347\u7ea7 Append Attention\uff0c\u652f\u6301\u4e86 FP8\u91cf\u5316\uff0c\u652f\u6301\u6295\u673a\u89e3\u7801\u3002\n\n* **2024.12.13 \ud83d\udcda\u300a\u98de\u6868\u5927\u6a21\u578b\u5957\u4ef6 Unified Checkpoint \u6280\u672f\u300b**\uff0c\u52a0\u901f\u6a21\u578b\u5b58\u50a895%\uff0c\u8282\u7701\u7a7a\u95f478%\u3002\u652f\u6301\u5168\u5206\u5e03\u5f0f\u7b56\u7565\u8c03\u6574\u81ea\u9002\u5e94\u8f6c\u6362\uff0c\u63d0\u5347\u6a21\u578b\u8bad\u7ec3\u7684\u7075\u6d3b\u6027\u4e0e\u53ef\u6269\u5c55\u6027\u3002\u8bad\u7ec3-\u538b\u7f29-\u63a8\u7406\u7edf\u4e00\u5b58\u50a8\u534f\u8bae\uff0c\u65e0\u9700\u624b\u52a8\u8f6c\u6362\u63d0\u5347\u5168\u6d41\u7a0b\u4f53\u9a8c\u3002Checkpoint \u65e0\u635f\u538b\u7f29\u7ed3\u5408\u5f02\u6b65\u4fdd\u5b58\uff0c\u5b9e\u73b0\u79d2\u7ea7\u5b58\u50a8\u5e76\u964d\u4f4e\u6a21\u578b\u5b58\u50a8\u6210\u672c\u3002\u9002\u7528\u4e8e\u667a\u80fd\u5236\u9020\u3001\u6307\u6325\u4ea4\u901a\u3001\u533b\u7597\u5065\u5eb7\u3001\u91d1\u878d\u670d\u52a1\u7b49\u4ea7\u4e1a\u5b9e\u9645\u573a\u666f\u300212\u670824\u65e5\uff08\u5468\u4e8c\uff0919\uff1a00\u76f4\u64ad\u4e3a\u60a8\u8be6\u7ec6\u89e3\u8bfb\u8be5\u6280\u672f\u5982\u4f55\u4f18\u5316\u5927\u6a21\u578b\u8bad\u7ec3\u6d41\u7a0b\u3002\u62a5\u540d\u94fe\u63a5\uff1ahttps://www.wjx.top/vm/huZkHn9.aspx?udsid=787976\n\n* **2024.11.28 \ud83d\udcda\u300aFlashRAG-Paddle | \u57fa\u4e8e PaddleNLP \u7684\u9ad8\u6548\u5f00\u53d1\u4e0e\u8bc4\u6d4b RAG \u6846\u67b6\u300b**\uff0c\u4e3a\u6587\u672c\u66f4\u5feb\u66f4\u597d\u6784\u5efa\u51c6\u786e\u5d4c\u5165\u8868\u793a\u3001\u52a0\u901f\u63a8\u7406\u751f\u6210\u901f\u5ea6\u3002PaddleNLP \u652f\u6301\u8d85\u5927 Batch \u5d4c\u5165\u8868\u793a\u5b66\u4e60\u4e0e\u591a\u786c\u4ef6\u9ad8\u6027\u80fd\u63a8\u7406\uff0c\u6db5\u76d6 INT8/INT4\u91cf\u5316\u6280\u672f\u53ca\u591a\u79cd\u9ad8\u6548\u6ce8\u610f\u529b\u673a\u5236\u4f18\u5316\u4e0e TensorCore \u6df1\u5ea6\u4f18\u5316\u3002\u5185\u7f6e\u5168\u73af\u8282\u7b97\u5b50\u878d\u5408\u6280\u672f\uff0c\u4f7f\u5f97 FlashRAG \u63a8\u7406\u6027\u80fd\u76f8\u6bd4 transformers \u52a8\u6001\u56fe\u63d0\u534770%\u4ee5\u4e0a\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u77e5\u8bc6\u8f93\u51fa\u7ed3\u679c\u66f4\u52a0\u51c6\u786e\uff0c\u5e26\u6765\u654f\u6377\u9ad8\u6548\u7684\u4f7f\u7528\u4f53\u9a8c\u3002\u76f4\u64ad\u65f6\u95f4\uff1a12\u67083\u65e5\uff08\u5468\u4e8c\uff0919\uff1a00\u3002\u62a5\u540d\u94fe\u63a5\uff1ahttps://www.wjx.top/vm/eaBa1vA.aspx?udsid=682361\n\n\n\n<details><summary> <b>\u70b9\u51fb\u5c55\u5f00</b> </summary><div>\n\n* **2024.08.08 \ud83d\udcda\u300a\u98de\u6868\u4ea7\u4e1a\u7ea7\u5927\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u5229\u5668 PaddleNLP 3.0 \u91cd\u78c5\u53d1\u5e03\u300b**\uff0c\u8bad\u538b\u63a8\u5168\u6d41\u7a0b\u8d2f\u901a\uff0c\u4e3b\u6d41\u6a21\u578b\u5168\u8986\u76d6\u3002\u5927\u6a21\u578b\u81ea\u52a8\u5e76\u884c\uff0c\u5343\u4ebf\u6a21\u578b\u8bad\u63a8\u5168\u6d41\u7a0b\u5f00\u7bb1\u5373\u7528\u3002\u63d0\u4f9b\u4ea7\u4e1a\u7ea7\u9ad8\u6027\u80fd\u7cbe\u8c03\u4e0e\u5bf9\u9f50\u89e3\u51b3\u65b9\u6848\uff0c\u538b\u7f29\u63a8\u7406\u9886\u5148\uff0c\u591a\u786c\u4ef6\u9002\u914d\u3002\u8986\u76d6\u4ea7\u4e1a\u7ea7\u667a\u80fd\u52a9\u624b\u3001\u5185\u5bb9\u521b\u4f5c\u3001\u77e5\u8bc6\u95ee\u7b54\u3001\u5173\u952e\u4fe1\u606f\u62bd\u53d6\u7b49\u5e94\u7528\u573a\u666f\u3002\u76f4\u64ad\u65f6\u95f4\uff1a8\u670822\u65e5\uff08\u5468\u56db\uff0919\uff1a00\u3002\u62a5\u540d\u94fe\u63a5\uff1ahttps://www.wjx.top/vm/Y2f7FFY.aspx?udsid=143844\n\n* **2024.06.27 [PaddleNLP v3.0 Beta](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v3.0.0-beta0)**\uff1a\u62e5\u62b1\u5927\u6a21\u578b\uff0c\u4f53\u9a8c\u5168\u5347\u7ea7\u3002\u7edf\u4e00\u5927\u6a21\u578b\u5957\u4ef6\uff0c\u5b9e\u73b0\u56fd\u4ea7\u8ba1\u7b97\u82af\u7247\u5168\u6d41\u7a0b\u63a5\u5165\uff1b\u5168\u9762\u652f\u6301\u98de\u68684D \u5e76\u884c\u914d\u7f6e\u3001\u9ad8\u6548\u7cbe\u8c03\u7b56\u7565\u3001\u9ad8\u6548\u5bf9\u9f50\u7b97\u6cd5\u3001\u9ad8\u6027\u80fd\u63a8\u7406\u7b49\u5927\u6a21\u578b\u4ea7\u4e1a\u7ea7\u5e94\u7528\u6d41\u7a0b\uff1b\u81ea\u7814\u6781\u81f4\u6536\u655b\u7684 RsLoRA+\u7b97\u6cd5\u3001\u81ea\u52a8\u6269\u7f29\u5bb9\u5b58\u50a8\u673a\u5236 Unified Checkpoint \u548c\u901a\u7528\u5316\u652f\u6301\u7684 FastFFN\u3001FusedQKV \u52a9\u529b\u5927\u6a21\u578b\u8bad\u63a8\uff1b\u4e3b\u6d41\u6a21\u578b\u6301\u7eed\u652f\u6301\u66f4\u65b0\uff0c\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002\n\n* **2024.04.24 [PaddleNLP v2.8](https://github.com/PaddlePaddle/PaddleNLP/releases/tag/v2.8.0)**\uff1a\u81ea\u7814\u6781\u81f4\u6536\u655b\u7684 RsLoRA+\u7b97\u6cd5\uff0c\u5927\u5e45\u63d0\u5347 PEFT \u8bad\u7ec3\u6536\u655b\u901f\u5ea6\u4ee5\u53ca\u8bad\u7ec3\u6548\u679c\uff1b\u5f15\u5165\u9ad8\u6027\u80fd\u751f\u6210\u52a0\u901f\u5230 RLHF PPO \u7b97\u6cd5\uff0c\u6253\u7834 PPO \u8bad\u7ec3\u4e2d\u751f\u6210\u901f\u5ea6\u74f6\u9888\uff0cPPO \u8bad\u7ec3\u6027\u80fd\u5927\u5e45\u9886\u5148\u3002\u901a\u7528\u5316\u652f\u6301 FastFFN\u3001FusedQKV \u7b49\u591a\u4e2a\u5927\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\u4f18\u5316\u65b9\u5f0f\uff0c\u5927\u6a21\u578b\u8bad\u7ec3\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\u3002\n</div></details>\n\n## \u7279\u6027\n\n### <a href=#\u591a\u786c\u4ef6\u8bad\u63a8\u4e00\u4f53> \ud83d\udd27 \u591a\u786c\u4ef6\u8bad\u63a8\u4e00\u4f53 </a>\n\n\u652f\u6301\u82f1\u4f1f\u8fbe GPU\u3001\u6606\u4ed1 XPU\u3001\u6607\u817e NPU\u3001\u71e7\u539f GCU \u548c\u6d77\u5149 DCU \u7b49\u591a\u4e2a\u786c\u4ef6\u7684\u5927\u6a21\u578b\u548c\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\uff0c\u5957\u4ef6\u63a5\u53e3\u652f\u6301\u786c\u4ef6\u5feb\u901f\u5207\u6362\uff0c\u5927\u5e45\u964d\u4f4e\u786c\u4ef6\u5207\u6362\u7814\u53d1\u6210\u672c\u3002\n\u5f53\u524d\u652f\u6301\u7684\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u6a21\u578b\uff1a[\u591a\u786c\u4ef6\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u6a21\u578b\u5217\u8868](./docs/model_zoo/model_list_multy_device.md)\n\n### <a href=#\u9ad8\u6548\u6613\u7528\u7684\u9884\u8bad\u7ec3> \ud83d\ude80 \u9ad8\u6548\u6613\u7528\u7684\u9884\u8bad\u7ec3 </a>\n\n\u652f\u6301\u7eaf\u6570\u636e\u5e76\u884c\u7b56\u7565\u3001\u5206\u7ec4\u53c2\u6570\u5207\u7247\u7684\u6570\u636e\u5e76\u884c\u7b56\u7565\u3001\u5f20\u91cf\u6a21\u578b\u5e76\u884c\u7b56\u7565\u548c\u6d41\u6c34\u7ebf\u6a21\u578b\u5e76\u884c\u7b56\u7565\u76844D \u9ad8\u6027\u80fd\u8bad\u7ec3\uff0cTrainer \u652f\u6301\u5206\u5e03\u5f0f\u7b56\u7565\u914d\u7f6e\u5316\uff0c\u964d\u4f4e\u590d\u6742\u5206\u5e03\u5f0f\u7ec4\u5408\u5e26\u6765\u7684\u4f7f\u7528\u6210\u672c\uff1b\n[Unified Checkpoint \u5927\u6a21\u578b\u5b58\u50a8\u5de5\u5177](./llm/docs/unified_checkpoint.md)\u53ef\u4ee5\u4f7f\u5f97\u8bad\u7ec3\u65ad\u70b9\u652f\u6301\u673a\u5668\u8d44\u6e90\u52a8\u6001\u6269\u7f29\u5bb9\u6062\u590d\u3002\u6b64\u5916\uff0c\u5f02\u6b65\u4fdd\u5b58\uff0c\u6a21\u578b\u5b58\u50a8\u53ef\u52a0\u901f95%\uff0cCheckpoint \u538b\u7f29\uff0c\u53ef\u8282\u770178.5%\u5b58\u50a8\u7a7a\u95f4\u3002\n\n### <a href=#\u9ad8\u6548\u7cbe\u8c03> \ud83e\udd17 \u9ad8\u6548\u7cbe\u8c03 </a>\n\n\u7cbe\u8c03\u7b97\u6cd5\u6df1\u5ea6\u7ed3\u5408\u96f6\u586b\u5145\u6570\u636e\u6d41\u548c [FlashMask](./llm/docs/flashmask.md) \u9ad8\u6027\u80fd\u7b97\u5b50\uff0c\u964d\u4f4e\u8bad\u7ec3\u65e0\u6548\u6570\u636e\u586b\u5145\u548c\u8ba1\u7b97\uff0c\u5927\u5e45\u63d0\u5347\u7cbe\u8c03\u8bad\u7ec3\u541e\u5410\u3002\n\n### <a href=#\u65e0\u635f\u538b\u7f29\u548c\u9ad8\u6027\u80fd\u63a8\u7406> \ud83c\udf9b\ufe0f \u65e0\u635f\u538b\u7f29\u548c\u9ad8\u6027\u80fd\u63a8\u7406 </a>\n\n\u5927\u6a21\u578b\u5957\u4ef6\u9ad8\u6027\u80fd\u63a8\u7406\u6a21\u5757\u5185\u7f6e\u52a8\u6001\u63d2\u5165\u548c\u5168\u73af\u8282\u7b97\u5b50\u878d\u5408\u7b56\u7565\uff0c\u6781\u5927\u52a0\u5feb\u5e76\u884c\u63a8\u7406\u901f\u5ea6\u3002\u5e95\u5c42\u5b9e\u73b0\u7ec6\u8282\u5c01\u88c5\u5316\uff0c\u5b9e\u73b0\u5f00\u7bb1\u5373\u7528\u7684\u9ad8\u6027\u80fd\u5e76\u884c\u63a8\u7406\u80fd\u529b\u3002\n\n------------------------------------------------------------------------------------------\n\n## \u6a21\u578b\u652f\u6301\n\n* \u6a21\u578b\u53c2\u6570\u5df2\u652f\u6301 LLaMA \u7cfb\u5217\u3001Baichuan \u7cfb\u5217\u3001Bloom \u7cfb\u5217\u3001ChatGLM \u7cfb\u5217\u3001Gemma \u7cfb\u5217\u3001Mistral \u7cfb\u5217\u3001OPT \u7cfb\u5217\u548c Qwen \u7cfb\u5217\uff0c\u8be6\u7ec6\u5217\u8868\ud83d\udc49\u3010LLM\u3011\u6a21\u578b\u53c2\u6570\u652f\u6301\u5217\u8868\u5982\u4e0b\uff1a\n\n|                                          \u6a21\u578b\u7cfb\u5217                                           | \u6a21\u578b\u540d\u79f0                                                                                                                                                                                                                                                                                                                                                                                      |\n|:-------------------------------------------------------------------------------------------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|      [LLaMA](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)       | facebook/llama-7b, facebook/llama-13b, facebook/llama-30b, facebook/llama-65b                                                                                                                                                                                                                                                                                                                 |\n|      [Llama2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)      | meta-llama/Llama-2-7b, meta-llama/Llama-2-7b-chat, meta-llama/Llama-2-13b, meta-llama/Llama-2-13b-chat, meta-llama/Llama-2-70b, meta-llama/Llama-2-70b-chat                                                                                                                                                                                                                                   |\n|      [Llama3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)      | meta-llama/Meta-Llama-3-8B, meta-llama/Meta-Llama-3-8B-Instruct, meta-llama/Meta-Llama-3-70B, meta-llama/Meta-Llama-3-70B-Instruct                                                                                                                                                                                                                                                            |\n|     [Llama3.1](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Meta-Llama-3.1-8B, meta-llama/Meta-Llama-3.1-8B-Instruct, meta-llama/Meta-Llama-3.1-70B, meta-llama/Meta-Llama-3.1-70B-Instruct, meta-llama/Meta-Llama-3.1-405B, meta-llama/Meta-Llama-3.1-405B-Instruct, meta-llama/Llama-Guard-3-8B                                                                                                                                              |\n|     [Llama3.2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Llama-3.2-1B, meta-llama/Llama-3.2-1B-Instruct, meta-llama/Llama-3.2-3B, meta-llama/Llama-3.2-3B-Instruct, meta-llama/Llama-Guard-3-1B                                                                                                                                                                                                                                             |\n|     [Llama3.3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/llama)     | meta-llama/Llama-3.3-70B-Instruct                                                                                                                                                                                                                                                                                                                                                             |\n|   [Baichuan](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/baichuan)    | baichuan-inc/Baichuan-7B, baichuan-inc/Baichuan-13B-Base, baichuan-inc/Baichuan-13B-Chat                                                                                                                                                                                                                                                                                                      |\n|   [Baichuan2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/baichuan)   | baichuan-inc/Baichuan2-7B-Base, baichuan-inc/Baichuan2-7B-Chat, baichuan-inc/Baichuan2-13B-Base, baichuan-inc/Baichuan2-13B-Chat                                                                                                                                                                                                                                                              |\n|      [Bloom](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/bloom)       | bigscience/bloom-560m, bigscience/bloom-560m-bf16, bigscience/bloom-1b1, bigscience/bloom-3b, bigscience/bloom-7b1, bigscience/bloomz-560m, bigscience/bloomz-1b1, bigscience/bloomz-3b, bigscience/bloomz-7b1-mt, bigscience/bloomz-7b1-p3, bigscience/bloomz-7b1, bellegroup/belle-7b-2m                                                                                                    |\n|    [ChatGLM](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm/)    | THUDM/chatglm-6b, THUDM/chatglm-6b-v1.1                                                                                                                                                                                                                                                                                                                                                       |\n|   [ChatGLM2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm2)    | THUDM/chatglm2-6b                                                                                                                                                                                                                                                                                                                                                                             |\n|   [ChatGLM3](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/chatglm2)    | THUDM/chatglm3-6b                                                                                                                                                                                                                                                                                                                                                                             |\n| [DeepSeekV2](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/config/deepseek-v2) | deepseek-ai/DeepSeek-V2, deepseek-ai/DeepSeek-V2-Chat, deepseek-ai/DeepSeek-V2-Lite, deepseek-ai/DeepSeek-V2-Lite-Chat, deepseek-ai/DeepSeek-Coder-V2-Base, deepseek-ai/DeepSeek-Coder-V2-Instruct, deepseek-ai/DeepSeek-Coder-V2-Lite-Base, deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct                                                                                                      |\n| [DeepSeekV3](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/llm/config/deepseek-v2) | deepseek-ai/DeepSeek-V3, deepseek-ai/DeepSeek-V3-Base                                                                                                                                                                                                                                                                                                                                         |\n|      [Gemma](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/gemma)       | google/gemma-7b, google/gemma-7b-it, google/gemma-2b, google/gemma-2b-it                                                                                                                                                                                                                                                                                                                      |\n|    [Mistral](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/mistral)     | mistralai/Mistral-7B-Instruct-v0.3, mistralai/Mistral-7B-v0.1                                                                                                                                                                                                                                                                                                                                 |\n|    [Mixtral](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/mixtral)     | mistralai/Mixtral-8x7B-Instruct-v0.1                                                                                                                                                                                                                                                                                                                                                          |\n|        [OPT](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/opt)         | facebook/opt-125m, facebook/opt-350m, facebook/opt-1.3b, facebook/opt-2.7b, facebook/opt-6.7b, facebook/opt-13b, facebook/opt-30b, facebook/opt-66b, facebook/opt-iml-1.3b, opt-iml-max-1.3b                                                                                                                                                                                                  |\n|       [Qwen](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)       | qwen/qwen-7b, qwen/qwen-7b-chat, qwen/qwen-14b, qwen/qwen-14b-chat, qwen/qwen-72b, qwen/qwen-72b-chat,                                                                                                                                                                                                                                                                                        |\n|     [Qwen1.5](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)      | Qwen/Qwen1.5-0.5B, Qwen/Qwen1.5-0.5B-Chat, Qwen/Qwen1.5-1.8B, Qwen/Qwen1.5-1.8B-Chat, Qwen/Qwen1.5-4B, Qwen/Qwen1.5-4B-Chat, Qwen/Qwen1.5-7B, Qwen/Qwen1.5-7B-Chat, Qwen/Qwen1.5-14B, Qwen/Qwen1.5-14B-Chat, Qwen/Qwen1.5-32B, Qwen/Qwen1.5-32B-Chat, Qwen/Qwen1.5-72B, Qwen/Qwen1.5-72B-Chat, Qwen/Qwen1.5-110B, Qwen/Qwen1.5-110B-Chat, Qwen/Qwen1.5-MoE-A2.7B, Qwen/Qwen1.5-MoE-A2.7B-Chat |\n|      [Qwen2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)       | Qwen/Qwen2-0.5B, Qwen/Qwen2-0.5B-Instruct, Qwen/Qwen2-1.5B, Qwen/Qwen2-1.5B-Instruct, Qwen/Qwen2-7B, Qwen/Qwen2-7B-Instruct, Qwen/Qwen2-72B, Qwen/Qwen2-72B-Instruct, Qwen/Qwen2-57B-A14B, Qwen/Qwen2-57B-A14B-Instruct                                                                                                                                                                       |\n|    [Qwen2-Math](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)    | Qwen/Qwen2-Math-1.5B, Qwen/Qwen2-Math-1.5B-Instruct, Qwen/Qwen2-Math-7B, Qwen/Qwen2-Math-7B-Instruct, Qwen/Qwen2-Math-72B, Qwen/Qwen2-Math-72B-Instruct, Qwen/Qwen2-Math-RM-72B                                                                                                                                                                                                               |\n|     [Qwen2.5](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)      | Qwen/Qwen2.5-0.5B, Qwen/Qwen2.5-0.5B-Instruct, Qwen/Qwen2.5-1.5B, Qwen/Qwen2.5-1.5B-Instruct, Qwen/Qwen2.5-3B, Qwen/Qwen2.5-3B-Instruct, Qwen/Qwen2.5-7B, Qwen/Qwen2.5-7B-Instruct, Qwen/Qwen2.5-14B, Qwen/Qwen2.5-14B-Instruct, Qwen/Qwen2.5-32B, Qwen/Qwen2.5-32B-Instruct, Qwen/Qwen2.5-72B, Qwen/Qwen2.5-72B-Instruct                                                                     |\n|   [Qwen2.5-Math](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)   | Qwen/Qwen2.5-Math-1.5B, Qwen/Qwen2.5-Math-1.5B-Instruct, Qwen/Qwen2.5-Math-7B, Qwen/Qwen2.5-Math-7B-Instruct, Qwen/Qwen2.5-Math-72B, Qwen/Qwen2.5-Math-72B-Instruct, Qwen/Qwen2.5-Math-RM-72B                                                                                                                                                                                                 |\n|  [Qwen2.5-Coder](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/qwen/)   | Qwen/Qwen2.5-Coder-1.5B, Qwen/Qwen2.5-Coder-1.5B-Instruct, Qwen/Qwen2.5-Coder-7B, Qwen/Qwen2.5-Coder-7B-Instruct                                                                                                                                                                                                                                                                              |\n|      [Yuan2](https://github.com/PaddlePaddle/PaddleNLP/tree/develop/llm/config/yuan/)       | IEITYuan/Yuan2-2B, IEITYuan/Yuan2-51B, IEITYuan/Yuan2-102B                                                                                                                                                                                                                                                                                                                                    |\n\n* 4D \u5e76\u884c\u548c\u7b97\u5b50\u4f18\u5316\u5df2\u652f\u6301 LLaMA \u7cfb\u5217\u3001Baichuan \u7cfb\u5217\u3001Bloom \u7cfb\u5217\u3001ChatGLM \u7cfb\u5217\u3001Gemma \u7cfb\u5217\u3001Mistral \u7cfb\u5217\u3001OPT \u7cfb\u5217\u548c Qwen \u7cfb\u5217\uff0c\u3010LLM\u3011\u6a21\u578b4D \u5e76\u884c\u548c\u7b97\u5b50\u652f\u6301\u5217\u8868\u5982\u4e0b\uff1a\n\n\n| \u6a21\u578b\u540d\u79f0/\u5e76\u884c\u80fd\u529b\u652f\u6301 | \u6570\u636e\u5e76\u884c | \u5f20\u91cf\u6a21\u578b\u5e76\u884c |          | \u53c2\u6570\u5206\u7247\u5e76\u884c |        |        | \u6d41\u6c34\u7ebf\u5e76\u884c |\n|:---------------------:|:--------:|:------------:|:--------:|:------------:|:------:|:------:|:----------:|\n|                       |          |   \u57fa\u7840\u80fd\u529b   | \u5e8f\u5217\u5e76\u884c |    stage1    | stage2 | stage3 |            |\n|         Llama         |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|         Qwen          |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|        Qwen1.5        |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|         Qwen2         |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|     Mixtral(moe)      |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|        Mistral        |    \u2705     |      \u2705       |    \ud83d\udea7    |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|       Baichuan        |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|       Baichuan2       |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|        ChatGLM        |    \u2705     |      \u2705       |    \ud83d\udea7    |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|       ChatGLM2        |    \u2705     |      \ud83d\udea7      |    \ud83d\udea7    |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|       ChatGLM3        |    \u2705     |      \ud83d\udea7      |    \ud83d\udea7    |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|         Bloom         |    \u2705     |      \u2705       |    \ud83d\udea7    |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|      GPT-2/GPT-3      |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|          OPT          |    \u2705     |      \u2705       |    \ud83d\udea7    |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n|         Gemma         |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \u2705      |\n|         Yuan2         |    \u2705     |      \u2705       |    \u2705     |      \u2705       |   \u2705    |   \u2705    |     \ud83d\udea7     |\n\n* \u5927\u6a21\u578b\u9884\u8bad\u7ec3\u3001\u7cbe\u8c03\uff08\u5305\u542b SFT\u3001PEFT \u6280\u672f\uff09\u3001\u5bf9\u9f50\u3001\u91cf\u5316\u5df2\u652f\u6301 LLaMA \u7cfb\u5217\u3001Baichuan \u7cfb\u5217\u3001Bloom \u7cfb\u5217\u3001ChatGLM \u7cfb\u5217\u3001Mistral \u7cfb\u5217\u3001OPT \u7cfb\u5217\u548c Qwen \u7cfb\u5217\uff0c\u3010LLM\u3011\u6a21\u578b\u9884\u8bad\u7ec3\u3001\u7cbe\u8c03\u3001\u5bf9\u9f50\u3001\u91cf\u5316\u652f\u6301\u5217\u8868\u5982\u4e0b\uff1a\n\n\n| Model                                      | Pretrain | SFT | LoRA | FlashMask | Prefix Tuning | DPO/SimPO/ORPO/KTO | RLHF | Mergekit | Quantization |\n|--------------------------------------------|:--------:|:---:|:----:|:---------:|:-------------:|:------------------:|:----:|:--------:|:------------:|\n| [Llama](./llm/config/llama)                |    \u2705     |  \u2705  |  \u2705   |     \u2705     |       \u2705       |         \u2705          |  \u2705   |    \u2705     |      \u2705       |\n| [Qwen](./llm/config/qwen)                  |    \u2705     |  \u2705  |  \u2705   |     \u2705     |       \u2705       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n| [Mixtral](./llm/config/mixtral)            |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |      \ud83d\udea7       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n| [Mistral](./llm/config/mistral)            |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |       \u2705       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n| [Baichuan/Baichuan2](./llm/config/llama)   |    \u2705     |  \u2705  |  \u2705   |     \u2705     |       \u2705       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \u2705       |\n| [ChatGLM-6B](./llm/config/chatglm)         |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |       \u2705       |         \ud83d\udea7         |  \ud83d\udea7  |    \u2705     |      \u2705       |\n| [ChatGLM2/ChatGLM3](./llm/config/chatglm2) |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |       \u2705       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \u2705       |\n| [Bloom](./llm/config/bloom)                |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |       \u2705       |         \ud83d\udea7         |  \ud83d\udea7  |    \u2705     |      \u2705       |\n| [GPT-3](./llm/config/gpt-3)                |    \u2705     |  \u2705  |  \ud83d\udea7  |    \ud83d\udea7     |      \ud83d\udea7       |         \ud83d\udea7         |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n| [OPT](./llm/config/opt)                    |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |      \ud83d\udea7       |         \ud83d\udea7         |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n| [Gemma](./llm/config/gemma)                |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |      \ud83d\udea7       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n| [Yuan](./llm/config/yuan)                  |    \u2705     |  \u2705  |  \u2705   |    \ud83d\udea7     |      \ud83d\udea7       |         \u2705          |  \ud83d\udea7  |    \u2705     |      \ud83d\udea7      |\n* [\u5927\u6a21\u578b\u63a8\u7406](./llm/docs/predict/inference.md)\u5df2\u652f\u6301 LLaMA \u7cfb\u5217\u3001Qwen \u7cfb\u5217\u3001Mistral \u7cfb\u5217\u3001ChatGLM \u7cfb\u5217\u3001Bloom \u7cfb\u5217\u548c Baichuan \u7cfb\u5217\uff0c\u652f\u6301 Weight Only INT8\u53ca INT4\u63a8\u7406\uff0c\u652f\u6301 WAC\uff08\u6743\u91cd\u3001\u6fc0\u6d3b\u3001Cache KV\uff09\u8fdb\u884c INT8\u3001FP8\u91cf\u5316\u7684\u63a8\u7406\uff0c\u3010LLM\u3011\u6a21\u578b\u63a8\u7406\u652f\u6301\u5217\u8868\u5982\u4e0b\uff1a\n\n|          \u6a21\u578b\u540d\u79f0/\u91cf\u5316\u7c7b\u578b\u652f\u6301           | FP16/BF16 | WINT8 | WINT4 | INT8-A8W8 | FP8-A8W8 | INT8-A8W8C8 |\n|:----------------------------------------:|:---------:|:-----:|:-----:|:---------:|:--------:|:-----------:|\n|   [LLaMA](./llm/docs/predict/llama.md)   |     \u2705     |   \u2705   |   \u2705   |     \u2705     |    \u2705     |      \u2705      |\n|    [Qwen](./llm/docs/predict/qwen.md)    |     \u2705     |   \u2705   |   \u2705   |     \u2705     |    \u2705     |      \u2705      |\n|  [Qwen-Moe](./llm/docs/predict/qwen.md)  |     \u2705     |   \u2705   |   \u2705   |    \ud83d\udea7     |    \ud83d\udea7    |     \ud83d\udea7      |\n| [Mixtral](./llm/docs/predict/mixtral.md) |     \u2705     |   \u2705   |   \u2705   |    \ud83d\udea7     |    \ud83d\udea7    |     \ud83d\udea7      |\n|                 ChatGLM                  |     \u2705     |   \u2705   |   \u2705   |    \ud83d\udea7     |    \ud83d\udea7    |     \ud83d\udea7      |\n|                  Bloom                   |     \u2705     |   \u2705   |   \u2705   |    \ud83d\udea7     |    \ud83d\udea7    |     \ud83d\udea7      |\n|                 BaiChuan                 |     \u2705     |   \u2705   |   \u2705   |     \u2705     |    \u2705     |     \ud83d\udea7      |\n\n## \u5b89\u88c5\n\n### \u73af\u5883\u4f9d\u8d56\n\n* python >= 3.8\n* paddlepaddle >= 3.0.0b0\n\n\u5982\u679c\u60a8\u5c1a\u672a\u5b89\u88c5 PaddlePaddle\uff0c\u8bf7\u53c2\u8003 [\u98de\u6868\u5b98\u7f51](https://www.paddlepaddle.org.cn/) \u8fdb\u884c\u5b89\u88c5\u3002\n\n### pip \u5b89\u88c5\n\n```shell\npip install --upgrade paddlenlp==3.0.0b3\n```\n\n\u6216\u8005\u53ef\u901a\u8fc7\u4ee5\u4e0b\u547d\u4ee4\u5b89\u88c5\u6700\u65b0 develop \u5206\u652f\u4ee3\u7801\uff1a\n\n```shell\npip install --pre --upgrade paddlenlp -f https://www.paddlepaddle.org.cn/whl/paddlenlp.html\n```\n\n\u66f4\u591a\u5173\u4e8e PaddlePaddle \u548c PaddleNLP \u5b89\u88c5\u7684\u8be6\u7ec6\u6559\u7a0b\u8bf7\u67e5\u770b[Installation](./docs/get_started/installation.rst)\u3002\n\n------------------------------------------------------------------------------------------\n\n## \u5feb\u901f\u5f00\u59cb\n\n### \u5927\u6a21\u578b\u6587\u672c\u751f\u6210\n\nPaddleNLP \u63d0\u4f9b\u4e86\u65b9\u4fbf\u6613\u7528\u7684 Auto API\uff0c\u80fd\u591f\u5feb\u901f\u7684\u52a0\u8f7d\u6a21\u578b\u548c Tokenizer\u3002\u8fd9\u91cc\u4ee5\u4f7f\u7528 `Qwen/Qwen2-0.5B` \u6a21\u578b\u505a\u6587\u672c\u751f\u6210\u4e3a\u4f8b\uff1a\n\n```python\n>>> from paddlenlp.transformers import AutoTokenizer, AutoModelForCausalLM\n>>> tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B\")\n>>> model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2-0.5B\", dtype=\"float16\")\n>>> input_features = tokenizer(\"\u4f60\u597d\uff01\u8bf7\u81ea\u6211\u4ecb\u7ecd\u4e00\u4e0b\u3002\", return_tensors=\"pd\")\n>>> outputs = model.generate(**input_features, max_length=128)\n>>> print(tokenizer.batch_decode(outputs[0], skip_special_tokens=True))\n['\u6211\u662f\u4e00\u4e2aAI\u8bed\u8a00\u6a21\u578b\uff0c\u6211\u53ef\u4ee5\u56de\u7b54\u5404\u79cd\u95ee\u9898\uff0c\u5305\u62ec\u4f46\u4e0d\u9650\u4e8e\uff1a\u5929\u6c14\u3001\u65b0\u95fb\u3001\u5386\u53f2\u3001\u6587\u5316\u3001\u79d1\u5b66\u3001\u6559\u80b2\u3001\u5a31\u4e50\u7b49\u3002\u8bf7\u95ee\u60a8\u6709\u4ec0\u4e48\u9700\u8981\u4e86\u89e3\u7684\u5417\uff1f']\n```\n\n### \u5927\u6a21\u578b\u9884\u8bad\u7ec3\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # \u5982\u5df2clone\u6216\u4e0b\u8f7dPaddleNLP\u53ef\u8df3\u8fc7\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.bin\nwget https://bj.bcebos.com/paddlenlp/models/transformers/llama/data/llama_openwebtext_100k.idx\ncd .. # change folder to PaddleNLP/llm\n# \u5982\u9700\u4f7f\u7528use_fused_rms_norm=true\uff0c\u9700\u8981\u524d\u5f80slm/model_zoo/gpt-3/external_ops\u5b89\u88c5fused_ln\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_pretrain.py ./config/llama/pretrain_argument.json --use_fused_rms_norm false\n```\n\n### \u5927\u6a21\u578b SFT \u7cbe\u8c03\n\n```shell\ngit clone https://github.com/PaddlePaddle/PaddleNLP.git && cd PaddleNLP # \u5982\u5df2clone\u6216\u4e0b\u8f7dPaddleNLP\u53ef\u8df3\u8fc7\nmkdir -p llm/data && cd llm/data\nwget https://bj.bcebos.com/paddlenlp/datasets/examples/AdvertiseGen.tar.gz && tar -zxvf AdvertiseGen.tar.gz\ncd .. # change folder to PaddleNLP/llm\npython -u -m paddle.distributed.launch --gpus \"0,1,2,3,4,5,6,7\" run_finetune.py ./config/llama/sft_argument.json\n```\n\n\u66f4\u591a\u5927\u6a21\u578b\u5168\u6d41\u7a0b\u6b65\u9aa4\uff0c\u8bf7\u53c2\u8003[\u98de\u6868\u5927\u6a21\u578b\u5957\u4ef6](./llm)\u4ecb\u7ecd\u3002\n\u53e6\u5916\u6211\u4eec\u8fd8\u63d0\u4f9b\u4e86\u5feb\u901f\u5fae\u8c03\u65b9\u5f0f, \u65e0\u9700 clone \u6e90\u4ee3\u7801\uff1a\n\n```python\nfrom paddlenlp.trl import SFTConfig, SFTTrainer\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"ZHUI/alpaca_demo\", split=\"train\")\n\ntraining_args = SFTConfig(output_dir=\"Qwen/Qwen2.5-0.5B-SFT\", device=\"gpu\")\ntrainer = SFTTrainer(\n    args=training_args,\n    model=\"Qwen/Qwen2.5-0.5B\",\n    train_dataset=dataset,\n)\ntrainer.train()\n```\n\n\u66f4\u591a PaddleNLP \u5185\u5bb9\u53ef\u53c2\u8003\uff1a\n\n* [\u7cbe\u9009\u6a21\u578b\u5e93](./slm/model_zoo)\uff0c\u5305\u542b\u4f18\u8d28\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u7aef\u5230\u7aef\u5168\u6d41\u7a0b\u4f7f\u7528\u3002\n* [\u591a\u573a\u666f\u793a\u4f8b](./slm/examples)\uff0c\u4e86\u89e3\u5982\u4f55\u4f7f\u7528 PaddleNLP \u89e3\u51b3 NLP \u591a\u79cd\u6280\u672f\u95ee\u9898\uff0c\u5305\u542b\u57fa\u7840\u6280\u672f\u3001\u7cfb\u7edf\u5e94\u7528\u4e0e\u62d3\u5c55\u5e94\u7528\u3002\n* [\u4ea4\u4e92\u5f0f\u6559\u7a0b](https://aistudio.baidu.com/aistudio/personalcenter/thirdview/574995)\uff0c\u5728\ud83c\udd93\u514d\u8d39\u7b97\u529b\u5e73\u53f0 AI Studio \u4e0a\u5feb\u901f\u5b66\u4e60 PaddleNLP\u3002\n\n------------------------------------------------------------------------------------------\n\n## \u793e\u533a\u4ea4\u6d41\n\n* \u5fae\u4fe1\u626b\u63cf\u4e8c\u7ef4\u7801\u5e76\u586b\u5199\u95ee\u5377\uff0c\u5373\u53ef\u52a0\u5165\u4ea4\u6d41\u7fa4\u4e0e\u4f17\u591a\u793e\u533a\u5f00\u53d1\u8005\u4ee5\u53ca\u5b98\u65b9\u56e2\u961f\u6df1\u5ea6\u4ea4\u6d41.\n\n<div align=\"center\">\n    <img src=\"https://github.com/user-attachments/assets/3a58cc9f-69c7-4ccb-b6f5-73e966b8051a\" width=\"150\" height=\"150\" />\n</div>\n\n## Citation\n\n\u5982\u679c PaddleNLP \u5bf9\u60a8\u7684\u7814\u7a76\u6709\u5e2e\u52a9\uff0c\u6b22\u8fce\u5f15\u7528\n\n```bibtex\n@misc{=paddlenlp,\n    title={PaddleNLP: An Easy-to-use and High Performance NLP Library},\n    author={PaddleNLP Contributors},\n    howpublished = {\\url{https://github.com/PaddlePaddle/PaddleNLP}},\n    year={2021}\n}\n```\n\n## Acknowledge\n\n\u6211\u4eec\u501f\u9274\u4e86 Hugging Face \u7684[Transformers](https://github.com/huggingface/transformers)\ud83e\udd17\u5173\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u4f7f\u7528\u7684\u4f18\u79c0\u8bbe\u8ba1\uff0c\u5728\u6b64\u5bf9 Hugging Face \u4f5c\u8005\u53ca\u5176\u5f00\u6e90\u793e\u533a\u8868\u793a\u611f\u8c22\u3002\n\n## License\n\nPaddleNLP \u9075\u5faa[Apache-2.0\u5f00\u6e90\u534f\u8bae](./LICENSE)\u3002\n",
        "releases": [
            {
                "name": "v3.0.0-beta3",
                "date": "2024-12-16T09:35:00Z"
            },
            {
                "name": "v3.0.0-beta2",
                "date": "2024-10-08T08:52:31Z"
            },
            {
                "name": "v3.0.0-beta1",
                "date": "2024-08-22T03:41:34Z"
            },
            {
                "name": "v3.0.0-beta0",
                "date": "2024-06-28T03:05:46Z"
            },
            {
                "name": "v2.8.1",
                "date": "2024-06-20T07:42:46Z"
            },
            {
                "name": "v2.8.0",
                "date": "2024-04-24T10:04:41Z"
            },
            {
                "name": "v2.7.2 ",
                "date": "2024-01-30T07:50:22Z"
            },
            {
                "name": "v2.7.1",
                "date": "2024-01-04T14:24:29Z"
            },
            {
                "name": "PaddleNLP 2.7.0 Release Note",
                "date": "2024-01-03T04:07:25Z"
            },
            {
                "name": "v2.6.1",
                "date": "2023-09-14T03:57:43Z"
            },
            {
                "name": "v2.6.0",
                "date": "2023-08-15T13:11:37Z"
            },
            {
                "name": "PaddleNLP v2.6.0rc",
                "date": "2023-06-12T03:23:17Z"
            },
            {
                "name": "PaddleNLP v2.5.2",
                "date": "2023-03-07T08:43:24Z"
            },
            {
                "name": "PaddleNLP v2.5.1",
                "date": "2023-02-17T12:38:30Z"
            },
            {
                "name": "PaddleNLP v2.5.0",
                "date": "2023-01-12T17:20:36Z"
            },
            {
                "name": "PaddleNLP v2.4.9",
                "date": "2022-12-30T05:43:30Z"
            },
            {
                "name": "PaddleNLP v2.4.8",
                "date": "2022-12-26T11:12:09Z"
            },
            {
                "name": "PaddleNLP v2.4.7",
                "date": "2022-12-23T12:34:32Z"
            },
            {
                "name": "PaddleNLP v2.4.5",
                "date": "2022-12-09T11:34:15Z"
            },
            {
                "name": "PaddleNLP v2.4.4",
                "date": "2022-11-28T11:59:50Z"
            },
            {
                "name": "PaddleNLP v2.4.3",
                "date": "2022-11-18T02:23:40Z"
            },
            {
                "name": "PaddleNLP v2.4.2",
                "date": "2022-10-27T13:39:56Z"
            },
            {
                "name": "PaddleNLP v2.4.1",
                "date": "2022-10-14T10:45:51Z"
            },
            {
                "name": "PaddleNLP v2.4.0",
                "date": "2022-09-06T11:19:07Z"
            },
            {
                "name": "PaddleNLP v2.3.6",
                "date": "2022-08-24T08:45:12Z"
            },
            {
                "name": "PaddleNLP v2.3.5",
                "date": "2022-08-01T13:02:58Z"
            },
            {
                "name": "PaddleNLP v2.3.4",
                "date": "2022-06-28T11:22:23Z"
            },
            {
                "name": "PaddleNLP v2.3.3",
                "date": "2022-06-07T10:52:27Z"
            },
            {
                "name": "PaddleNLP v2.3.2",
                "date": "2022-06-02T13:34:44Z"
            },
            {
                "name": "PaddleNLP v2.3.1",
                "date": "2022-05-19T11:56:29Z"
            },
            {
                "name": "PaddleNLP v2.3.0",
                "date": "2022-05-16T05:14:48Z"
            },
            {
                "name": "PaddleNLP v2.2.6",
                "date": "2022-04-15T15:42:31Z"
            },
            {
                "name": "v2.2.5",
                "date": "2022-03-21T13:13:16Z"
            },
            {
                "name": "PaddleNLP v2.2.4",
                "date": "2022-01-26T10:05:34Z"
            },
            {
                "name": "PaddleNLP v2.2.2",
                "date": "2021-12-28T10:26:16Z"
            },
            {
                "name": "PaddleNLP v2.2.1",
                "date": "2021-12-17T09:50:34Z"
            },
            {
                "name": "PaddleNLP v2.2.0",
                "date": "2021-12-10T17:51:56Z"
            },
            {
                "name": "PaddleNLP v2.1.1",
                "date": "2021-10-20T13:56:27Z"
            },
            {
                "name": "PaddleNLP v2.1.0",
                "date": "2021-10-11T18:32:34Z"
            },
            {
                "name": "PaddleNLP v2.0.8",
                "date": "2021-08-22T13:07:00Z"
            },
            {
                "name": "PaddleNLP v2.0.7",
                "date": "2021-08-02T02:45:19Z"
            },
            {
                "name": "PaddleNLP v2.0.6",
                "date": "2021-07-20T13:15:27Z"
            },
            {
                "name": "PaddleNLP v2.0.5",
                "date": "2021-06-29T06:22:06Z"
            },
            {
                "name": "PaddleNLP v2.0.4",
                "date": "2021-06-29T06:09:35Z"
            },
            {
                "name": "PaddleNLP v2.0.3",
                "date": "2021-06-17T15:21:24Z"
            },
            {
                "name": "PaddleNLP v2.0.2",
                "date": "2021-06-04T07:24:28Z"
            },
            {
                "name": "PaddleNLP v2.0.0",
                "date": "2021-05-20T08:42:48Z"
            }
        ]
    }
}