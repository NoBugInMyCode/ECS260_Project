{
    "https://api.github.com/repos/codelucas/newspaper": {
        "forks": 2114,
        "watchers": 14298,
        "stars": 14298,
        "languages": {
            "Python": 167885
        },
        "commits": [
            "2020-09-02T06:54:25Z",
            "2020-07-13T01:16:14Z",
            "2020-07-05T02:34:46Z",
            "2020-07-03T19:10:45Z",
            "2020-07-03T19:09:51Z",
            "2020-07-03T19:04:24Z",
            "2020-06-28T02:49:08Z",
            "2020-06-26T05:47:35Z",
            "2020-06-22T23:36:27Z",
            "2020-06-22T23:35:16Z",
            "2020-06-22T20:38:44Z",
            "2020-06-20T18:59:42Z",
            "2019-04-12T12:23:13Z",
            "2019-04-07T20:31:52Z",
            "2019-04-07T20:00:31Z",
            "2019-03-17T00:58:27Z",
            "2019-03-17T00:56:20Z",
            "2019-03-17T00:53:04Z",
            "2019-03-11T01:26:19Z",
            "2019-03-11T01:22:26Z",
            "2019-01-05T04:30:09Z",
            "2018-12-27T15:06:06Z",
            "2018-12-04T15:02:26Z",
            "2018-12-03T15:48:31Z",
            "2018-10-28T20:25:14Z",
            "2018-10-27T22:09:09Z",
            "2018-10-26T18:37:14Z",
            "2018-10-11T11:50:14Z",
            "2018-10-04T05:11:50Z",
            "2018-09-28T05:03:59Z"
        ],
        "creation_date": "2013-11-25T09:50:50Z",
        "contributors": 30,
        "topics": [
            "crawler",
            "crawling",
            "news",
            "news-aggregator",
            "python",
            "scraper"
        ],
        "subscribers": 384,
        "readme": "Newspaper3k: Article scraping & curation\n========================================\n\n.. image:: https://badge.fury.io/py/newspaper3k.svg\n    :target: http://badge.fury.io/py/newspaper3k.svg\n        :alt: Latest version\n\n.. image:: https://travis-ci.org/codelucas/newspaper.svg\n        :target: http://travis-ci.org/codelucas/newspaper/\n        :alt: Build status\n\n.. image:: https://coveralls.io/repos/github/codelucas/newspaper/badge.svg?branch=master\n        :target: https://coveralls.io/github/codelucas/newspaper\n        :alt: Coverage status\n\n\nInspired by `requests`_ for its simplicity and powered by `lxml`_ for its speed:\n\n    \"Newspaper is an amazing python library for extracting & curating articles.\"\n    -- `tweeted by`_ Kenneth Reitz, Author of `requests`_\n\n    \"Newspaper delivers Instapaper style article extraction.\" -- `The Changelog`_\n\n.. _`tweeted by`: https://twitter.com/kennethreitz/status/419520678862548992\n.. _`The Changelog`: http://thechangelog.com/newspaper-delivers-instapaper-style-article-extraction/\n\n**Newspaper is a Python3 library**! Or, view our **deprecated and buggy** `Python2 branch`_\n\n.. _`Python2 branch`: https://github.com/codelucas/newspaper/tree/python-2-head\n\nA Glance:\n---------\n\n.. code-block:: pycon\n\n    >>> from newspaper import Article\n\n    >>> url = 'http://fox13now.com/2013/12/30/new-year-new-laws-obamacare-pot-guns-and-drones/'\n    >>> article = Article(url)\n\n.. code-block:: pycon\n\n    >>> article.download()\n\n    >>> article.html\n    '<!DOCTYPE HTML><html itemscope itemtype=\"http://...'\n\n.. code-block:: pycon\n\n    >>> article.parse()\n\n    >>> article.authors\n    ['Leigh Ann Caldwell', 'John Honway']\n\n    >>> article.publish_date\n    datetime.datetime(2013, 12, 30, 0, 0)\n\n    >>> article.text\n    'Washington (CNN) -- Not everyone subscribes to a New Year's resolution...'\n\n    >>> article.top_image\n    'http://someCDN.com/blah/blah/blah/file.png'\n\n    >>> article.movies\n    ['http://youtube.com/path/to/link.com', ...]\n\n.. code-block:: pycon\n\n    >>> article.nlp()\n\n    >>> article.keywords\n    ['New Years', 'resolution', ...]\n\n    >>> article.summary\n    'The study shows that 93% of people ...'\n\n.. code-block:: pycon\n\n    >>> import newspaper\n\n    >>> cnn_paper = newspaper.build('http://cnn.com')\n\n    >>> for article in cnn_paper.articles:\n    >>>     print(article.url)\n    http://www.cnn.com/2013/11/27/justice/tucson-arizona-captive-girls/\n    http://www.cnn.com/2013/12/11/us/texas-teen-dwi-wreck/index.html\n    ...\n\n    >>> for category in cnn_paper.category_urls():\n    >>>     print(category)\n\n    http://lifestyle.cnn.com\n    http://cnn.com/world\n    http://tech.cnn.com\n    ...\n\n    >>> cnn_article = cnn_paper.articles[0]\n    >>> cnn_article.download()\n    >>> cnn_article.parse()\n    >>> cnn_article.nlp()\n    ...\n\n.. code-block:: pycon\n\n    >>> from newspaper import fulltext\n\n    >>> html = requests.get(...).text\n    >>> text = fulltext(html)\n\n\nNewspaper can extract and detect languages *seamlessly*.\nIf no language is specified, Newspaper will attempt to auto detect a language.\n\n.. code-block:: pycon\n\n    >>> from newspaper import Article\n    >>> url = 'http://www.bbc.co.uk/zhongwen/simp/chinese_news/2012/12/121210_hongkong_politics.shtml'\n\n    >>> a = Article(url, language='zh') # Chinese\n\n    >>> a.download()\n    >>> a.parse()\n\n    >>> print(a.text[:150])\n    \u9999\u6e2f\u884c\u653f\u957f\u5b98\u6881\u632f\u82f1\u5728\u5404\u65b9\u538b\u529b\u4e0b\u5c31\u5176\u5927\u5b85\u7684\u8fdd\u7ae0\u5efa\n    \u7b51\uff08\u50ed\u5efa\uff09\u95ee\u9898\u5230\u7acb\u6cd5\u4f1a\u63a5\u53d7\u8d28\u8be2\uff0c\u5e76\u5411\u9999\u6e2f\u6c11\u4f17\u9053\u6b49\u3002\n    \u6881\u632f\u82f1\u5728\u661f\u671f\u4e8c\uff0812\u670810\u65e5\uff09\u7684\u7b54\u95ee\u5927\u4f1a\u5f00\u59cb\u4e4b\u9645\n    \u5728\u5176\u6f14\u8bf4\u4e2d\u9053\u6b49\uff0c\u4f46\u5f3a\u8c03\u4ed6\u5728\u8fdd\u7ae0\u5efa\u7b51\u95ee\u9898\u4e0a\u6ca1\u6709\u9690\u7792\u7684\n    \u610f\u56fe\u548c\u52a8\u673a\u3002 \u4e00\u4e9b\u4eb2\u5317\u4eac\u9635\u8425\u8bae\u5458\u6b22\u8fce\u6881\u632f\u82f1\u9053\u6b49\uff0c\n    \u4e14\u8ba4\u4e3a\u5e94\u80fd\u83b7\u5f97\u9999\u6e2f\u6c11\u4f17\u63a5\u53d7\uff0c\u4f46\u8fd9\u4e9b\u8bae\u5458\u4e5f\u8d28\u95ee\u6881\u632f\u82f1\u6709\n\n    >>> print(a.title)\n    \u6e2f\u7279\u9996\u6881\u632f\u82f1\u5c31\u4f4f\u5b85\u8fdd\u5efa\u4e8b\u4ef6\u9053\u6b49\n\n\nIf you are certain that an *entire* news source is in one language, **go ahead and use the same api :)**\n\n.. code-block:: pycon\n\n    >>> import newspaper\n    >>> sina_paper = newspaper.build('http://www.sina.com.cn/', language='zh')\n\n    >>> for category in sina_paper.category_urls():\n    >>>     print(category)\n    http://health.sina.com.cn\n    http://eladies.sina.com.cn\n    http://english.sina.com\n    ...\n\n    >>> article = sina_paper.articles[0]\n    >>> article.download()\n    >>> article.parse()\n\n    >>> print(article.text)\n    \u65b0\u6d6a\u6b66\u6c49\u6c7d\u8f66\u7efc\u5408 \u968f\u7740\u6c7d\u8f66\u5e02\u573a\u7684\u65e5\u8d8b\u6210\u719f\uff0c\n    \u4f20\u7edf\u7684\u201c\u96c6\u5168\u5bb6\u4e4b\u529b\u62b1\u5f97\u7231\u8f66\u5f52\u201d\u7684\u5168\u989d\u8d2d\u8f66\u6a21\u5f0f\u5df2\u7136\u8fc7\u65f6\uff0c\n    \u53e6\u4e00\u79cd\u8f7b\u677e\u7684\u65b0\u5174 \u8f66\u6a21\u5f0f\u2015\u2015\u91d1\u878d\u8d2d\u8f66\u6b63\u9010\u6b65\u6210\u4e3a\u65f6\u4e0b\u6d88\u8d39\u8005\u8d2d\n    \u4e70\u7231\u8f66\u6700\u4e3a\u65f6\u5c1a\u7684\u6d88\u8d39\u7406\u5ff5\uff0c\u4ed6\u4eec\u8ba4\u4e3a\uff0c\u8fd9\u79cd\u65b0\u9896\u7684\u8d2d\u8f66\n    \u6a21\u5f0f\u65e2\u80fd\u5728\u77ed\u671f\u5185\n    ...\n\n    >>> print(article.title)\n    \u4e24\u5e74\u53cc\u514d0\u624b\u7eed0\u5229\u7387 \u79d1\u9c81\u5179\u6380\u80cc\u91d1\u878d\u8f7b\u677e\u8d2d_\u6b66\u6c49\u8f66\u5e02_\u6b66\u6c49\u6c7d\n    \u8f66\u7f51_\u65b0\u6d6a\u6c7d\u8f66_\u65b0\u6d6a\u7f51\n\nSupport our library\n-------------------\n`It takes only one click`_\n\nDocs\n----\n\nCheck out `The Docs`_ for full and detailed guides using newspaper.\n\nInterested in adding a new language for us? Refer to: `Docs - Adding new languages <https://newspaper.readthedocs.io/en/latest/user_guide/advanced.html#adding-new-languages>`_\n\nFeatures\n--------\n\n- Multi-threaded article download framework\n- News url identification\n- Text extraction from html\n- Top image extraction from html\n- All image extraction from html\n- Keyword extraction from text\n- Summary extraction from text\n- Author extraction from text\n- Google trending terms extraction\n- Works in 10+ languages (English, Chinese, German, Arabic, ...)\n\n.. code-block:: pycon\n\n    >>> import newspaper\n    >>> newspaper.languages()\n\n    Your available languages are:\n    input code      full name\n\n      ar              Arabic\n      be              Belarusian\n      bg              Bulgarian\n      da              Danish\n      de              German\n      el              Greek\n      en              English\n      es              Spanish\n      et              Estonian\n      fa              Persian\n      fi              Finnish\n      fr              French\n      he              Hebrew\n      hi              Hindi\n      hr              Croatian\n      hu              Hungarian\n      id              Indonesian\n      it              Italian\n      ja              Japanese\n      ko              Korean\n      lt              Lithuanian\n      mk              Macedonian\n      nb              Norwegian (Bokm\u00e5l)\n      nl              Dutch\n      no              Norwegian\n      pl              Polish\n      pt              Portuguese\n      ro              Romanian\n      ru              Russian\n      sl              Slovenian\n      sr              Serbian\n      sv              Swedish\n      sw              Swahili\n      th              Thai\n      tr              Turkish\n      uk              Ukrainian\n      vi              Vietnamese\n      zh              Chinese\n\n\nGet it now\n----------\n\nRun \u2705 ``pip3 install newspaper3k`` \u2705\n\nNOT \u26d4 ``pip3 install newspaper`` \u26d4\n\nOn python3 you must install ``newspaper3k``, **not** ``newspaper``. ``newspaper`` is our python2 library.\nAlthough installing newspaper is simple with `pip <http://www.pip-installer.org/>`_, you will\nrun into fixable issues if you are trying to install on ubuntu.\n\n**If you are on Debian / Ubuntu**, install using the following:\n\n- Install ``pip3`` command needed to install ``newspaper3k`` package::\n\n    $ sudo apt-get install python3-pip\n\n- Python development version, needed for Python.h::\n\n    $ sudo apt-get install python-dev\n\n- lxml requirements::\n\n    $ sudo apt-get install libxml2-dev libxslt-dev\n\n- For PIL to recognize .jpg images::\n\n    $ sudo apt-get install libjpeg-dev zlib1g-dev libpng12-dev\n\nNOTE: If you find problem installing ``libpng12-dev``, try installing ``libpng-dev``.\n\n- Download NLP related corpora::\n\n    $ curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python3\n\n- Install the distribution via pip::\n\n    $ pip3 install newspaper3k\n\n**If you are on OSX**, install using the following, you may use both homebrew or macports:\n\n::\n\n    $ brew install libxml2 libxslt\n\n    $ brew install libtiff libjpeg webp little-cms2\n\n    $ pip3 install newspaper3k\n\n    $ curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python3\n\n\n**Otherwise**, install with the following:\n\nNOTE: You will still most likely need to install the following libraries via your package manager\n\n- PIL: ``libjpeg-dev`` ``zlib1g-dev`` ``libpng12-dev``\n- lxml: ``libxml2-dev`` ``libxslt-dev``\n- Python Development version: ``python-dev``\n\n::\n\n    $ pip3 install newspaper3k\n\n    $ curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python3\n\nDonations\n---------\n\nYour donations are greatly appreciated! They will free me up to work on this project more,\nto take on things like: adding new features, bug-fix support, addressing concerns with the library.\n\n- My PayPal link: `https://www.paypal.me/codelucas`_\n- My `Venmo`_ handle: @Lucas-Ou-Yang\n\nDevelopment\n-----------\n\nIf you'd like to contribute and hack on the newspaper project, feel free to clone\na development version of this repository locally::\n\n    git clone git://github.com/codelucas/newspaper.git\n\nOnce you have a copy of the source, you can embed it in your Python package,\nor install it into your site-packages easily::\n\n    $ pip3 install -r requirements.txt\n    $ python3 setup.py install\n\nFeel free to give our testing suite a shot, everything is mocked!::\n\n    $ python3 tests/unit_tests.py\n\nPlanning on tweaking our full-text algorithm? Add the ``fulltext`` parameter::\n\n    $ python3 tests/unit_tests.py fulltext\n\n\nDemo\n----\n\nView a working online demo here: http://newspaper-demo.herokuapp.com\n\nThis is another working online demo: http://newspaper.chinazt.cc/\n\nLICENSE\n-------\n\nAuthored and maintained by `Lucas Ou-Yang`_.\n\n`Parse.ly`_ sponsored some work on newspaper, specifically focused on\nautomatic extraction.\n\nNewspaper uses a lot of `python-goose's`_ parsing code. View their license `here`_.\n\nPlease feel free to `email & contact me`_ if you run into issues or just would like\nto talk about the future of this library and news extraction in general!\n\n.. _`Lucas Ou-Yang`: http://codelucas.com\n.. _`email & contact me`: mailto:lucasyangpersonal@gmail.com\n.. _`python-goose's`: https://github.com/grangier/python-goose\n.. _`here`: https://github.com/codelucas/newspaper/blob/master/GOOSE-LICENSE.txt\n\n.. _`https://www.paypal.me/codelucas`: https://www.paypal.me/codelucas\n.. _`Venmo`: https://www.venmo.com/Lucas-Ou-Yang\n\n.. _`Quickstart guide`: https://newspaper.readthedocs.io/en/latest/\n.. _`The Docs`: https://newspaper.readthedocs.io\n.. _`lxml`: http://lxml.de/\n.. _`requests`: https://github.com/kennethreitz/requests\n.. _`Parse.ly`: http://parse.ly\n.. _`It takes only one click`: https://tracking.gitads.io/?campaign=gitads&repo=newspaper&redirect=gitads.io\n",
        "releases": [
            {
                "name": "End of Python 2 support",
                "date": "2014-12-17T19:19:47Z"
            },
            {
                "name": "Bugfixes, better documentation",
                "date": "2014-10-13T00:16:42Z"
            }
        ]
    }
}