{
    "https://api.github.com/repos/CMU-Perceptual-Computing-Lab/openpose": {
        "forks": 7895,
        "watchers": 31696,
        "stars": 31696,
        "languages": {
            "C++": 2242455,
            "Cuda": 140391,
            "CMake": 94680,
            "Shell": 42126,
            "HCL": 2146,
            "Batchfile": 1615,
            "Python": 40
        },
        "commits": [
            "2024-08-03T01:40:45Z",
            "2024-04-15T13:47:50Z",
            "2024-03-02T02:16:28Z",
            "2024-01-09T14:04:19Z",
            "2023-12-11T12:13:22Z",
            "2023-12-11T12:03:42Z",
            "2023-12-06T11:57:33Z",
            "2023-07-15T13:50:23Z",
            "2023-06-22T02:27:02Z",
            "2023-06-22T02:26:26Z",
            "2023-04-22T20:38:12Z",
            "2022-10-23T22:36:13Z",
            "2022-10-17T23:23:04Z",
            "2022-09-30T04:54:10Z",
            "2022-09-17T15:31:32Z",
            "2022-09-17T15:15:01Z",
            "2022-06-19T20:28:30Z",
            "2022-06-10T20:18:00Z",
            "2022-06-10T20:12:36Z",
            "2022-05-17T18:53:03Z",
            "2022-03-24T14:59:56Z",
            "2022-03-14T03:44:58Z",
            "2022-03-13T15:07:42Z",
            "2022-03-11T21:06:42Z",
            "2022-01-09T16:40:43Z",
            "2021-12-03T04:35:54Z",
            "2021-11-30T16:05:01Z",
            "2021-11-29T16:15:09Z",
            "2021-11-19T16:50:55Z",
            "2021-09-25T15:23:01Z"
        ],
        "creation_date": "2017-04-24T14:06:31Z",
        "contributors": 30,
        "topics": [
            "caffe",
            "computer-vision",
            "cpp",
            "cvpr-2017",
            "deep-learning",
            "face",
            "foot-estimation",
            "hand-estimation",
            "human-behavior-understanding",
            "human-pose",
            "human-pose-estimation",
            "keypoint-detection",
            "keypoints",
            "machine-learning",
            "multi-person",
            "opencv",
            "openpose",
            "pose",
            "pose-estimation",
            "real-time"
        ],
        "subscribers": 923,
        "readme": "<div align=\"center\">\n    <img src=\".github/Logo_main_black.png\" width=\"300\">\n</div>\n\n-----------------\n\n| **Build Type**   |`Linux`           |`MacOS`           |`Windows`         |\n| :---:            | :---:            | :---:            | :---:            |\n| **Build Status** | [![Status](https://github.com/CMU-Perceptual-Computing-Lab/openpose/workflows/CI/badge.svg)](https://github.com/CMU-Perceptual-Computing-Lab/openpose/actions) | [![Status](https://github.com/CMU-Perceptual-Computing-Lab/openpose/workflows/CI/badge.svg)](https://github.com/CMU-Perceptual-Computing-Lab/openpose/actions) | [![Status](https://ci.appveyor.com/api/projects/status/5leescxxdwen77kg/branch/master?svg=true)](https://ci.appveyor.com/project/gineshidalgo99/openpose/branch/master) |\n\n[**OpenPose**](https://github.com/CMU-Perceptual-Computing-Lab/openpose) has represented the **first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints (in total 135 keypoints) on single images**.\n\nIt is **authored by** [**Gin\u00e9s Hidalgo**](https://www.gineshidalgo.com), [**Zhe Cao**](https://people.eecs.berkeley.edu/~zhecao), [**Tomas Simon**](http://www.cs.cmu.edu/~tsimon), [**Shih-En Wei**](https://scholar.google.com/citations?user=sFQD3k4AAAAJ&hl=en), [**Yaadhav Raaj**](https://www.raaj.tech), [**Hanbyul Joo**](https://jhugestar.github.io), **and** [**Yaser Sheikh**](http://www.cs.cmu.edu/~yaser). It is **maintained by** [**Gin\u00e9s Hidalgo**](https://www.gineshidalgo.com) **and** [**Yaadhav Raaj**](https://www.raaj.tech). OpenPose would not be possible without the [**CMU Panoptic Studio dataset**](http://domedb.perception.cs.cmu.edu). We would also like to thank all the people who [have helped OpenPose in any way](doc/09_authors_and_contributors.md).\n\n\n\n<p align=\"center\">\n    <img src=\".github/media/pose_face_hands.gif\" width=\"480\">\n    <br>\n    <sup>Authors <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gin\u00e9s Hidalgo</a> (left) and <a href=\"https://jhugestar.github.io\" target=\"_blank\">Hanbyul Joo</a> (right) in front of the <a href=\"http://domedb.perception.cs.cmu.edu\" target=\"_blank\">CMU Panoptic Studio</a></sup>\n</p>\n\n\n\n## Contents\n1. [Results](#results)\n2. [Features](#features)\n3. [Related Work](#related-work)\n4. [Installation](#installation)\n5. [Quick Start Overview](#quick-start-overview)\n6. [Send Us Feedback!](#send-us-feedback)\n7. [Citation](#citation)\n8. [License](#license)\n\n\n\n## Results\n### Whole-body (Body, Foot, Face, and Hands) 2D Pose Estimation\n<p align=\"center\">\n    <img src=\".github/media/dance_foot.gif\" width=\"300\">\n    <img src=\".github/media/pose_face.gif\" width=\"300\">\n    <img src=\".github/media/pose_hands.gif\" width=\"300\">\n    <br>\n    <sup>Testing OpenPose: (Left) <a href=\"https://www.youtube.com/watch?v=2DiQUX11YaY\" target=\"_blank\"><i>Crazy Uptown Funk flashmob in Sydney</i></a> video sequence. (Center and right) Authors <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gin\u00e9s Hidalgo</a> and <a href=\"http://www.cs.cmu.edu/~tsimon\" target=\"_blank\">Tomas Simon</a> testing face and hands</sup>\n</p>\n\n### Whole-body 3D Pose Reconstruction and Estimation\n<p align=\"center\">\n    <img src=\".github/media/openpose3d.gif\" width=\"360\">\n    <br>\n    <sup><a href=\"https://ziutinyat.github.io/\" target=\"_blank\">Tianyi Zhao</a> testing the OpenPose 3D Module</a></sup>\n</p>\n\n### Unity Plugin\n<p align=\"center\">\n    <img src=\".github/media/unity_main.png\" width=\"300\">\n    <img src=\".github/media/unity_body_foot.png\" width=\"300\">\n    <img src=\".github/media/unity_hand_face.png\" width=\"300\">\n    <br>\n    <sup><a href=\"https://ziutinyat.github.io/\" target=\"_blank\">Tianyi Zhao</a> and <a href=\"https://www.gineshidalgo.com\" target=\"_blank\">Gin\u00e9s Hidalgo</a> testing the <a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin\" target=\"_blank\">OpenPose Unity Plugin</a></sup>\n</p>\n\n### Runtime Analysis\nWe show an inference time comparison between the 3 available pose estimation libraries (same hardware and conditions): OpenPose, Alpha-Pose (fast Pytorch version), and Mask R-CNN. The OpenPose runtime is constant, while the runtime of Alpha-Pose and Mask R-CNN grow linearly with the number of people. More details [**here**](https://arxiv.org/abs/1812.08008).\n\n<p align=\"center\">\n    <img src=\".github/media/openpose_vs_competition.png\" width=\"360\">\n</p>\n\n\n\n## Features\n**Main Functionality**:\n- **2D real-time multi-person keypoint detection**:\n    - 15, 18 or **25-keypoint body/foot keypoint estimation**, including **6 foot keypoints**. **Runtime invariant to number of detected people**.\n    - **2x21-keypoint hand keypoint estimation**. **Runtime depends on number of detected people**. See [**OpenPose Training**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train) for a runtime invariant alternative.\n    - **70-keypoint face keypoint estimation**. **Runtime depends on number of detected people**. See [**OpenPose Training**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train) for a runtime invariant alternative.\n- [**3D real-time single-person keypoint detection**](doc/advanced/3d_reconstruction_module.md):\n    - 3D triangulation from multiple single views.\n    - Synchronization of Flir cameras handled.\n    - Compatible with Flir/Point Grey cameras.\n- [**Calibration toolbox**](doc/advanced/calibration_module.md): Estimation of distortion, intrinsic, and extrinsic camera parameters.\n- **Single-person tracking** for further speedup or visual smoothing.\n\n**Input**: Image, video, webcam, Flir/Point Grey, IP camera, and support to add your own custom input source (e.g., depth camera).\n\n**Output**: Basic image + keypoint display/saving (PNG, JPG, AVI, ...), keypoint saving (JSON, XML, YML, ...), keypoints as array class, and support to add your own custom output code (e.g., some fancy UI).\n\n**OS**: Ubuntu (20, 18, 16, 14), Windows (10, 8), Mac OSX, Nvidia TX2.\n\n**Hardware compatibility**: CUDA (Nvidia GPU), OpenCL (AMD GPU), and non-GPU (CPU-only) versions.\n\n**Usage Alternatives**:\n- [**Command-line demo**](doc/01_demo.md) for built-in functionality.\n- [**C++ API**](doc/04_cpp_api.md/) and [**Python API**](doc/03_python_api.md) for custom functionality. E.g., adding your custom inputs, pre-processing, post-posprocessing, and output steps.\n\nFor further details, check the [major released features](doc/07_major_released_features.md) and [release notes](doc/08_release_notes.md) docs.\n\n\n\n## Related Work\n- [**OpenPose training code**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_train)\n- [**OpenPose foot dataset**](https://cmu-perceptual-computing-lab.github.io/foot_keypoint_dataset/)\n- [**OpenPose Unity Plugin**](https://github.com/CMU-Perceptual-Computing-Lab/openpose_unity_plugin)\n- OpenPose papers published in **IEEE TPAMI and CVPR**. Cite them in your publications if OpenPose helps your research! (Links and more details in the [Citation](#citation) section below).\n\n\n\n## Installation\nIf you want to use OpenPose without installing or writing any code, simply [download and use the latest Windows portable version of OpenPose](doc/installation/0_index.md#windows-portable-demo)!\n\nOtherwise, you could [build OpenPose from source](doc/installation/0_index.md#compiling-and-running-openpose-from-source). See the [installation doc](doc/installation/0_index.md) for all the alternatives.\n\n\n\n## Quick Start Overview\nSimply use the OpenPose Demo from your favorite command-line tool (e.g., Windows PowerShell or Ubuntu Terminal). E.g., this example runs OpenPose on your webcam and displays the body keypoints:\n```\n# Ubuntu\n./build/examples/openpose/openpose.bin\n```\n```\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi\n```\n\nYou can also add any of the available flags in any order. E.g., the following example runs on a video (`--video {PATH}`), enables face (`--face`) and hands (`--hand`), and saves the output keypoints on JSON files on disk (`--write_json {PATH}`).\n```\n# Ubuntu\n./build/examples/openpose/openpose.bin --video examples/media/video.avi --face --hand --write_json output_json_folder/\n```\n```\n:: Windows - Portable Demo\nbin\\OpenPoseDemo.exe --video examples\\media\\video.avi --face --hand --write_json output_json_folder/\n```\n\nOptionally, you can also extend OpenPose's functionality from its Python and C++ APIs. After [installing](doc/installation/0_index.md) OpenPose, check its [official doc](doc/00_index.md) for a quick overview of all the alternatives and tutorials.\n\n\n\n## Send Us Feedback!\nOur library is open source for research purposes, and we want to improve it! So let us know (create a new GitHub issue or pull request, email us, etc.) if you...\n1. Find/fix any bug (in functionality or speed) or know how to speed up or improve any part of OpenPose.\n2. Want to add/show some cool functionality/demo/project made on top of OpenPose. We can add your project link to our [Community-based Projects](doc/10_community_projects.md) section or even integrate it with OpenPose!\n\n\n\n## Citation\nPlease cite these papers in your publications if OpenPose helps your research. All of OpenPose is based on [OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1812.08008), while the hand and face detectors also use [Hand Keypoint Detection in Single Images using Multiview Bootstrapping](https://arxiv.org/abs/1704.07809) (the face detector was trained using the same procedure as the hand detector).\n\n    @article{8765346,\n      author = {Z. {Cao} and G. {Hidalgo Martinez} and T. {Simon} and S. {Wei} and Y. A. {Sheikh}},\n      journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},\n      title = {OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n      year = {2019}\n    }\n\n    @inproceedings{simon2017hand,\n      author = {Tomas Simon and Hanbyul Joo and Iain Matthews and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Hand Keypoint Detection in Single Images using Multiview Bootstrapping},\n      year = {2017}\n    }\n\n    @inproceedings{cao2017realtime,\n      author = {Zhe Cao and Tomas Simon and Shih-En Wei and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields},\n      year = {2017}\n    }\n\n    @inproceedings{wei2016cpm,\n      author = {Shih-En Wei and Varun Ramakrishna and Takeo Kanade and Yaser Sheikh},\n      booktitle = {CVPR},\n      title = {Convolutional pose machines},\n      year = {2016}\n    }\n\nPaper links:\n- OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields:\n    - [IEEE TPAMI](https://ieeexplore.ieee.org/document/8765346)\n    - [ArXiv](https://arxiv.org/abs/1812.08008)\n- [Hand Keypoint Detection in Single Images using Multiview Bootstrapping](https://arxiv.org/abs/1704.07809)\n- [Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1611.08050)\n- [Convolutional Pose Machines](https://arxiv.org/abs/1602.00134)\n\n\n\n## License\nOpenPose is freely available for free non-commercial use, and may be redistributed under these conditions. Please, see the [license](./LICENSE) for further details. Interested in a commercial license? Check this [FlintBox link](https://cmu.flintbox.com/#technologies/b820c21d-8443-4aa2-a49f-8919d93a8740). For commercial queries, use the `Contact` section from the [FlintBox link](https://cmu.flintbox.com/#technologies/b820c21d-8443-4aa2-a49f-8919d93a8740) and also send a copy of that message to [Yaser Sheikh](mailto:yaser@cs.cmu.edu).\n",
        "releases": [
            {
                "name": "OpenPose v1.7.0",
                "date": "2020-11-17T05:48:13Z"
            },
            {
                "name": "OpenPose v1.6.0",
                "date": "2020-04-27T03:50:43Z"
            },
            {
                "name": "OpenPose v1.5.1",
                "date": "2019-09-04T01:40:28Z"
            },
            {
                "name": "OpenPose v1.5.0",
                "date": "2019-05-16T13:14:12Z"
            },
            {
                "name": "OpenPose v1.4.0",
                "date": "2018-09-02T02:42:57Z"
            },
            {
                "name": "OpenPose v1.3.0",
                "date": "2018-03-24T16:31:23Z"
            },
            {
                "name": "OpenPose v1.2.1",
                "date": "2018-01-09T20:20:39Z"
            },
            {
                "name": "OpenPose v1.2.0",
                "date": "2017-11-03T22:01:42Z"
            },
            {
                "name": "OpenPose v1.1.0",
                "date": "2017-10-31T21:55:59Z"
            },
            {
                "name": "OpenPose v1.0.2",
                "date": "2017-10-31T21:54:44Z"
            },
            {
                "name": "OpenPose v1.0.1",
                "date": "2017-10-31T21:53:36Z"
            },
            {
                "name": "OpenPose v1.0.0",
                "date": "2017-10-31T21:49:39Z"
            },
            {
                "name": "OpenPose v1.0.0-rc3",
                "date": "2017-10-31T22:03:24Z"
            },
            {
                "name": "OpenPose v1.0.0-rc2",
                "date": "2017-10-31T21:50:08Z"
            },
            {
                "name": "OpenPose v1.0.0-rc1",
                "date": "2017-10-31T21:50:18Z"
            }
        ]
    }
}