{
    "https://api.github.com/repos/deepmind/deepmind-research": {
        "forks": 2616,
        "watchers": 13423,
        "stars": 13423,
        "languages": {
            "Jupyter Notebook": 12330730,
            "Python": 3426519,
            "Racket": 226692,
            "Shell": 84450,
            "Lua": 76186,
            "OpenEdge ABL": 15630,
            "C++": 5765,
            "Starlark": 5152,
            "C": 1002,
            "PureBasic": 8
        },
        "commits": [
            "2023-05-26T11:49:41Z",
            "2023-04-28T17:53:17Z",
            "2023-04-19T13:37:09Z",
            "2023-03-31T06:59:53Z",
            "2023-03-29T09:03:36Z",
            "2023-03-24T19:06:40Z",
            "2023-03-20T12:02:42Z",
            "2023-03-10T18:42:12Z",
            "2023-03-10T10:30:19Z",
            "2023-03-08T10:57:57Z",
            "2023-02-26T01:47:16Z",
            "2023-02-21T21:45:32Z",
            "2023-02-06T15:25:23Z",
            "2023-01-27T20:05:30Z",
            "2023-01-13T13:41:21Z",
            "2022-12-20T22:04:27Z",
            "2022-12-16T13:39:44Z",
            "2022-11-28T11:31:34Z",
            "2022-10-26T11:49:48Z",
            "2022-10-24T09:29:40Z",
            "2022-10-11T10:16:42Z",
            "2022-10-11T10:15:00Z",
            "2022-10-11T10:13:38Z",
            "2022-10-11T10:11:56Z",
            "2022-09-28T21:53:07Z",
            "2022-09-12T09:56:26Z",
            "2022-09-10T13:13:36Z",
            "2022-07-26T20:51:08Z",
            "2022-07-15T20:14:58Z",
            "2022-07-14T21:03:46Z"
        ],
        "creation_date": "2019-01-15T09:54:13Z",
        "contributors": 30,
        "topics": [],
        "subscribers": 325,
        "readme": "# DeepMind Research\n\nThis repository contains implementations and illustrative code to accompany\nDeepMind publications. Along with publishing papers to accompany research\nconducted at DeepMind, we release open-source\n[environments](https://deepmind.com/research/open-source/open-source-environments/),\n[data sets](https://deepmind.com/research/open-source/open-source-datasets/),\nand [code](https://deepmind.com/research/open-source/open-source-code/) to\nenable the broader research community to engage with our work and build upon it,\nwith the ultimate goal of accelerating scientific progress to benefit society.\nFor example, you can build on our implementations of the\n[Deep Q-Network](https://github.com/deepmind/dqn) or\n[Differential Neural Computer](https://github.com/deepmind/dnc), or experiment\nin the same environments we use for our research, such as\n[DeepMind Lab](https://github.com/deepmind/lab) or\n[StarCraft II](https://github.com/deepmind/pysc2).\n\nIf you enjoy building tools, environments, software libraries, and other\ninfrastructure of the kind listed below, you can view open positions to work in\nrelated areas on our [careers page](https://deepmind.com/careers/).\n\nFor a full list of our publications, please see\nhttps://deepmind.com/research/publications/\n\n## Projects\n\n*   [Magnetic control of tokamak plasmas through deep reinforcement learning](fusion_tcv), Nature 2022\n*   [Pushing the Frontiers of Density Functionals by Solving the Fractional Electron Problem](density_functional_approximation_dm21), Science 2021\n*   [Mind the Gap: Assessing Temporal Generalization in Neural Language Models](pitfalls_static_language_models), NeurIPS 2021\n*   [The Difficulty of Passive Learning in Deep Reinforcement Learning](tandem_dqn), NeurIPS 2021\n*   [Skilful precipitation nowcasting using deep generative models of radar](nowcasting), Nature 2021\n*   [Compute-Aided Design as Language](cadl)\n*   [Encoders and ensembles for continual learning](continual_learning)\n*   [Towards mental time travel: a hierarchical memory for reinforcement learning agents](hierarchical_transformer_memory)\n*   [Perceiver IO: A General Architecture for Structured Inputs & Outputs](perceiver)\n*   [Solving Mixed Integer Programs Using Neural Networks](neural_mip_solving)\n*   [A Realistic Simulation Framework for Learning with Label Noise](noisy_label)\n*   [Rapid Task-Solving in Novel Environments](rapid_task_solving), ICLR 2021\n*   [WikiGraphs: A Wikipedia - Knowledge Graph Paired Dataset](wikigraphs), TextGraphs 2021\n*   [Behavior Priors for Efficient Reinforcement Learning](box_arrangement)\n*   [Learning Mesh-Based Simulation with Graph Networks](meshgraphnets), ICLR 2021\n*   [Open Graph Benchmark - Large-Scale Challenge (OGB-LSC)](ogb_lsc)\n*   [Synthetic Returns for Long-Term Credit Assignment](synthetic_returns)\n*   [A Deep Learning Approach for Characterizing Major Galaxy Mergers](galaxy_mergers)\n*   [Better, Faster Fermionic Neural Networks](kfac_ferminet_alpha) (KFAC implementation)\n*   [Object-based attention for spatio-temporal reasoning](object_attention_for_reasoning)\n*   [Effective gene expression prediction from sequence by integrating long-range interactions](enformer)\n*   [Satore: First-order logic saturation with atom rewriting](satore)\n*   [Characterizing signal propagation to close the performance gap in unnormalized ResNets](nfnets), ICLR 2021\n*   [Uncovering the Limits of Adversarial Training against Norm-Bounded Adversarial Examples](adversarial_robustness)\n*   [Learning rich touch representations through cross-modal self-supervision](cmtouch), CoRL 2020\n*   [Functional Regularisation for Continual Learning](functional_regularisation_for_continual_learning), ICLR 2020\n*   [The Autoencoding Variational Autoencoder](avae), NeurIPS 2020\n*   [Self-Supervised MultiModal Versatile Networks](mmv), NeurIPS 2020\n*   [ODE-GAN: Training GANs by Solving Ordinary Differential Equations](ode_gan), NeurIPS 2020\n*   [Algorithms for Causal Reasoning in Probability Trees](causal_reasoning)\n*   [Gated Linear Networks](gated_linear_networks), NeurIPS 2020\n*   [Value-driven Hindsight Modelling](himo), NeurIPS 2020\n*   [Targeted free energy estimation via learned mappings](learned_free_energy_estimation), Journal of Chemical Physics 2020\n*   [Learning to Simulate Complex Physics with Graph Networks](learning_to_simulate), ICML 2020\n*   [Physically Embedded Planning Problems](physics_planning_games)\n*   [PolyGen: PolyGen: An Autoregressive Generative Model of 3D Meshes](polygen), ICML 2020\n*   [Bootstrap Your Own Latent](byol)\n*   [Catch & Carry: Reusable Neural Controllers for Vision-Guided Whole-Body Tasks](catch_carry), SIGGRAPH 2020\n*   [MEMO: A Deep Network For Flexible Combination Of Episodic Memories](memo), ICLR 2020\n*   [RL Unplugged: Benchmarks for Offline Reinforcement Learning](rl_unplugged)\n*   [Disentangling by Subspace Diffusion (GEOMANCER)](geomancer), NeurIPS 2020\n*   [What can I do here? A theory of affordances in reinforcement learning](affordances_theory), ICML 2020\n*   [Scaling data-driven robotics with reward sketching and batch reinforcement learning](sketchy), RSS 2020\n*   [Path-Specific Counterfactual Fairness](counterfactual_fairness), AAAI 2019\n*   [The Option Keyboard: Combining Skills in Reinforcement Learning](option_keyboard), NeurIPS 2019\n*   [VISR - Fast Task Inference with Variational Intrinsic Successor Features](visr), ICLR 2020\n*   [Unveiling the predictive power of static structure in glassy systems](glassy_dynamics), Nature Physics 2020\n*   [Multi-Object Representation Learning with Iterative Variational Inference (IODINE)](iodine)\n*   [AlphaFold CASP13](alphafold_casp13), Nature 2020\n*   [Unrestricted Adversarial Challenge](unrestricted_advx)\n*   [Hierarchical Probabilistic U-Net (HPU-Net)](hierarchical_probabilistic_unet)\n*   [Training Language GANs from Scratch](scratchgan), NeurIPS 2019\n*   [Temporal Value Transport](tvt), Nature Communications 2019\n*   [Continual Unsupervised Representation Learning (CURL)](curl), NeurIPS 2019\n*   [Unsupervised Learning of Object Keypoints (Transporter)](transporter), NeurIPS 2019\n*   [BigBiGAN](bigbigan), NeurIPS 2019\n*   [Deep Compressed Sensing](cs_gan), ICML 2019\n*   [Side Effects Penalties](side_effects_penalties)\n*   [PrediNet Architecture and Relations Game Datasets](PrediNet)\n*   [Unsupervised Adversarial Training](unsupervised_adversarial_training), NeurIPS 2019\n*   [Graph Matching Networks for Learning the Similarity of Graph Structured\n    Objects](graph_matching_networks), ICML 2019\n*   [REGAL: Transfer Learning for Fast Optimization of Computation Graphs](regal)\n*   [Deep Ensembles: A Loss Landscape Perspective](ensemble_loss_landscape)\n*   [Powerpropagation](powerpropagation)\n*   [Physics Inspired Models](physics_inspired_models)\n\n\n\n## Disclaimer\n\n*This is not an official Google product.*\n",
        "releases": []
    }
}